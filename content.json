{"pages":[{"title":"关于我","text":"Hey，我是蔡华，一个普通的程序员。 我从2007年4月开始编写代码，目前已经有10多年的行业经验。现在我主要从事基于Unity的游戏产品的开发。","link":"/about/index.html"}],"posts":[{"title":"iOS学习笔记-01基本语法","text":"1.基本语法 与其它编程语言一样有基本类型，比如int，bool，double，float等等。为了64位的问题需要使用OC中定义的类型，例如NSInteger 1234567#if __LP64__ || (TARGET_OS_EMBEDDED &amp;&amp; !TARGET_OS_IPHONE) || TARGET_OS_WIN32 || NS_BUILD_32_LIKE_64typedef long NSInteger;typedef unsigned long NSUInteger;#elsetypedef int NSInteger;typedef unsigned int NSUInteger;#endif 在类的定义上分为Interface和Implement两部分，这个与C的头文件和实现文件是一个概念，只不过写法上还是有区别的。Interface作为头文件的基本写法就是这样的，注意到在@Interface上有一句变量的定义，这个是全局静态变量其用法和C中定义静态变量是一样的，在@Interface的花括号中还定义了两变量，其实@private可有可无，写法与C++是一样的。而property则写在中间，在@Interface花括号区域定义的变量目前发现不能使用类似retain这样的写法。 1234567891011121314static NSInteger staticIntInFirstViewController;@interface FirstViewController : UIViewController {@private NSInteger privateInt;@public NSInteger publicInt;}- (void)foo:(NSInteger)arg1;- (void)foo:(BOOL)arg1 withArg2:(NSInteger)arg2;+ (void)foo;- (void)printRetain;@property (nonatomic, retain) NSArray* arr;@end 字段和属性的使用方法如下： 1234FirstViewController* f = [[FirstViewController alloc] init];staticIntInFirstViewController = 1; // 只要引用了头文件，直接使用即可f-&gt;publicInt = 2; // C++的用法f.arr; 而Implement则是实现部分，Implement中可以添加一些只用于.m文件中的变量。 123@implementation FirstViewController { NSInteger I;} 类文件的生成： UI类：右键→New File→选定平台(iOS/OSX等)→Cocoa Class分类(category)：右键→New File→选定平台(iOS/OSX等)→Objective-C File→输入名称、选择类型为category，选择基类。（在这里还可以创建协议(protocol)和类扩展(extension)） 类的扩展，类的扩展分为分类(category)和使用()的形式来扩展类（class-continuation）。其区别在于category类似一个完整的类文件，有.h和.m。它的文件的名称通常为原类名+分类名，比如FirstViewController+Test,其Interface和Implement分别为 12345#import &quot;FirstViewController.h&quot;@interface FirstViewController (Test)@end 12345#import &quot;FirstViewController+Test.h&quot;@implementation FirstViewController (Test)@end 注意在分类中可以添加属性，但是会提示 ![](http://images2015.cnblogs.com/blog/23250/201610/23250-20161003182039301-389964144.jpg) 这是因为除了class-continuation其它分类不支持生成实例变量，而且也不建议在分类中定义属性。 而使用()来做的扩展类只是个头文件，形式如下，注意到类名后面有个()，这个里面定义的方法还是需要在主类的.m文件中实现。在class-continuation中可以定义属性、实例变量、方法，其无法被外部类访问，这就实现了细节的隐藏。 12345#import &quot;FirstViewController.h&quot;@interface FirstViewController ()@end 函数的定义,”-“为实例方法，”+”类方法（静态方法），语法上基本没有什么特别注意的，只是在函数和变量的明面上应该遵循oc命名的习惯 12345@interface FirstViewController : UIViewController- (void)foo:(NSInteger)arg1;- (void)foo:(BOOL)arg1 withArg2:(NSInteger)arg2;+ (void)foo;@end 函数的调用[xxxInstance foo]或者实例函数[xxxClass foo] 12345FirstViewController *f = [[FirstViewController alloc] init];[f foo:1];[f foo:YES withArg2:1];[FirstViewController foo];[f release]; 协议(protocol)和代理(delegate)，两者是合起来用，代理本质上是一个实现了协议的对象的引用。协议的形式为 123@protocol FirstViewDelegate &lt;NSObject&gt;- (void)didClickSomeUI;@end 代理的形式为 @property (nonatomic, assign) id&lt;FirstViewDelegate&gt; delegate; 需要注意的是：因为是个对象的引用，因此在使用的时候可能出现互相引用的问题，这样在定义property的时候需要定义为弱引用，防止对象因为互相调用而无法被释放。 在流程控制上一样使用if else, switch, for, do while等 123456789101112131415161718192021222324252627282930313233343536- (void)foo:(NSInteger)arg1 { if (arg1 &lt; 1) { return; } NSLog(@&quot;for start&quot;); for (NSInteger i = 0; i &lt; arg1; i++) { if (i % 2 == 0) { NSLog(@&quot;%ld&quot;, i); } } NSLog(@&quot;while start&quot;); NSInteger m = 10; while (m &gt; 0) { NSLog(@&quot;%ld&quot;, m); m--; } NSLog(@&quot;do while start&quot;); do { NSLog(@&quot;%ld&quot;, m); m++; } while (m &lt; 10); switch (arg1) { case 1: NSLog(@&quot;&quot;); break; case 2: { // do some } break; default: break; }}","link":"/2016/09/16/01基本语法/"},{"title":"iOS学习笔记-03UI","text":"3.UI iOS的UI开发说起来复杂也不复杂，复杂在于控件很多，属性很多，各种delegate,但是众多的控件也遵循着相同的模式，让人学起来会觉得可以举一反三。同时在UI这个大的标题下还有Draw、layer、transforms、animation、touch这些技术点。想要做出一些非常规UI效果往往不是依靠简单的使用SDK提供的控件可以做到的。 3.1 手动编写UI 个人认知：手动编写UI在iOS不需要考虑手机屏幕尺寸的时代是很好用的，但是随着多种尺寸屏幕的出现，在自适应上手动编写UI代码就有了一些局限性。 手动编写的核心在于创建UI对象，设置frame及各种属性。 当然也可以使用xib来拖动UI，然后让UI与代码关联进而编写相关功能。 3.2 autolayout 目前在Xcode中可以很好的时候用约束(constraints)来实现UI的自适应。 constraints的使用心得： 按住ctrl+左键来创建约束 可以在Constraints下找到具体的约束，进而进行修改。 其基本的使用可以对比NGUI，都是距离superview上下左右的距离，与其它View的间距、size等约束。 需要注意，当存在多层关系时，需要逐层设置，否则效果可能有问题。 对于constraint不但可以通过视图来设置，还可以编写代码来设置或修改。只要关联到代码(类似其它UI关联带代码的方式)就可以控制，一般只修改constraint属性。 活用|-△-|和|-口-|两个图标按钮。 3.3 触摸和手势识别器 触摸的信息包含触摸点的位置、处于的阶段，其包含在UITouch对象中，手势是在触摸的基础上SDK封装的功能，它将一些复杂的连续触摸抽象成一个个手势动作。UITouch对象保存了含有手势识别器的数组。这个 数组里的每个元素都是手势识别器，而每个识别器都用来接收相关的触摸对象。如果创建某个 视图时没有指定手势识别器，那么在系统传给响应者方法的。而UIEvent对象包含了多个UITouch对象，多少由触摸点决定。 触摸的五个阶段：UITouchPhaseBegan、UITouchPhaseMoved、 UITouchPhaseStationary、UITouchPhaseEnded、UITouchPhaseCancelled，除了stationary其它都可以在代码中重写方法（其实就是其它四个是可以callUIResponder中预定义好的回调方法）。以下代码演示了拖地效果的touch实现 123456789101112131415161718- (void)touchesBegan:(NSSet*)touches withEvent:(UIEvent *)event{ // Calculate and store offset, and pop view into front if needed startLocation = [[touches anyObject] locationInView:self]; [self.superview bringSubviewToFront:self];}- (void)touchesMoved:(NSSet*)touches withEvent:(UIEvent *)event{ // Calculate offset CGPoint pt = [[touches anyObject] locationInView:self]; float dx = pt.x - startLocation.x; float dy = pt.y - startLocation.y; CGPoint newcenter = CGPointMake(self.center.x + dx, self.center.y + dy); // Set new location self.center = newcenter;} 触摸分为单点和多点触摸，控制代码self.multipleTouchEnabled = YES;控制。 手势识别器主要有点击(tap)、滑动(swipe)、手指聚拢(pinch)、旋转(rotate)，拖动(pan)、长按(long press)。其基本用法都一样，类似： 12UIPanGestureRecognizer *panRecognizer = [[UIPanGestureRecognizer alloc] initWithTarget:self action:@selector(handlePan:)]; self.gestureRecognizers = @[panRecognizer]; 一个控件可以同时使用多个手势识别器。 关于同时识别手势的问题，一般是一个手势由一个控件识别但是通过下面的代码可以让一个手势被多个对象识别。 12345678910111213- (BOOL)gestureRecognizer:(UIGestureRecognizer *)gestureRecognizer shouldRecognizeSimultaneouslyWithGestureRecognizer:(UIGestureRecognizer *)otherGestureRecognizer{ return YES;}``` - 注意事项： 1. 一些图片带有透明区域，因此有可能点击了透明区域也被识别为tap。 2. 拖动的处理可以通过touch相关的函数或者手势，这就引出了放射变换的一些问题。 &gt; AffineTransform，仿射变换。其中transform定义为 &gt; &gt; struct CGAffineTransform { &gt; CGFloat a, b, c, d; &gt; CGFloat tx, ty; &gt;}; &gt; ``` 它包含了位置、旋转、缩放三个信息。类似U3D中的transform的概念。 变换的本质是矩阵的计算，（(x,0,0),(0,y,0),(tx,ty,1)）。 SDK中有很多的方法，基础的方法是CGAffineTransformMake(a,b,c,d,tx,ty)，参数对应矩阵。还有GAffineTransformMakeXXX和GAffineTransformXXX两个系列的方法。 3.4 控件","link":"/2016/09/16/03UI/"},{"title":"iOS学习笔记-04内存管理","text":"4.内存管理4.1 手动管理 自己生成的对象自己持有，可以调用release方法减少retain数量。 非自己生成的对象也可以持有，通过调用retain方法可以持有对象，引用数+1。 不再需要自己持有的对象要及时释放，注意类中的property要在- (void)dealloc方法中赋值nil，这样写相当于release了。 12345- (void)dealloc{ self.arr = nil; [super dealloc];} 无法释放非自己持有的对象，注意当一个变量持有一次对象后，只能释放一次。也就是说retainCount必须+1和-1对称。 alloc的实现。其实就是调用calloc方法申请内存和C语言的差不多，只不过对象的头部位有个地址用于存储引用数。而retain、release就是对引用数加减，dealloc则是free掉对象。 4.2 Autorelease autorelease这个玩意本质上是将对象加入到最近的一个NSAutoreleasePool中，当NSAutoreleasePool销毁时会将对象release。因此这里就有个坑了，如果这个pool很久都不销毁，里面的对象就始终存在，有可能会造成内存不足。 123456NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];// 当调用autorelease方法时，其实是将对象obj放到了pool的一个对象列表中NSObject* obj = [[[NSObject alloc] init] autorelease];[pool drain]; // obj会被调用release方法 注意到main.m中有这样的代码，在最外层就有个autoreleasepool了。 12345int main(int argc, char * argv[]) { @autoreleasepool { return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class])); }} 4.3 ARC 我的理解 所谓ARC是通过编译器和运行时的协作来实现自动管理引用计数，编译器在ARC有效的代码中加入额外的代码来加减引用计数。 标识 __strong：默认就是 __weak：需显式使用 __autoreleasing：这个标识一些情况下是不需要显式使用，一些情况下是不需要的，最为致命。 __unsafe_unretained：个人感觉已经被弃用了，在没有weak的时代使用的东西。 __strong 这个修饰符具有持有对象的功能，与retain类似。它的使用分为如下几种情况：1、id __strong obj = [[NSObject alloc] init]; 这行代码可以理解为如下代码，可见所谓自动管理，就是在编译出来的代码中对强引用变量调用release方法。 1234&gt; id obj = objc_msgSend(NSObject, @selector(alloc)); objc_msgSend(obj, @selector(init)); objc_release(obj);&gt; 2、id __strong obj = [NSMutableArray array]; 这行代码可以理解为以下代码，很有意思的代码。objc_retainAutoreleasedReturnValue是持有(retain)了一个在autoreleasepool中的对象,而这个对象就是array方法的返回值。 1234&gt; id obj = objc_msgSend(NSMutableArray, @selector(array)); objc_retainAutoreleasedReturnValue(obj); objc_release(obj); // 离开作用域后自动释放&gt; 与objc_retainAutoreleasedReturnValue成对出现的是这个方法objc_autoreleasedReturnValue方法，对于NSMutableArray类的array方法可能是这样实现的 12345&gt; + (id)array{ return [[NSMutableArray alloc] init];}&gt; 它可以理解为如下代码 1234567&gt; + (id)array{ id obj = objc_msgSend(NSMutableArray, @selector(alloc)); objc_msgSend(obj, @selector(init)); return objc_autoreleasedReturnValue(obj);}&gt; 对于外界调用这个方法赋值的变量来说，只是在使用一个autoreleasepool中的对象。在结合objc_retainAutoreleasedReturnValue使用时，其实生成的对象并没有进入autoreleasepool，而是直接传递给了使用objc_retainAutoreleasedReturnValue方法赋值的变量。 __weak 1、被__weak修饰的变量的地址会被放入到weak表中，这个表是个k-v形式的，key是对象的地址，value是所有引用了这个对象的变量的地址。 2、一个对象被释放的过程是个复杂的过程， 1234567891011&gt; objc_release -&gt; dealloc(如果引用计数为0) -&gt; _objc_rootDealloc &gt; -&gt; object_dispose -&gt; objc_destructInstance &gt; -&gt; objc_clear_deallocating&gt; {&gt; 1、用对象地址找到weak表中的value&gt; 2、所有变量(weak表中记录了地址)赋值nil&gt; 3、从weak表删除记录&gt; 4、从引用计数表删除废弃对象的地址为键值的记录&gt; } &gt; 从以上的过程可以看出当对象被销毁后所有引用它的__weak变量都会被赋值为nil，这个过程是比较消耗CPU的，少用。 3、使用被__weak修饰的变量就是使用注册到autoreleasepool中的对象，从以下代码来进行理解这句话， 123 id __weak obj1 = obj; NSLog(@&quot;%@&quot;, obj1);&gt; 这句话会大致被编译器翻译成这样 1234567id obj； objc_initWeak(&amp;obj1, obj); id tmp = objc_loadWeakRetaind(&amp;obj1); objc_autorelease(tmp); NSLog(@&quot;%@&quot;, tmp); objc_destroyWeak(&amp;obj1);&gt; &gt;可以看到为了能够NSLog执行时obj1引用的对象不被销毁，需要将它赋值给一个strong(默认)修饰的临时变量，而这个临时变量需要放到autoreleasepool中，因此存在一个问题，当你多次在一个作用域中多次使用weak修饰的变量，会导致很多临时变量产生而且会放到autoreleasepool中，作用域结束后autoreleasepool有很多工作要做。所以少用weak，一般就是避免循环引用。 __autoreleasing，核心就是把修饰的变量放入到autoreleasepool中，没啥多说的。 注意事项： 不能使用retain、release、retainCount、autorelease这样方法 不能使用NSAllocateObject和NSDeallocateObject方法，实际上我根本没用过。 需要在函数命名时遵守规则，比如alloc\\new\\copy\\mutableCopy必须给与调用者对象持有权限。 不能使用NSAutoreleasePool，可以用@autoreleasepool替换。 dealloc方法不能显示调用，很明显的例子就是在MRC中写dealloc方法时一定要调用super的dealloc方法，但是在ARC中不行了，不过notificationCenter的删除等处理还是要写在dealloc方法中的，会自动调用。","link":"/2016/09/16/04内存管理/"},{"title":"iOS学习笔记-08杂","text":"8.杂表达式表达式，是由数字、算符、数字分组符号（括号）、自由变量和约束变量等以能求得数值的有意义排列方法所得的组合。如：算术表达式、逻辑表达式、关系表达式、赋值表达式、逗号表达式等等。","link":"/2016/09/16/08杂/"},{"title":"iOS学习笔记-07必要知识","text":"7.必要知识7.1 APNS 目前在8.0以后的推送需要以下几个步骤： 1.使用registerUserNotificationSettings: &amp; registerForRemoteNotifications方法 12345if ([[UIApplication sharedApplication] respondsToSelector:@selector(registerForRemoteNotifications)]) { UIUserNotificationSettings* notificationSettings = [UIUserNotificationSettings settingsForTypes:(UIUserNotificationTypeSound | UIUserNotificationTypeAlert | UIUserNotificationTypeBadge) categories:nil]; [[UIApplication sharedApplication] registerUserNotificationSettings:notificationSettings]; [[UIApplication sharedApplication] registerForRemoteNotifications];} 关于registerForRemoteNotifications方法有以下说明，它会需要实现两个delegate方法，并且方法能够被执行的条件是通过registerUserNotificationSettings:方法成功注册用户的notification，或者enabled for Background App Refresh。 // Calling this will result in either application:didRegisterForRemoteNotificationsWithDeviceToken: or application:didFailToRegisterForRemoteNotificationsWithError: to be called on the application delegate. Note: these callbacks will be made only if the application has successfully registered for user notifications with registerUserNotificationSettings:, or if it is enabled for Background App Refresh 2.实现delegate方法：每个APP都不同，就不写了。 7.2 block tips 多使用typedef来定义block，因为简洁、可复用、对于结构相同的block可以通过命名来区分。 在定义API时多用handle block来降低代码分散程度。 注意在使用block时循环引用对象 12345678910111213141516171819202122232425262728293031323334#import &quot;BlockHandle.h&quot;#import &lt;Foundation/Foundation.h&gt;@interface BlockClass : NSObject@property (strong, nonatomic) NSData* localData;@property (strong, nonatomic) BlockHandle* bh;- (void)download;@end#import &quot;BlockClass.h&quot;@implementation BlockClass- (void)download{ // BlockHandle* bh self.bh = [[BlockHandle alloc] initWithUrl:@&quot;&quot;]; [self.bh startDownloadwithcompletionHandleBlock:^(NSData* data) { self.localData = data; // 解除引用，打破保留环 self.bh = nil; }];}- (void)dealloc{ NSLog(@&quot;BlockClass dealloc&quot;);}@end 123456789101112131415161718192021222324252627282930313233343536373839404142434445#import &lt;Foundation/Foundation.h&gt;typedef void (^completionHandleBlock)(NSData* data);@interface BlockHandle : NSObject@property (strong, nonatomic) NSString* url;@property (strong, nonatomic) completionHandleBlock block;- (id)initWithUrl:(NSString*)url;- (void)startDownloadwithcompletionHandleBlock:(completionHandleBlock)block;@end#import &quot;BlockHandle.h&quot;@implementation BlockHandle- (id)initWithUrl:(NSString*)url{ self = [super init]; if (self) { self.url = url; } return self;}- (void)startDownloadwithcompletionHandleBlock:(completionHandleBlock)block{ self.block = block; if (self.block != nil) { { dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{ [NSThread sleepForTimeInterval:3]; self.block(nil); }); } }}- (void)dealloc{ NSLog(@&quot;BlockHandle dealloc&quot;);}@end","link":"/2016/09/16/07必要知识/"},{"title":"LOD初探","text":"概念 LOD全称是Level of Detail，也就是细节层级。 为什么会产生这个技术？根据官方教程的解释是因为在一个很大的场景中，需要进一步考虑性能问题。LOD就是一个很好的解决性能问题的方案，它根据物体与摄像机的距离来展示这个物体不同的mesh，从而使得物体较远是使用面数比较少的mesh，而距离近的时候使用面数多的mesh。 如何使用 LOD在unity中的使用极为简单，基本分为以下几个步骤 创建一个空GameObject，然后加上LOD Group组件。 LOD Group中选择某个LOD块会出现 拖动对象到add按钮上后就设置了当前level下的模型。 依次设置完0、1、2的模型，需要注意LOD 0 表示摄像机最近距离显示，因此模型质量最高，数字越大距离摄像机越远，模型质量越低。 最终效果 我设置的是绿色cube在LOD 2，黄色在LOD 1,红色是0，因此从右下角的camera preview看到摄像机距离对象最远时显示的绿色，依次变为黄色和红色。 几个参数的设置 在setting的quality中有LOD的两个参数 Maximum LOD Level：最大LOD级别，表示游戏中使用的最高LOD级别。在该级别以上的模型不会被使用，并且在编译时忽略。（这将节省存储空间和内存空间）。 Bias LOD：LOD偏离 ，LOD级别基于物体在屏幕上的大小。当物体大小在两个LOD级别之间，可以选择使用低细节模型或高细节模型。数值取值范围为0-1，数值越接近0，越偏向于选择低细节模型。即是：如果该值小，那么摄像机离物体距离稍微有些变化，不同细节物体即会切换，该值大，那么摄像机需要与物体有很大的距离才会切换。 缺点 它的缺点是需要占用更多的内存，而且如果没有调整好距离的话，可能会造成模拟的突变。 如果不想占用内存还有种办法是只设置一个LOD在group中，可以通过代码实现，这样只用一个模型即可，不过如果刷新不够快或者设置的不合适可能出现视野中突然多了个物体的情况。","link":"/2016/10/09/LOD初探/"},{"title":"iOS学习笔记-06数据处理","text":"6.数据处理6.1 plsit 创建plist文件及添加数值 数据读取，注意因为plist创建的时候可以选择dictionary或者array，这个也决定了后面怎么去读取它。 1234567891011121314NSString* filePath = [[NSBundle mainBundle] pathForResource:@&quot;dict_data&quot; ofType:@&quot;plist&quot;];if (!isEmpty(filePath)) { NSDictionary* dict = [NSDictionary dictionaryWithContentsOfFile:filePath]; NSLog(@&quot;%@&quot;, dict[@&quot;name&quot;]); NSArray* arr = (NSArray*)dict[@&quot;favor&quot;]; [arr enumerateObjectsUsingBlock:^(id _Nonnull obj, NSUInteger idx, BOOL* _Nonnull stop) { NSLog(@&quot;%@&quot;, obj); }];}NSString *filePath2 = [[NSBundle mainBundle] pathForResource:@&quot;arr_plist&quot; ofType:@&quot;plist&quot;];NSArray *arr2 = [NSArray arrayWithContentsOfFile:filePath2];NSLog(@&quot;%@&quot;, arr2); 修改数据，注意工程中的arr_plist文件内容没变，但是实际上安装包里面的文件数据是变了的，可以通过open命令打开filePath2路径下的文件。 12345678910111213+ (void)writePlistData{ NSString* filePath2 = [[NSBundle mainBundle] pathForResource:@&quot;arr_plist&quot; ofType:@&quot;plist&quot;]; NSMutableArray* arr2 = [NSMutableArray arrayWithContentsOfFile:filePath2]; NSLog(@&quot;1 : %@&quot;, arr2); [arr2 addObject:@&quot;new obj&quot;]; [arr2 writeToFile:filePath2 atomically:YES]; NSMutableArray* arr3 = [NSMutableArray arrayWithContentsOfFile:filePath2]; NSLog(@&quot;2 : %@&quot;, arr3); [arr3 enumerateObjectsUsingBlock:^(id _Nonnull obj, NSUInteger idx, BOOL* _Nonnull stop) { NSLog(@&quot;%@&quot;, obj); }];} 6.2 xml6.2 JSON 创建json文件 数据读写 123456789101112131415161718192021222324252627NSError* error;NSString* path = [[NSBundle mainBundle] pathForResource:@&quot;data&quot; ofType:@&quot;json&quot;];// 1.iOS自己的API解析NSData* data = [NSData dataWithContentsOfFile:path];NSDictionary* jsonDict = [NSJSONSerialization JSONObjectWithData:data options:NSJSONReadingMutableLeaves error:&amp;error];NSLog(@&quot;%@&quot;, jsonDict);NSLog(@&quot;name = %@&quot;, [jsonDict objectForKey:@&quot;name&quot;]);// 2.JSONKit解析NSString* jsonStr = [NSString stringWithContentsOfFile:path encoding:NSUTF8StringEncoding error:&amp;error];NSLog(@&quot;%@&quot;, jsonStr);NSDictionary* jsonDict2 = [jsonStr objectFromJSONString];NSLog(@&quot;%@&quot;, jsonDict2);//3.反向生成JSONNSDictionary* dict = @{ @&quot;age&quot; : @1, @&quot;xx&quot; : @&quot;2&quot;, @&quot;favor&quot; : @[ @&quot;cai&quot;, @&quot;hua&quot; ] };NSData* jsonData = [NSJSONSerialization dataWithJSONObject:dict options:NSJSONWritingPrettyPrinted error:nil];NSString* jsonStr = [[NSString alloc] initWithData:jsonData encoding:NSUTF8StringEncoding];NSLog(@&quot;%@&quot;, jsonStr);NSString* jsonStr2 = [dict JSONString];NSLog(@&quot;%@&quot;, jsonStr2); 注意：目前的JSONKit是MRC的，需要在编译选项里面加入-fno-objc-arc,并且修正两个简单的bug。","link":"/2016/09/16/06数据处理/"},{"title":"Github Page爬坑指南","text":"1.jekyll的使用 jekyll的核心命令就几个 123jekyll new blog // 选好文件夹位置jekyll build // 在_site文件夹下生成网站内容jekyll serve // 可以在本地生成一个服务查看生成网站的内容，IP:127.0.0.1:4000 模板，参考别人的模板进行了修改，地址。 2.github上的设置 github上需要设置的反而是最少的，创建一个用户名下的repository，例如sam.github.io，然后直接将jekyll中_site下的文件提交到这个repository即可。如果代码没错就可以直接通过访问sam.github.io进入个人网站了。 3.个人域名绑定 首先在sam.github.io这个repository下添加一个名为CNAME的文件，内容为你自己的网站地址，比如sam.tech 去自己的域名管理中进行解析设置，以阿里云为例。从左侧进入云解析 DNS，选择域名后点击解析。删除原来的几个默认生成的解析，然后进行如下设置 记录值为sam.github.io.，注意io后面有个点。 经过上面两步如果你的域名和网站内容没有问题的话就可以通过域名访问了。 4.https的问题 经过上面的几步已经可以正常访问网站了，但是会注意到在chrome中会提示网站不安全，因为不支持https。 解决办法参考了这篇文章，在阿里云中通过域名→管理然后设置新的nameservers即可。只不过一直提示非万网DNS。 5.图片链接问题 目前生成出来的HTML代码中图片的路径是错误的，从网上也找了很多办法但是都不理想，咋这篇文章中使用的图片其实是我把图片上传到博客园，然后拿到URL后使用的。也就是说使用图片存储服务来实现，这样的好处就在于github page容量有限，如果将来图片多了会很麻烦，不如一开始就使用第三方来存储图片。","link":"/2016/10/03/github page爬坑指南/"},{"title":"解决JSONKit在macOS Sierra上crash的问题","text":"按照如下方法修改代码即可https://github.com/johnezang/JSONKit/pull/141/commits/ccc0565f0ae4a27371d18309ccb982a9f1f21b63 懒得改的可以直接clone我修改过的https://github.com/klkucan/JSONKit","link":"/2016/09/22/解决JSONKit在macOS Sierra上crash的问题/"},{"title":"VR开发环境搭建","text":"unity3d的安装 目前使用的Deepoon1.安装大朋助手。2.如果提示require DpnPlatform_x64.dll，则在大朋官网下载platform的sdk，并找到对应的平台的文件夹安装，有个bat文件可以安装。 安装steam和steamVR。对于steamVR来说正常安装完会显示能识别头盔，但是可能提示未准备好，需要进行房间设置。","link":"/2016/10/09/VR开发环境搭建/"},{"title":"向量夹角计算","text":"向量夹角123456789101112131415// 基于点积计算，// a.b = ||a|| * ||b|| * sin(θ) // =&gt; θ = arccos(a·b / (||a|| * ||b||))// =&gt; θ = arccos(a·b) //当a和b按照单位向量算时float angle = Mathf.Acos(Vector3.Dot(a.normalized, b.normalized)) * Mathf.Rad2Deg;// 基于叉积计算，// ||a × b|| = ||a|| ||b|| sinθ // =&gt; θ = arcsin(||a × b|| / (||a|| * ||b||))// =&gt; θ = arcsin(||a × b||) //当a和b按照单位向量算时// 下面公式中有个Distance的计算是因为||a × b||是有长度的angle = Mathf.Asin(Vector3.Distance(Vector3.zero, Vector3.Cross(a.normalized, b.normalized))) * Mathf.Rad2Deg;// 最简单计算方式Vector3.Angle(a, b)","link":"/2016/11/12/向量夹角计算/"},{"title":"Deepoon的相关设置以及如何玩steam游戏","text":"基本 保证Deepoon助手、显卡驱动是最新的。 安装Deepoon platform sdk。在platform sdk的安装过程中需要阅读其自带的文档，sdk path中不要带中文。 DpnnGetLastError的处理 目前发现在安装了steamVR的情况下会出现DpnuGetLastError错误，在启动状态下出现错误后，退出steamVR。然后重启游戏。 在setting→play中关闭VR support，这个东西在启动后会被steamVR开启（如果你的程序中用到了steamVR）。 按照上述两部则应该不会出现DpnnGetLastError错误，并且只能通过头盔来看游戏内容。 玩steam 在steam的安装目录下放置xxx\\Steam\\steamapps\\common\\SteamVR\\drivers\\deepoon。如果没有放置这个驱动可能导致steam下无法设置VR房间。设置完成后应该是 经过上面的设置就可以用大朋眼镜玩steam游戏了。 开发相关 目前发现如果用大朋眼镜可以玩steam，则在unity中是不需要使用DpnCameraRig的，而且也不需要开启大朋助手。 从这些表现来看大朋应该用的是Oculus的底层。","link":"/2016/10/12/Deepoon的相关设置以及如何玩steam游戏/"},{"title":"由一个美术需求引发的Custom Inspector","text":"需求 Editor模式下，在运行或者非运行状态下，能够按照指定的变化率来自动改变material中属性数值。 需求分析 如何在Editor模式下获得一个游戏对象及其组件，尤其是在非运行状态下？我们知道在Unity IDE运行起来后是很容易获得一个对象和组件的，在GameObject上挂一个脚本即可。但是在非运行状态下呢，transform.GetComponent这样的方法怎么执行？好在unity已经为我们考虑到了这个问题，提供了[ExecuteInEditMode]Attribute，通过指定这个attribute使得组件类中的方法可以在edit模式下执行，并且是在非运行状态下的。 如何在非运行状态下匀速改变数值呢？update方法中配合Time.deltaTime是一个完美的方案，但是即使设置了[ExecuteInEditMode]，update的表现在非运行和运行时也是完全不同的，查资料看到 is only called when something in the scene changed. 这句话时也有种吐槽的冲动。好在unity又为大家考虑到了这个问题（话说unity editor确实功能强大，AssetAtore里面那些插件真是厉害）,Edit模式下提供了EditorApplication.update，这是一个事件，我们注册一个自己的方法就可以在非运行状态下实现update的功能。我个人比较推荐使用EditorCoroutine，一个基于EditorApplication.update的协程实现。 功能实现 使用一个自定义组件来实现material中数值的修改，这个类在UI上要体现出能够设置变化速率和初始值。并且在UI上通过点击按钮的形式来触发改变。 使用Custom Inspector来实现组件UI的自定义。 在运行状态下通过使用默认的update来实现匀速变化，在非运行状态下通过使用EditorCoroutine来实现。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120using UnityEngine;using System.Collections;using UnityEditor;public class UVAnimation : MonoBehaviour{ public Vector2 TilingSpeed = new Vector2(1, 1); public Vector2 OffsetSpeed = new Vector2(0.1f, 0.1f); public Vector2 Tiling = new Vector2(1, 1); public Vector2 Offset = new Vector2(0, 0); float rate = 0.02f; EditorCoroutine coroutineOffset; EditorCoroutine coroutineTiling; bool isOffset = false; bool isTiling = false; // Use this for initialization void Start() { } // Update is called once per frame void Update() { } void FixedUpdate() { if (isOffset) { transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureOffset += OffsetSpeed * Time.deltaTime; } if (isTiling) { transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureScale += TilingSpeed * Time.deltaTime; } } public void ChangeOffset() { if (EditorApplication.isPlaying) { isOffset = true; } else { if (coroutineOffset != null) { coroutineOffset.stop(); } coroutineOffset = EditorCoroutine.start(ChangeOffsetCoroutine()); } } IEnumerator ChangeOffsetCoroutine() { while (true) { yield return new WaitForSeconds(rate); transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureOffset += OffsetSpeed * rate; } } public void ChangeTiling() { if (EditorApplication.isPlaying) { isTiling = true; } else { if (coroutineTiling != null) { coroutineTiling.stop(); } coroutineTiling = EditorCoroutine.start(ChangeTilingCoroutine()); } } IEnumerator ChangeTilingCoroutine() { while (true) { yield return new WaitForSeconds(rate); transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureScale += TilingSpeed * rate; } } public void SetOffset() { transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureOffset = Offset; } public void SetTiling() { transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureScale = Tiling; } public void Reset() { isOffset = false; isTiling = false; transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureScale = new Vector2(1, 1); transform.GetComponent&lt;Renderer&gt;().sharedMaterials[0].mainTextureOffset = new Vector2(0, 0); if (coroutineOffset != null) { coroutineOffset.stop(); } if (coroutineTiling != null) { coroutineTiling.stop(); } }} 123456789101112131415161718192021222324252627282930313233using UnityEngine;using System.Collections;using UnityEditor;[CustomEditor(typeof(UVAnimation))]public class UVAnimationBuilderEditor : Editor { public override void OnInspectorGUI () { base.OnInspectorGUI (); //DrawDefaultInspector (); UVAnimation uva = (UVAnimation)target; if (GUI.changed) { uva.SetTiling (); uva.SetOffset (); } if (GUILayout.Button(&quot;Change Tiling&quot;)) { uva.ChangeTiling (); EditorUtility.SetDirty (target); } if (GUILayout.Button(&quot;Change Offset&quot;)) { uva.ChangeOffset (); } if (GUILayout.Button(&quot;Reset&quot;)) { uva.Reset (); } }} 代码解析 [CustomEditor(typeof(UVAnimation))]为UVAnimation创建的Editor类，在这个类里面可以修改UVAnimation类的UI，可以调用UVAnimation类中的方法。 OnInspectorGUI方法，顾名思义在里面可以对UI进行编程，注意一下这个方法会自己生产一句代码base.OnInspectorGUI ();，我所注释掉的DrawDefaultInspector ();这句代码都是用来绘制默认UI的，二者只可留其一。 transform.GetComponent&lt;Renderer&gt;().sharedMaterials在edit模式下获取材质球的对象需要用sharedMaterials。 mainTextureScale对应的就是UI上的Tiling。命名这让人吐槽。","link":"/2016/11/19/由一个美术需求引发的Custom Inspector/"},{"title":"游戏设计模式读书笔记：架构、性能、游戏","text":"架构、性能、游戏 在开始读第一章的时候会觉得有点混乱，作者提出了什么是架构这个问题，但是并没有像其它书里那样给出一个明确的定义，而是提到了： 这本书是关于上面这一切要使用的代码的组织方式。这里少谈代码，多谈代码组织。 仔细品读这句话，你会发现这里面其实已经提到了什么是架构：所谓架构就是代码的组织方式。但是从我个人的认识来看这并不够全面，在这里在引用几段《架构漫谈》中的文字来阐述什么是架构： 在每个人都必须自己完成所有生活必须品的生产的时候，是没有架构的(当然在个人来讲，同一时刻只能做有限的事情，在时间上还是可能会产生架构的)。一旦产生的分工，就把所有的事情，切分成由不同角色的什么是架构人来完成，最后再通过交易，使得每个个体都拥有生活必须品，而不需要每个个体做所有的事情，只需要每个个体做好自己擅长的事情，并具备一定的交易能力即可。 这实际上就形成了社会的架构。那么怎么定义架构呢?以上面这个例子为例，把一个整体(完成人类生存的所有工作)切分成不同的部分(分 工)，由不同角色来完成这些分工，并通过建立不同部分相互沟通的机制， 使得这些部分能够有机的结合为一个整体，并完成这个整体所需要的所有 活动，这就是架构。 软件架构实际上包括了:代码架构， 以及承载代码运行的硬件部署架构。实际上，硬件部署架构最终还是由代 码的架构来决定。因为代码架构不合理，是无法把一个运行单元分拆出多 个来的，那么硬件架构能分拆的就非常的有限，整个系统最终很难长的更大。 关于架构和性能的冲突，我认为这个点写的很好，可以说我之前没有这样的认识。长久以来我都希望写出非常面向对象的代码，在我长久的认知中，代码的灵活性、高扩展性和可维护性是最重要的，因此设计模式是我在编写代码时所追求的。 但是作者提出良好的架构是需要很大的代价的，因为这需要遵守一些列的准则，Coder必须谨慎的组织代码，而且在引入了抽象，引入了可扩展性，引入的某个设计模式时，我们在增加了代码的灵活性的同时也增加了不可读性，增加了代码复杂度，这就增加了理解的难度。过度的架构设计往往会导致代码库失控，也许你会看到接口和抽象无处不在，我们可能需要花费大量时间才能找到真正功能的代码。关于这一点我也是深有体会，最近在看UniRx库，发现各种接口齐飞，大量的重载，梳理起来确实很费劲。 同时，从代码本身执行角度来说，灵活的代码往往意味着执行速度比较慢。从UNITY的角度来说，因为有类似CLR的东西，当使用面向接口编程时，往往意味这具体类型的判断需要在运行期，JIT做的越多，性能也越差。而且还很可能导致无法实现代码缓存，每次运行都需要实时的做判定。 原型代码 原型代码中可能包含大量的一次性代码，但是原型代码往往意味着不可维护，必须被重写。目前在项目的开发过程中，往往出现原型代码被最终使用在项目中，简直就是灾难。 寻求平衡 快速编写出的代码未必是执行最快的代码，而且这样的代码在后面往往需要花费很多时间来优化，这都是需要时间的。这些都需要平衡。 我们在工作中就是在不断的寻找平衡，有时候看到自己写的或者别人写的代码，就想去重构一下，但是现实又往往不给这个时间。","link":"/2016/12/17/游戏设计模式读书笔记：架构、性能、游戏/"},{"title":"游戏设计模式读书笔记：命令模式","text":"模式定义 定义：将一个请求封装成一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或者记录请求日志，以及支持可撤销的操作。 看图（图片资源来自于百度，侵删） 模式的理解 所谓命令模式说白了就是把一个方法对象化。怎么来理解这句话呢？可以看下UML图中的Command的interface，里面有个execute方法，还有一个undo方法。undo我们后面说，从内容上看这个接口非常的简单，它主要是为一个方法（execute）提供一个对象的载体。 这样做有什么用? 使你可用不同的请求对客户进行参数化； 对请求排队或者记录请求日志; 支持可撤销的操作。 因为一个方法的执行过程中往往是无法中断或者取消的，另外就是如果不做特殊的编码或者写相对应的方法，一个方法的执行往往不可逆。命令模式通过将方法封装成对象，进而可以制作出一个方法对象的列表，这样在顺序执行列表的过程中就可以将未执行的方法取消掉，而且保留这个列表相当于保留了一个操作的日志，在反向执行undo的操作就相当于对执行顺序进行逆转了。所以undo方法基本上是execute方法的逆向操作。 在unity中的使用 在这里我没有什么自己的例子，而是推荐这篇文章，这里已经很好的讲述的如何在unity中使用，并且也有了示例代码。 进一步的思考 《游戏设计模式》的作者也提到了是类风格化还是函数风格化的问题，他提到了JS写的代码如何实现这个模式。在我看来，C#的Action和Func一样可以替代类来实现方法的封装。因为命令模式的核心是将请求（方法）封装成对象，因此是用类或者一个delegate都是可以的。 那么何时使用类，又何时使用delegate呢？ 如果有undo的需求时采用类比较好，反之可以考虑delegate。 如果你的方法中使用了很多的共享的数据，你考虑使用享元模式时应该使用类，如果你的execute方法还调用了父类的方法，需要使用沙盒模式时应该考虑使用类。可以说一个复杂的逻辑方法中往往代表了数据和算法以及调用其它函数，这样的话一个Action可能并不能满足你的需要，因此类是你唯一的选择。 命令模式的一个很大的用途在于制作录像，也就是说如果我们有一个赛车游戏，那么录像的制作可以考虑只记录玩家的操作（命令），而其它的运动交给游戏逻辑（比如加速后的移动，碰撞后受到的影响等）本身来完成。这个应该是很多录像的实现方式。但是有个问题就是如何保障只使用命令的情况下，每次的游戏过程都能保证一致性。比如说一个赛车游戏中，玩家在躲避障碍的时候发布了左转命令，录像也忠实的记录了这个命令，但是在录像播放（游戏场景重现）时，依赖游戏逻辑是否能够完全正确的重现当时的场景，并且让这个左转的命令看上去是恰当的，这个十分考验引擎的计算准确性。 在多人联机游戏中是否应该使用命令模式来重现其他玩家的操作？因为我一直做的竞速游戏，所以如果考虑行为的一致性应该是使用命令模式来做的，但是有个问题就是帧率太高的话，可能出现客户端无法快速响应命令的问题，尤其是设备FPS不同的情况下。因此在使用命令模式的同时，做补帧是必要的。当然这个主要针对的是位移这个问题。","link":"/2016/12/26/游戏设计模式读书笔记：命令模式/"},{"title":"LuaFramework&PureMVC","text":"LuaFramework是GitHub上一个基于tolua的人更新案例，里面除了tolua的功能外还使用了PureMVC的部分功能。这个文章是对代码中PureMVC部分的一些理解。PureMVCStructureModel&amp;Proxy Model保存对Proxy对象的引用，Proxy负责操作数据模型，与远程服务通信存取数据。这样保证了Model层的可移植性。 View&amp;Mediator View保存对Mediator对象的引用。 由Mediator对象来操作具体的视图组件（View Component，例如Flex的DataGrid组件），包括：添加事件监听器，发送或接收Notification ，直接改变视图组件的状态。 这样做实现了把视图和控制它的逻辑分离开来。 在LuaFramework的初始代码中只有个APPView，在其中的 Controller&amp;Command Controller保存所有Command的映射。Command类是无状态的，只在需要时才被创建。 Command可以获取Proxy对象并与之交互，发送Notification，执行其他的Command。经常用于复杂的或系统范围的操作，如应用程序的“启动”和“关闭”。应用程序的业务逻辑应该在这里实现。 Controller会注册侦听每一个Notification，当被通知到时，Controller会实例化一个该Notification对应的Command类的对象。最后，将Notification作为参数传递给execute方法。 Facade Façade类应用单例模式，它负责初始化核心层（Model，View和Controller），并能访问它们的Public方法。 在实际的应用中，只需继承Façade类创建一个具体的Façade类就可以实现整个MVC模式，并不需要在代码中导入编写Model，View和Controller类。 Proxy、Mediator和Command就可以通过创建的Façade类来相互访问通信。 Facade保存了Command与Notification之间的映射。当Notification（通知）被发出时，对应的Command（命令）就会自动地由Controller执行。Command实现复杂的交互，降低View和Model之间的耦合性。 Observer&amp;Notification 使用一个简单的观察者模式实现。 PureMVC in LuaFrameworkNOTE：在LuaFramework的初始代码中是没有model、proxy、mediator这些内容的。View view部分也只存在一个AppView对象，它监听了一个MessageList，如果需要监听自己的事件可以在messagelist继续添加。从目前情况看，一个AppView基本可以满足所有UI事件的需要。 如果需要多个view的时候，在每个view中可以通过RegisterMessage方法来注册多个事件。 view的父类Base负责view的notification和command的映射。 Controller LuaFramework中Controller是一个singleton的，在一次性command的基础上加入了一个m_viewCmdMap用于处理由view负责处理的事件。 上面提到PureMvc中Command类是无状态的，只在需要时才被创建。所以在command的注册上LuaFramework采用的是名字+类型，因为有了类型就可以动态生成对象。 具体来说在LuaFramework的初始代码中注册了socketcommand，当facade send某个message时会调用这个command，采用的就是生成一个socketcommand对象，然后执行它的execute方法。这个方法调用了lua的network对象的OnSocket方法。 在command的注册上分为一次性的和view的 在command的执行上，在Controller的ExecuteCommand方法中可以看到，先从m_commandMap中查询是否有类型，如果有就实例化并执行execute方法。如果没有就在m_viewCmdMa中找，所有订阅了特定消息的view都会被执行OnMessage方法。 Facade AppFacade是其子对象。 在LuaFramework中facade不但负责将notification和command关联，而且负责管理Manager实例。本质一个字典，如果add的时候没有动静就是 facade父类负责将一次性的notification和command关联起来。 Observer&amp;Notification m_viewCmdMap是多播，而m_commandMap是单播。 总结 基本上在LuaFramework中的PureMvc只是使用了一部分功能，主要功能在于消息的注册发布和manager的管理。 在使用过程中，因为这个框架本身是要使用lua的，所以在源码中lua的部分在解耦上主要依赖event库来实现订阅发布。在C#部分反而不是很能体现MVC架构的优势。 在我自己的项目中为了最大化的使用热更新，所以很多逻辑都是写在lua中的，其实可以考虑在lua中实现一套PureMVC，但是这个语言在实现上应该不简单。","link":"/2017/10/16/LuaFramework&PureMVC/"},{"title":"每天一点UWA：第十二周","text":"UI对于UGUI文字花屏问题，有什么推荐的解决方法吗？ 对于UGUI字体花屏的现象， 很有可能是字体的UV不准确导致。 关于UGUI字体花屏和乱码 UGUI研究院之Text字体花屏（二十二）：http://www.xuanyusong.com/archives/4259 工具最近用Deep Profiler发现项目里有一个直接调用Color != Color的接口耗时很高，而且百分比也很高（不管是Self还是Total）。但是如果用Profiler.BeginSample显示时，其耗时又很低，百分比也很低几乎等于0。这样的情况下是Deep Profiler出问题了吗？ 针对上图具体例子来看，Deep Profiler中RoleRender_ChangeColor.get_running的CPU开销虽然较高，但其参考意义不大。因为不开Deep Profiler模式，此处开销是不会这么高的。 这是因为，图中的开销实际上是操作了200次循环且获取时间戳的开销，也就是说，当循环或者操作大量次数时，Deep Profiler模式中本身统计耗时操作的时间占比很大，所以此处反馈的时间其实并不是研发团队想看到的真正代码耗时。这也是为何很多团队反馈Deep Profiler统计不算准确的原因。 粒子粒子系统里面使用到的模型，是不是读写开关必须要打开，否则会崩溃？ 这个问题在第六周的内容中有提到原因。在较新的版本上（例如4.7.2，5.3.5 等版本）进行了各种情况的测试后，尚未复现出这一现象。因此，我们建议研发团队可以尝试关闭 Readable选项。 模型&amp;动画SkinnedMeshRenderer的Mesh是不是不能动态修改？属性里只开放了SharedMesh。 https://blog.uwa4d.com/archives/TechSharing_51.html mark一下。 渲染Unity中修改了Material的一个属性后，该Object就会单独实例化出一个Material，所以它就不能被动态Batching了，是这样吗？ 是的，所以我们在Material使用详情中对内存中驻留的Material进行了详细的检测和分析，如下图所示。 图中后缀为（Instance）的材质均为修改材质属性而生成的临时材质，对于这种情况，我们建议研发团队应严格将Instance材质数量控制在尽可能小（&lt;10）的范围内，而对于过高数量的Instance材质，建议研发团队考虑是否可以通过动态更换Material的方式来代替修改材质属性的方式，从而来减少不必要的Instance材质，进而提升物体动态合批的几率。 游戏中有一些静止的建筑，会和整个场景一起烘焙（包括了每个建筑在地表的阴影）。现在希望这些建筑是逐步开放的，比如玩家1级的时候只有建筑A开放，2级的时候建筑B开放，现在的问题是当建筑未开放时（SetActive(false)）地表的相关阴影还在。这种问题一般是怎么处理的？ 这种问题是因为研发团队将整个场景烘焙成一张Lightmap所致。如果地图中的建筑是固定的，且游戏中并没有动态改变方向光的需求（比如Time Of Day模拟），那么可以尝试以下方法来实现需求： （1）如果建筑物是根据等级而批量出现的，那么可以尝试根据等级不同而烘焙相应建筑群的Lightmap，然后在游戏中根据需求动态替换Lightmap； （2）如果是逐个出现且建筑之间相距较为紧密的话，那么建议尝试通过Dynamic Projector（Asset Store插件）或Shadow Map（Unity自带阴影）来进行处理，因为Lightmap方法已无法支持这种需求。同时，可配合Fast Shadow Receiver（Asset Store 插件）来尽可能降低上述实时阴影带来的性能开销。","link":"/2017/10/23/每天一点UWA：第十二周/"},{"title":"Shader合并与Variant","text":"前言 写这个的起因是因为看了唐建伟大佬在UWA上发表的文章合并Shader系列_如何合并渲染状态。看完后受益良多，但是也对文中这样合并shader会不会产生shader的变种（shader variant）有所担心，因此在UWA的问答上提出了问题，最后唐建伟也做出了回答，经过大佬授权在这里根据回答进行一些总结，想看原文的可以直接点击链接。 Sahder Variant的概念 其实一个variant可以理解为一个具体的在GPU上执行的小程序，而一个Shader通常会编译出非常多的variant来应对不同的情况，比如单说雾效就有如下：没有雾效、有线性雾、有指数雾1、有指数雾2这样的4个variant(ps:这里只考虑雾效，其他条件一致)。至于原因嘛，有很多，粗略归纳一下是因为GPU需要更多的并行处理、逻辑单元少，因此Shader里面要尽可能规避各种判断、循环语句等等，最后本来可以通过逻辑判断来处理的雾效就需要编译成不同的执行程序来对应不同的情况(ps：这是一种高级优化，背后的原理很多很多，建议自行查询相关资料，查明前因后果，我懂的也不多)。 问题1:这样通过多参数来设置渲染状态不会造成shader variant吗？ 在这篇文章中，我们只合并了渲染状态，渲染状态的合并不会导致Unity编译出更多的shader variant。口说无凭，那么我们就先拿一个示例Shader来做测试，我选用了文章中的“ShaderCombine/01.ShaderCombineSimpleZTest”来做测试，Unity版本为 5.5.4p3，使用Unity的Shader Variant Collection来算取Variant数量，不管是否加入合并的代码，Variant的数量都是259，如下图所示： 即便是使用“ShaderCombine/02.ShaderCombineCommonState”来测试，Variant的数量也是是259，如下图所示 从上面的图片可以看出，不管是否有渲染状态的参数在里面，Variant的数量都不会改变。 问题2：什么情况下在才会造成shader variant呢？ 宏定义(Keyword)，“#pragma multi_compile XXX YYY ZZZ”，“#pragma multi_compile_xxx”，SubShader，Pass，Fallback及一些特殊不常用命令等的增减会造成variant的数量变化。 至于一个Shader到底会生成多少variant呢？精确的计算方法，Unity并没有给出，但是我的归纳总结一下就是几组不同的编译宏的组合了，比如雾效、光照图、光源、阴影等等。另外还可以通过Unity的工具Shader Variant Collection来查看一个Shader到底有多少个variant，也可以在里面来自己组合和预编译自己想要的variant。 福利：为什么修改渲染状态不会产生variant？ 刚刚我们说了造成variant数量增加主要是需要生成不同的variant来应对不同的情况，那么不同的渲染状态是不是不同的情况呢？ 其实不是。生成不同的variant主要是为了消灭Shader内部的逻辑判断（ps：Shader的真正逻辑是CGPROGRAM…ENDCG中间的东西）。 继续用雾效举例，先只考虑有雾效和没雾效，按一般的游戏逻辑写法，我们通常会在逻辑里用一个if判断来搞定，但是由于GPU的特殊性，这样的做法非常低效、不可取，那么就会使用Keyword这样的编译宏在编译的时候就分别编译为有雾效和没雾效的2个执行程序，也就是2个variant。 现在说会渲染状态，看任何的Shader，我们都不会在CGPROGRAM…ENDCG里面有关于渲染状态的处理代码，当然不需要为不同的渲染状态编译不同的variant，也就不会造成variant的增加。（这部分可以参看Unity的渲染流水线，渲染一个物体需要非常多的步骤，我们写的Shader编译成的variant只在流水线中的两个可编程部分执行，而渲染状态是设置其他步骤的，与variant是完全隔离开、互不干扰。也可以说CGPROGRAM…ENDCG内的逻辑决定了variant的数量，CGPROGRAM…ENDCG外的是给Unity配置状态用的，不会引起Shader的逻辑变化，因此没变化）。另附上一张简化版渲染流程图：","link":"/2017/10/25/Shader合并与Variant/"},{"title":"每天一点UWA：第十一周","text":"字体优化字体资源方向：内存和数量峰值 主要是因为在字体资源的使用过程中采用了不同的方式。比如一开始的UI没有考虑使用AssetBundle，从而直接从Resources或者其它文件夹加载了字体资源。而后面的UI又依赖了AssetBundle中的字体，虽然也没有主动load，但是因为unity在load asset的时候会自动加载（有待验证）所以导致字体资源又被加载一次。从而峰值数量会不止一个。 内存:很多情况下我们对于一个字体库中的字体只是用了个别的，但是却加载了整个字体库。 优化方案 字库裁切 针对不同字体的应用场景，设计有效精简的裁切字库。 需要注意同一个字体资源在AssetBundle内外可能都会有依赖，如果依赖不能避免，那么就要各自设计裁切字库。 工具：FontSubsetGUI 结果 UI什么情况下会触发MaskableGraphic.Enable() ？现在我得到的结论是只要用到了Image组件，然后禁用启用带有这个组件的物体，都会触发进而产生GC。大家都怎么显示隐藏图片这种需求的，SetActive这种方式容易产生GC。 在UGUI中，Image组件并没有重写其父类的OnEnable函数，所以在激活时会出现MaskableGraphic.OnEnable。其中出现堆内存开销的话，通常是因为其父类函数Graphic.OnEnable中，UGUI在进行全局容器的Add等类似的操作时，遇到了扩容等产生堆内存的操作。 总之，在UGUI中，UI元素的激活和禁用所导致的堆内存分配，通常是不会持续出现的，其实不需要特别地处理。但对于其CPU开销，在UI元素数量较大时，依然是可观的，所以我们依然建议，对于激活禁用操作较为频繁的UI元素，可以尝试通过移出屏幕，缩放为0等方式来避免SetActive的调用。 UWA建议“将较多的动态UI元素分组放在不同的UI Panel中”，那么请问如果是ScrollView里面多个item的话，是否意味着每个Item都加一个Panel会更好一些？ “动态元素”其实是相对的。在 ScrollView 中，一般情况下，如背包，其中的Item在滑动过程中是相对静止的，因此这种情况下只需要将这些Item放在一个UIPanel中即可。 但在类似于聊天界面中，存在一些UI元素是有持续的动画的，那么就需要考虑对这类元素进行特殊处理，可以尝试将这部分有动画的UI放在独立的UIPanel中，或者在个数不多的情况下，各自变为一个UIPanel等。 如果我在UIPanel下面放的是Sprite Renderer而不是NGUI的Sprite，是否会引起整个UIPanel的重绘？ 在NGUI中使用Unity2D的Sprite有两种情况，一种是直接使用Unity2D的SpriteRenderer组件，这种情况下，NGUI和Unity2D之间是互不影响的，只是在深度的设置上相对会比较麻烦一些。 另一种是使用NGUI的UI2DSprite组件，而该组件是NGUI对Unity2D的SpriteRenderer组件上进行封装的，方便使其深度与其他UI元素进行穿插，因此其行为和其他的UI元素一致，在某些情况下是有可能引起UIPanel的重绘。 模型&amp;动画有一个带位移动画A，有位置有旋转的变化，需要播完这个动画后切换到一个原地的动画B。现在我发现动画A没播放就会切换到B了，导致一些位移数据并没有作用到模型上，这种情况怎么处理？ Mecanim动画系统提供了“Apply Root Motion”功能来满足两个动画文件顶点位移不一致的切换的需求。当开启“Apply Root Motion”功能后，角色的GameObject位置会随着动画的更新而更新。 因此，问题中的A切到B后，GameObject的位移将不会改变。建议该研发团队检测GameObject Animator组件的“Apply Root Motion”功能是否开启。 删除模型上动画的缩放link 防止将来翻不出去了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051void Apply(GameObject g) { List&lt;AnimationClip&gt; animationClipList = new List&lt;AnimationClip&gt;(AnimationUtility.GetAnimationClips(g)); if (animationClipList.Count == 0) { AnimationClip[] objectList = UnityEngine.Object.FindObjectsOfType (typeof(AnimationClip)) as AnimationClip[]; animationClipList.AddRange(objectList); } int count = 0; foreach (AnimationClip theAnimation in animationClipList) { foreach (AnimationClipCurveData theCurve in AnimationUtility.GetAllCurves(theAnimation)) { string name = theCurve.propertyName.ToLower(); if (name.Contains(&quot;scale&quot;)) { for (int i = theCurve.curve.keys.Length - 1; i &gt;= 0; i--) { theCurve.curve.RemoveKey(i); } string propertyName = theCurve.propertyName; // we can&apos;t delete &quot;*.x&quot;, e.g. m_LocalScale.x - but only &quot;*&quot;, e.g. m_LocalScale if (propertyName.IndexOf(&quot;.&quot;) &gt; 0) { propertyName = propertyName.Substring(0, propertyName.IndexOf(&quot;.&quot;)); } Debug.Log(string.Format(&quot;Fixing: {0} - {1}&quot;, theCurve.path, propertyName)); theAnimation.SetCurve(theCurve.path, theCurve.type, propertyName, null); count++; } } } int checkCount = 0; foreach (AnimationClip theAnimation in animationClipList) { foreach (AnimationClipCurveData theCurve in AnimationUtility.GetAllCurves(theAnimation)) { string name = theCurve.propertyName.ToLower(); if (name.Contains(&quot;scale&quot;)) { checkCount++; } } } if (count &gt; 0) { Debug.Log(&quot;Total number of removed curves is &quot; + count + &quot;. GO name: &quot; + g.name); Debug.Log(&quot;Number of remaining scale curves is &quot; + checkCount); } } 渲染物体的动态合批条件和是否是透明物体没什么关系吧？比如粒子系统的物体一般都是透明的，是不是也可以合批？ 动态合批并不限制物体是否为半透明或不透明物体。 合批的首要要求是Material一致，其本身是半透明Material还是不透明Material均没有限制。 粒子系统同样是可以合批的，只要其材质一致，深度较为接近且中间没有其他材质的物体阻隔，那么Unity引擎将会将其进行合批。 查看Unity引擎的官方文档：https://docs.unity3d.com/Manual/DrawCallBatching.html","link":"/2017/10/16/每天一点UWA：第十一周/"},{"title":"Xlua摘要","text":"加载机制 xlua在加载lua文件时会使用多个loader，LuaEnv的构造函数中有这么一段代码: 123456AddSearcher(StaticLuaCallbacks.LoadBuiltinLib, 2); // just after the preload searcherAddSearcher(StaticLuaCallbacks.LoadFromCustomLoaders, 3);#if !XLUA_GENERALAddSearcher(StaticLuaCallbacks.LoadFromResource, 4);AddSearcher(StaticLuaCallbacks.LoadFromStreamingAssetsPath, -1);#endif 从这段代码可以看出xlua主要的4个加载器分别是内置的lua的LoadBuiltinLib，已经lua可能存在的两个目录，一个是Resources、另一个是StreamingAssets，通常来说我们也很有可能会把lua代码放到这两个里面。尤其是当用lua做热更新的时候，StreamingAssets是一个很好的选择。 当LuaEnv遇到一个require的时候，就开始从这四个文件夹找 lua调用C#代码 unity中C#类分为两种，一种是继承了MonoBehaviour的，一种是一般的C#类。这两种都可以在lua中调用，但是调用方式不同。但是都需要给LuaCallCSharp这个attribute。 对于一般的C#类型，可以使用这样的方式 123local testClass = CS.Testlocal test = testClass()test.foo() 对于继承MonoBehaviour的类是不能用上述方法的，因为在实例化的时候会报错。xlua在生wrap的时候没有考虑是否继承自mono，继承自mono的类不能用new，所以会报错。只能用下面的方法，注意第一个是已经在某个游戏对象上挂了脚本的情况，第二个是用lua动态添加脚本。 123456self:GetComponent(&quot;MainUI&quot;):LoadScene(&quot;class1/class1&quot;) -- 或者local mainui = self.gameObject:AddComponent(typeof(CS.MainUI))mainui:LoadScene(&quot;class1/class1&quot;) 需要注意一下对于静态方法是用.，非静态是用:，其实也可以用.但是需要在函数定义的时候带自己self参数。对于unity中的一些函数这里尤为重要，比如 1234-- 因为Find是静态方法所以用.local cubes = GameObject.Find(&quot;Cubes&quot;)-- 而Transform.Find其实是依赖于一个具体的GameObject的所以要用:cube1 = cubes.transform:Find(&quot;Cube1&quot;).gameObject lua与C#代码结合 如果想使用xlua的LuaBehaviour这个脚本，需要注意的是不能用加载器加载lua代码，而是dostring，否则不能使用self、注入的对象。但是awake方法是可以用的。需要注意要使用GetInPath，get方法我没成功过。 123456789101112131415// 用对象名字作为加载脚本的查询名字string luaname = GameRoot.Instance.GlobleUtil.NameDeleteClone(gameObject.name);// 直接用byte[] dostringAssetBundle bundle = AssetBundle.LoadFromFile(&quot;Assets/StreamingAssets/main/lua&quot;);TextAsset lua = bundle.LoadAsset(&quot;MainUI.lua&quot;, typeof(TextAsset)) as TextAsset;luaEnv.DoString(lua.bytes, luaname, scriptEnv);// 用 custom loader加载 但是无法使用self，也无法获取luaAwake这类的方法//luaEnv.DoString(&quot;require &apos;&quot; + luaname + &quot;&apos;&quot;, luaname, scriptEnv);Action luaAwake = scriptEnv.GetInPath&lt;Action&gt;(&quot;MainUI.awake&quot;);luaStart = scriptEnv.GetInPath&lt;Action&gt;(&quot;MainUI.start&quot;);luaUpdate = scriptEnv.GetInPath&lt;Action&gt;(&quot;MainUI.update&quot;);luaOnDestroy = scriptEnv.GetInPath&lt;Action&gt;(&quot;MainUI.ondestroy&quot;); 关于ref和out修饰符 一开始我测试的时候是本以为lua调用ref传入的参数，也会返回出修改的结果，但出乎我的意料，并没能修改，经过作者提示，lua是通过返回值返回的ref参数，如果函数本身就有返回值，那么最后一个参数是返回的ref或者out参数，如果是一个没有返回值的函数（C#中），在lua中同样可以让它给变量赋值，赋的值就是ref的结果。","link":"/2017/10/05/2017-10-5-Xlua摘要/"},{"title":"每天一点UWA：第十周","text":"AssetBundleAssetBundle中的脚本 首先，需要说明的是，脚本本身的内容是不会被打包到AssetBundle文件中的，AssetBundle文件储存的仅是脚本的索引信息。因此，即便有多个AssetBundle中都存在UIAtlas这一脚本索引，对堆内存也几乎是不产生影响的，且不会产生冗余问题。 其次，脚本被当做资源且会产生依赖这一现象，仅在Unity 4.x版本中出现，而在Unity 5.0以后，脚本之间将不会产生依赖关系。因此，如果你目前还在使用Unity 4.x版本进行开发，那么依赖关系打包时确实需要注意这个问题，即依次Push A和B进行打包时，如果AssetBundle之间存在相同脚本，那么B会对A的脚本产生依赖。 如果我用WWW加载了一个AssetBundle，创建了一块WebStream内存。这时候我用另一个东西保存这个AssetBundle的引用，然后用WWW给Dispose了，那么这块WebStream内存会释放掉么？ 如果仅是www.dispose，但是AssetBundle引用依然保留的话，那么WebStream是不会释放的。WebStream存在两个引用，一个是www对象，一个是加载出来的AssetBundle。仅这两个引用全部消除时，WebStream才会被Unity引擎回收，具体说明可见之前的技术文章：Unity AssetBundle内存管理机制详解。 5.4之后似乎没有webstream的概念了。因为很多方法现在都是直接从disk读取，或者先保存在读取。 我发现如果不调用UnloadUnUsedAssets这个函数，则无法销毁通过Instantiate实例化出来的材质（包括纹理）。如果我尝试用Resouces.UnloadAsset来卸载挂在GameObject上的实例化材质, 则会闪退，请问这种情况该如何解决呢？ 如果想要直接销毁通过Instantiate实例化出来的材质、纹理等资源，则只能使用DestroyImmediate来进行销毁。研发团队可以参考NGUI中UI Draw Call组件里对动态材质的处理，来加深对动态创建以及销毁的理解。 脚本关于字符串驻留导致的内存占用 https://blog.uwa4d.com/archives/USparkle_String-interning.html https://gist.github.com/klkucan/6c51468ca6f92933356477745f0a50e0 Android用AssetBundle.LoadFromFile读取Application.streamingAssetsPath目录下的AssetBundle文件，用什么样的地址？ Unity 5.3之前，直接使用 Application.streamingAssetsPath 作为目录路径。 Unity 5.3之后，通过新增的LoadFromFile接口加载AssetBundle时，则需要改为 Application.dataPath+”!assets。 准确说这个不是一个优化的问题：NGUI的UIEventListener中的OnPress与UIButton的Press状态不能对应上。具体情况是我点击某个按钮并且按住不放，UIButton处于Press状态，然后移出了Button的范围，UIButton的状态变回了Normal，而UIEventListener中的OnPress并没有监听到，必须松开点击才能监听到。它们的Press状态切换有什么不一样呢？ 理论上UIButton的OnPress和UIEventListener的OnPress是在相同时间点触发的，即手指按下和手指抬起这两个时间点上。 而手指在按住状态下移开按钮时， UIButton的状态会变为Normal，这是因为其响应了OnHover的消息。因此如果要模拟UIButton的行为，至少要配合使用OnPress和OnHover两个消息。 模型&amp;动画求教Mesh导入后这里的uv3和uv4是怎么回事？有的模型只有uv和uv2，有的有四套。 如果在模型导入时就存在 uv2，uv3，uv4，那么这是因为在建模软件中添加了这些顶点属性。一般来说uv3和uv4的使用较为少见，通常是用来配合特殊的Shader实现特殊的效果。而uv2通常被用于Lightmap，uv2可以在建模软件中添加，也可以在Unity中通过Generate Lightmap UVs的选项来生成。 物理伤害检测、还有靠近采集物品时触发可以采集的提示箭头等，我们都使用了碰撞，请问如果不使用碰撞，可以用什么方法代替呢？ 使用Trigger也是较为合理的做法，如果想替代，可尝试根据距离、动画运行的时间点来进行判断。 性能综合prefab加载时依赖图片何时加载 首先说明一下，如果AssetBundle B和AssetBundle A产生依赖，那么在仅仅加载AssetBunde B中的Prefab B_prefab时，其本身开销仅为B_prefab的加载开销，对于AssetBundle A中的依赖资源并无影响。 但是在实例化B_prefab时，Unity引擎会去检查AssetBundle A中的依赖资源是否已经被加载好，如果没有加载好，则先加载AssetBundle A中相关资源，然后再实例化B_prefab。这其实就是大家经常遇到的初次实例化一个技能、角色时出现卡顿的主要原因。 因此，如果大家想加快B_prefab的实例化效率，那么对于其依赖关系AssetBundle A中的相关资源，可提前进行预加载，从而减少B_prefab实例化时的相关资源加载时间。 手动调用UnloadUnusedAssets+GC的问题 通过LoadLevel等API来切换场景时，Unity会自动触发Resources.UnloadUnusedAssets的操作，但在切换完成后再次调用Resources.UnloadUnusedAssets来确保卸载完全的做法也是较为常见的。但是在其它时间点不要调用。 对于大场景的MMO类型的游戏，因为切换场景的频率较低，也可以考虑每隔几分钟来手动触发一次Resources.UnloadUnusedAssets来降低内存。而GC的话，则不建议手动调用，即使是在切换场景时。 Resources目录下的所有内容都会加载到内存里吗？如果里面东西多，是不是会导致占用内存过高？ 不会，Resources.Load也是即用即加载，但就目前我们统计的结果来看，Resources文件下的资源越多，其生成的ResourceManager内存占用也越大。 Font Texture 资源是如何生成的，因为我发现好像有重复的出现，如何优化呢？ 这是Unity为动态字体自动产生的纹理，一般来说不用特别关注。即使重复出现，里面的内容一般也是不一样的（内容即屏幕上显示的文字）。 重建的Mesh，Unity引擎会将其重新传入GPU端进行渲染，这部分开销主要体现在Mesh.CreateVBO和Mesh.DrawVBO中。FK &amp; Statemachine 状态机占用时间比较高，是否有优化的方法呢？ 影响该项的因素较多，一般为： 是否开启Optimize GameObjects选项，如果没有，建议开启； 场景中Active的GameObject（使用并开启了Animator组件的）是否较多，数量越多，则该项目开销越高； GameObject的骨骼数越多、AnimationClip的采样次数越多，则该项开销也越高。 因此，建议研发团队可从以上三种情况入手来优化FK &amp; Statemachine的开销。 对Prefab资源的卸载、预览英雄模块、需要卸载英雄角色的资源、动画和材质都可以通过Resources.UnloadAsset(xxx)来顶点清除，而Prefab不行，Prefab 只能用 Destroy + Resouces.UnloadUnused()卸载吗？ Prefab如果想要单独卸载，只能使用DestroyImmediate来实现。同时，考虑到Prefab本身已经是很小的一个壳了，对内存的影响非常小，一般情况下是在切换场景的时候一起释放的。","link":"/2017/10/05/2017-10-5-每天一点UWA：第十周/"},{"title":"每天一点UWA：第十六周","text":"Texture如何处理ETC压缩完图片质量模糊和ARGB32内存占用太大这种关系？ 使用ETC压缩的图片尽量减少过渡，这是美术制作时需要注意的，很多情况下并不需要明显的过渡，只是需要半透明而已； 当然，有部分过渡色是必须的，这时候就要把相关小图整合到一张RGBA32的图片上； 在资源管理上入手。一般情况下，我们是允许部分资源使用RGBA32，但是要注意，及时卸载掉不使用的资源，以保证内存峰值在可控范围内。 果ETC压&gt; 缩效果不好的，会使用RGBA32并降一个尺寸规格来压缩，这样虽然图片会模糊点，但是过渡还是平滑的。 ASTC格式并不是所有机型都支持，在Android端只有配有高端Mali芯片的机器才支持，对于不支持的，引擎会将其解压成RGBA32进行处理，所以图片中的内存值过大，很可能是项目在不支持ASTC格式的设备上所看到的结果。 工具PutGeometryJobFence开销较高 就目前我们所优化过的项目而言，推测PutGeometryJobFence是Unity项目的主线程在等子线程的一些网格计算操作完成，其在不同的模块中均有出现（UGUI模块、渲染模块、Mesh.Skin操作、Animator动画模块等等），出现的地方不同，其本身含义也并不相同，不能一概而论。 Transform.set_position的开销很大 Deep Profiler本身对于耗时的统计影响很大，通常在Deep Profiler下调用次数越多的函数，其耗时的统计就会越明显地偏高，因此，我们首先建议关闭Deep Profiler，同时用Profiler.BeginSample/EndSample将修改Position的代码包进来，再查看其耗时，相对会更加准确。 CanvasRenderer.OnTransformChanged过多，移动UI元素相比于移动其他的元素确实会有额外的开销。 Unity Profiler中的Canvas.RenderSubBatch是否属于UI上渲染的开销？和重建有关系吗？ 是UI模块（UGUI）的渲染开销，但是跟UI的重建并无太大关系，主要还是跟UI界面的渲染Draw Call相关。 Clear的耗时过大 Clear操作一般是用来清除Camera的各种Render Buffer，当图像后处理使用的越多，则同一帧中开辟更多的Buffer的概率也越大，从而造成Clear的开销也较高。 项目中Clear耗时较高，且高耗时较为频繁，则建议先关闭图像后处理操作，来查看该情况是否有所好转。然后再逐步开启各个图像后处理操作，逐步定位造成Clear较高的耗时根源 模型&amp;动画如何降低动画文件的浮点数精度？之前UWA给过思路，但具体怎么个执行方法？ 动画文件后处理可以做两件事，1）精度压缩，2）scale曲线剔除。比起用工具修改原始fbx文件，这样比较灵活。实际测试，在开启Optimal压缩的情况下，加上这个后处理，能再节省40%左右。","link":"/2017/11/19/每天一点UWA：第十六周/"},{"title":"PHP的OOP","text":"在类中可以使用public（公有），protected（受保护）或 private（私有）来修饰属性和方法。如果不修饰默认是public。 类中用var定义变量，var $name，使用方式$this-&gt;name 构造函数function __construct()，析构函数function __destruct() 继承class Child_Site extends Site，使用extends关键字 实例化类 12345678910111213141516171819202122class Login{ var $m_user; var $m_pw; function __construct($user, $pw) { $this-&gt;m_user = $user; $this-&gt;m_pw = $pw; } function Login() { echo $this-&gt;m_user .&apos;-&apos;. $this-&gt;m_user; }}$user = $_POST[&apos;user&apos;];$pw = $_POST[&apos;pw&apos;];$login = new Login($user, $pw);$login-&gt;Login(); 可以使用interface 1234567891011121314151617181920212223242526272829&lt;?php// 声明一个&apos;iTemplate&apos;接口interface iTemplate{ public function setVariable($name, $var); public function getHtml($template);}// 实现接口class Template implements iTemplate{ private $vars = array(); public function setVariable($name, $var) { $this-&gt;vars[$name] = $var; } public function getHtml($template) { foreach($this-&gt;vars as $name =&gt; $value) { $template = str_replace(&apos;{&apos; . $name . &apos;}&apos;, $value, $template); } return $template; }} 常量 1234567891011&lt;?phpclass MyClass{ const constant = &apos;常量值&apos;; function showConstant() { echo self::constant . PHP_EOL; }}echo MyClass::constant . PHP_EOL; 静态属性不能通过一个类已实例化的对象来访问（但静态方法可以）。 静态属性不可以由对象通过 -&gt; 操作符来访问。调用方法是:: 抽象类与C#一样 Final 关键字，作用与C#的sealed一样。 子类中调用父类的方法parent::Login();，与C#的base.Login结构上一样。","link":"/2017/11/19/PHP的OOP/"},{"title":"Unity Android二次开发经(血)验(泪)谈(史)","text":"主要参考的是这篇文章，不过在这个期间遇到了各种的问题，在这里写出来，希望看到的人能够少走弯路。准备工作 安装Android Studio（以下用AS代替），然后通过它下载Android SDK和tools。 AS目前已经是3.0版本，在3之前不支持java8，也就是说没有lambda和一些新的特性。 从AS上可以下载到的build-tool是27，但是最新的tools是unity不支持，会在输出工程的时候报错，目前我使用的是26。 PS:实际上在这几天的尝试过程中使用27在unity端会有一个can not get xx list的错误，通过网上查询说是build tools版本的问题。而AS端似乎也有问题，不过没有记清楚。 AS中做的事情 按照文中的说法做即可。 其实作者本人也提到了几个点： 在建立module后要删除原来的app内存。 module名字和unity工程名字相同。 这是一个很坑的地方，在最开始的时候，我不断的遇到一个提示错误：library和project使用了同样的package name，而且unity的文档也说了不能同名。但是实际上是完全可以同名的。而且不管是直接用module还是把APP改成module，这两种方式都需要包名相同。 build AAR 其实在AS中只要把工程设置成了module，那么选择build apk出来的也是AAR。 AAR文件放到Assets\\Plugins\\Android\\libs 或者通过gradle直接生成，这个方式是目前用这最方便的。看下图，双击即可build。 图中的classes.jar就是我们自己的代码，libs文件夹下的是我们拷贝unity的，要删除掉。 unity中build apk 这块分开说下，因为我在整个尝试的过程中尝试了直接使用module方法（以下用方法1替代），这个方法不需要用到AS中的manifest。还有就是将app改造成module（以下用方法2替代），这个需要提供manifest。 方法1因为不需要提供manifest，所以省了很多事。 首先按照文中的方法先在AS中改造下manifest文件。 拷贝到Plugins/Android文件夹下。 在unity的PlayerSetting中进行设置。保证包名一致，保证minimum api level和AS中设置的一样。 在AS中我设置了compileSdkVersion和targetSdkVersion为25，开始按照文中和其他人的说法，在unity中target api level也设置的是25，==但是导出project时遇到android:configChanges错误：== unity CommandInvokationFailure: Gradle build failed. ‘configChanges’ with value… 真正的解决这个问题应该是在unity中Player Setting中将target API level设置为auto，这个要比minimum高才行。 方法2会遇到的问题： 因为开始没有把AndroidManifest.xml放到Plugin下，导致每次unity编译的时候都生成一个新的build-id，与AS中的不一致。这个问题其实只要把AS中的manifest文件放到unityPlugin中，就保证了不会每次编译都ID变的问题。 ==合并manifest==：AS的Gradle插件默认会启用Manifest Merger Tool，若Library项目中也定义了与主项目相同的属性（例如默认生成的android:icon和android:theme），则此时会合并失败。 解决方法有以下2种：1有效，2没试： 方法1：在Manifest.xml的application标签下添加tools:replace=”android:icon, android:theme”（多个属性用,隔开，并且记住在manifest根标签上加入xmlns:tools=”http://schemas.android.com/tools&quot;，否则会找不到namespace哦） PS：其实是这样写&lt;category tools:replace=&quot; android:name&quot; android:name=&quot;com.google.intent.category.CARDBOARD&quot; /&gt; 方法2：在build.gradle根标签上加上useOldManifestMerger true （懒人方法） 各种错误的处理 Failed to resolve:com.android.support:appcompat-v7:27+:报错处理 这个问题本质在于AS或者说本地的工具版本低，从下图中可以找到本地的版本。可以看到时26，所以需要在build.gradle中设置compile 'com.android.support:appcompat-v7:26.+'，将27改为26即可。 在project structure中可以设置java语言的版本，1.7的时候是不支持lambda的。需要注意。如果仍旧抽风般的提示lambda的问题就重启AS. AS2.3使用java8，本来3.0直接用的，2.3需要做如下处理。设置成功后也解决了unity Can't read classes.jar这个问题，是因为项目使用的Java（JDK）版本比较高，而ProGuard, version 4.4支持的版本（最高到1.6），所以产生该问题。，看了AS是一样的问题。 12345678910111213android { ... defaultConfig { ... jackOptions { enabled true } } compileOptions { sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 }} 下面这个错误印象中是改AS中工程的target版本，或者删除了对应的代码。 Error:(4) Error retrieving parent for item: No resource found that matches the given name ‘android:TextAppearance.Material.Widget.Button.Inverse’. AS3版本好像不能支持gradle4.1，找到dependencies改成如下。 1234567891011121314dependencies { classpath &apos;com.android.tools.build:gradle:3.0.0&apos; } ... apply plugin: &apos;com.android.library&apos;....defaultConfig { targetSdkVersion 27 //applicationId &apos;xxxx&apos; } 这个错误的情况是用unity生成并导出Android的代码，在2017.2p1的情况下输出的代码中gradle是4.1的。 如果是用AS自己生成APP或者module就没这样的问题。 adb.exe 已停止工作 这个问题最终发现是360手机助手占用了5037端口造成的 排查过程记录一下： 在\\platform-tools目录下调用adb devices命令 提示这个错误：adb server version (31) doesn't match this client (39); killing... error: could not install *smartsocket* listener: cannot bind to 127.0.0.1:5037: 通常每个套接字地址(协议/网络地址/端口)只允许使用一次。 (1 0048) CMD:netstat -ano | findstr &quot;5037&quot; //查看占用这个端口的APP，发现是进程15128 CMD:tasklist | findstr &quot;14152&quot; //查看这个进程对应的应用 下图中的14152进程是adb.exe，此时adb就允许正常了。 后记 其实在整个的使用过程中还遇到了非常多的问题，都是遇到一个搜索一个。所以也不可能完全的记录下来。 另外遗留了一个问题就是目前还不能调用Android中的类方法。","link":"/2017/11/20/Unity Android二次开发经(血)验(泪)谈(史)/"},{"title":"Gamma校正与线性空间","text":"前言 近期看了一篇文章，主要讲了如何处理lightmap在Android平台下下偏暗的问题。引发了对gamma校正的好奇。 Gamma校正的由来和计算方式 所谓Gamma校正指的是在传统的拍摄相机中会对照片中的亮度进行修正，计算公式为Lout = pow(Lin, 0.45)，说白了就是如果某个像素的亮度为0.5，那么保存后的照片的亮度就是0.5的0.45次方，即0.732。从下图可以看到绿色的线就是经过校正后的亮度曲线。在这个坐标系中，x轴为原始亮度，y轴是校正后的数值。 如果以原始亮度0.5作为一个分界线，很明显的看出来0.5之前的亮度在校正后占据了70%（0.732)以上的数据空间。这也是为何会有gamma校正的根本原因，即：肉眼对较暗区域的变化更为敏感，而0.5为灰度的界限，原始亮度小于0.5的部分可以认为是较暗的区域。因此将0.5之前的亮度经过校正，使得其结果的范围变大到0-0.732，这就可以进一步的放大黑暗区域的范围，从而使得照片更加真实。 但是从这个曲线我们看到，除了0和1以外的像素的亮度整体的变大了，因此就出现了下图的中左边图中的现象，即经过0.45的gamma校正后图片变亮。但是为何我们最后在电视或者电脑屏幕上看到的图像基本和肉眼看到的真实亮度一样呢， 是因为显示器的硬件也会做一次gamma校正，而这个指数是2.2，即pow(0.732，2.2） ≈ 0.5035 ，和0.5有数值上的差异但是基本接近。这只是个巧合。 同理，如果是原始像素的图片不经过gamma校正而直接输出到显示器，其结果就是下图中右边图的结果，也就是亮度整体变暗。这个和上图中蓝色曲线的结果也相同。计算方法也是幂计算。 导入unity中的图片 基本上所有的绘图软件在输出的结果上都是做过gamma校正的，否则在电脑屏幕上看到的就是偏暗。 因此在导入到unity后，在作用到shader时也是gamma校正后的图片。 当然我们也可以在绘图软件中就输出不经过gamma校正的图，这个后面说。 unity中的颜色空间 unity的颜色空间就是gamma或者liner space gamma选项下默认unity在shader中直接用gamma校正后的图片进行光照计算，然后输出到现实设备时硬件会做一次gamma校正，最终输出结果。 线性空间选项中，unity shader会对输入的图片进行一次gamma校正（2.2），得到真正的亮度值后进行光照计算。最后在进入颜色缓存区之前做一次gamma校正（0.45），然后图像进入显示设备，再次进行gamma校正（2.2）。 两者在最终结果的比对可以参考下图 可以看出来线性空间下产生的最终渲染效果比较接近于真实。 我们以一个亮度为1的点为例进行两种模式的计算，对比下结果，假设这个点的法线与点到光源的向量的夹角为60°。根据Lambert公式，此时该点的亮度（用亮度代替像素值）为Clight * Cdiffuse * max(0, dot(n,I))，为了简化计算我们认为Clight也就是光照颜色也是1， n和I都是1。 gamma下原始亮度是1的点，Cdeffuse为1，60°的点积是0.5，计算出来的颜色是0.5，输出到屏幕经过gamma校正（2.2）后值为0.218。 线性空间下线移除gamma校正，亮度1的移除后结果也是1，60°的光照结果也是0.5，输出到颜色缓冲区线做一次校正（0.45），到屏幕做一次校正（2.2），期结果应该是0.5035。 可以看出来两者在最后的结果上，线性空间的结果比较接近真实的60°情况下的亮度，这个真实值就是0.5。 线性空间工作流 现在unity中移动平台已经支持线性空间，只是需要OpenGL ES3。那么如果使用线性空间就需要一套类似PBR的流程。 首先就是纹理图是移除了gamma校正的。 在烘焙光照贴图的时候也要移除gamma校正。 后期处理的时候倒是不用额外做什么，因为unity已经对颜色值做了处理。 引用 GAMMA AND LINEAR SPACE - WHAT THEY ARE AND HOW THEY DIFFER PS 开头提到的lightmap偏暗的问题，在2017.2.0p1中移动平台lightmap处理LDR时已经加入了是否是gamma的判定，然后根据结果会对LDR的亮度进行不同的补偿。","link":"/2017/11/30/Gamma校正与线性空间/"},{"title":"iOS学习笔记-05线程","text":"5.线程5.1 GCD GCD是一套多线程库，可以有效的替换NSThread或者NSOperation。它的基本结构是dispatch_async(queue, block);参数中的queue可以通过dispatch_queue_create或者系统提供的标准dispatch queue。 123456789101112131415161718192021// 生成一个serial dispatch queuedispatch_queue_t serialQueue = dispatch_queue_create(&quot;com.demo.sai&quot;, NULL);// 生成一个concurrent dispatch queuedispatch_queue_t concurrentQueue = dispatch_queue_create(&quot;com.demo.sai&quot;, DISPATCH_QUEUE_CONCURRENT);// 生成的dispatch queue需要手动release，注意ARC不会释放dispatch_queue_t类型的变量dispatch_release(serialQueue);dispatch_release(concurrentQueue);// 使用系统已经提供的方法来create queuedispatch_queue_t serialQueue2 = dispatch_get_main_queue();dispatch_queue_t concurrentQueue2 = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);// 因此真正在代码中经常是这样写的dispatch_async(dispatch_get_main_queue(), ^{ NSLog(@&quot;execute in main thread&quot;);});dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{ NSLog(@&quot;execute in a concurrent thread&quot;);}); GCD中线程分为Serial Dispatch Queue和Concurrent Dispatch Queue，分别为顺序执行和并发执行。在使用dispatch_get_main_queue时获得的是主线程queue，因此它一定是顺序执行的。使用dispatch_get_global_queue获得的queue所能并行的线程数量由系统来确定，并且可以甚至优先级，然后由于XNU内核用于Global Dispatch Queue的线程不保证实时性，因此执行优先级只是大致的判断（说白了就是并不是严格执行的）。 dispatch_set_target_queue(dispatch_object_t object, dispatch_queue_t queue);可以用来改变queue的优先级先度 12// 变更queue的prioritydispatch_set_target_queue(concurrentQueue, serialQueue); 延迟将block添加到queue中，dispatch_after 123dispatch_after(dispatch_time(DISPATCH_TIME_NOW, 3 * NSEC_PER_SEC), dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{ NSLog(@&quot;dispatch_after&quot;); }); 注意这个方法可以用来做指定一个时间后执行某段代码但是这个时间参数并不准确,因为这个只是在一段时间后将block加入到queue中，但是并不意味着马上执行。 PS:关于用到的时间的宏的说明 NSEC：纳秒。 USEC：微妙。 SEC：秒 PER：每 所以： NSEC_PER_SEC，每秒有多少纳秒。 USEC_PER_SEC，每秒有多少毫秒。（注意是指在纳秒的基础上） NSEC_PER_USEC，每毫秒有多少纳秒。 所以，延时1秒可以写成如下几种： dispatch_time(DISPATCH_TIME_NOW, 1 * NSEC_PER_SEC); dispatch_time(DISPATCH_TIME_NOW, 1000 * USEC_PER_SEC); dispatch_time(DISPATCH_TIME_NOW, USEC_PER_SEC * NSEC_PER_USEC); 最后一个“USEC_PER_SEC * NSEC_PER_USEC”，翻译过来就是“每秒的毫秒数乘以每毫秒的纳秒数”，也就是“每秒的纳秒数” dispatch_group，当在并发完成一些处理后，可能需要一个节点来完成某个操作，这个操作必须等到之前的处理全部完成，那么就需要用到dispatch_group来实现。配合dispatch_group使用的有两个，dispatch_group_notify、dispatch_group_wait,前者是当处理全部完成后执行，后者是等待一段时间后，用返回值判断是否所有的任务都完成了。当等待时间为DISPATCH_TIME_FOREVER时返回值一定会是0。另外，dispatch_group_wait会阻塞调用的线程。 123456789101112131415161718192021222324252627 dispatch_queue_t groupQueue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);dispatch_group_t group = dispatch_group_create();// 第一个处理dispatch_group_async(group, groupQueue, ^{ NSLog(@&quot;first&quot;);});// 第二个处理dispatch_group_async(group, groupQueue, ^{ NSLog(@&quot;secend&quot;);});// 完成后最终的处理dispatch_group_notify(group, groupQueue, ^{ NSLog(@&quot;done&quot;);});long result = dispatch_group_wait(group, DISPATCH_TIME_FOREVER);if (result == 0) { NSLog(@&quot;done&quot;);}else { NSLog(@&quot;not done&quot;);}// 需要releasedispatch_release(group); -dispatch_barrier_async,在代码中会等待之前加入某个queue的block全部执行完，然后使得concurrent queue变为一个serial queue，只能执行用dispatch_barrier_async添加的block，等完成后，queue变回并发。典型应用场景DB read的操作使用dispatch_async，当需要write DB时使用dispatch_barrier_async，可以保证数据的一致性，也相当于给写操作加了锁（好吧这样说不够严谨）。 -dispatch_sync，同步的将block放到某个queue中，执行这个函数的线程会阻塞等待block执行完成。很容易导致死锁，目前看最好别用。 关于dispatch_sync导致死锁的问题：dispatch_sync(dispatch_get_main_queue, ...)这样写一定会死锁，dispatch_(a)sync这两个函数本质上是将block放到一个queue中，只不过一个会阻塞当前调用函数的线程，一个不会。 dispatch_async(dispatch_get_main_queue, ...)假设是main thread执行这个函数，那么线程不会等待block执行，虽然这个block是在main thread中执行的，最有可能的是在下一个loop中才会执行block。 dispatch_async(dispatch_get_global_queue(...), ...)假设是main thread执行这个函数，那么线程不会等待block执行，而是由系统分配另一个线程完成block，这个方式就是典型的多线程。 dispatch_sync(dispatch_get_main_queue, ...)假设是main thread执行这个函数，那么线程会等待block执行，但是这个block又是在main thread执行的，导致死锁。 dispatch_sync(dispatch_get_global_queue(...), ...)假设是main thread执行这个函数，那么线程会等待block执行，由系统分配另一个线程完成block，这个方式可用，但是最好不用main thread，而是自己创建一个serial queue。 最后看一组代码的结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 使用系统已经提供的方法来create queue dispatch_queue_t serialQueue2 = dispatch_get_main_queue(); dispatch_queue_t concurrentQueue2 = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); // 因此真正在代码中经常是这样写的 dispatch_async(dispatch_get_main_queue(), ^{ NSLog(@&quot;execute in main thread&quot;); }); dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{ NSLog(@&quot;execute in a concurrent thread&quot;); }); // 变更queue的priority // dispatch_set_target_queue(concurrentQueue, serialQueue); dispatch_after(dispatch_time(DISPATCH_TIME_NOW, 3ull * NSEC_PER_SEC), dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{ NSLog(@&quot;dispatch_after&quot;); }); dispatch_queue_t groupQueue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); dispatch_group_t group = dispatch_group_create(); // 第一个处理 dispatch_group_async(group, groupQueue, ^{ NSLog(@&quot;first&quot;); }); // 第二个处理 dispatch_group_async(group, groupQueue, ^{ NSLog(@&quot;secend&quot;); }); // 完成后最终的处理 dispatch_group_notify(group, groupQueue, ^{ NSLog(@&quot;done&quot;); }); long result = dispatch_group_wait(group, DISPATCH_TIME_FOREVER); if (result == 0) { NSLog(@&quot;result done&quot;); } else { NSLog(@&quot;result not done&quot;); } // 需要release dispatch_release(group); dispatch_async(concurrentQueue2, ^{ NSLog(@&quot;read1&quot;); }); dispatch_async(concurrentQueue2, ^{ NSLog(@&quot;read2&quot;); }); dispatch_barrier_async(concurrentQueue2, ^{ NSLog(@&quot;write&quot;); }); dispatch_async(concurrentQueue2, ^{ NSLog(@&quot;read3&quot;); }); dispatch_async(concurrentQueue2, ^{ NSLog(@&quot;read4&quot;); }); 1234567891011122016-07-09 14:46:28.500 CRHelper[3027:231293] execute in a concurrent thread2016-07-09 14:46:28.500 CRHelper[3027:231294] first2016-07-09 14:46:28.500 CRHelper[3027:231297] secend2016-07-09 14:46:28.502 CRHelper[3027:231297] done2016-07-09 14:46:28.502 CRHelper[3027:231205] result done2016-07-09 14:46:28.507 CRHelper[3027:231297] read12016-07-09 14:46:28.507 CRHelper[3027:231293] read22016-07-09 14:46:28.507 CRHelper[3027:231390] write2016-07-09 14:46:28.507 CRHelper[3027:231294] read32016-07-09 14:46:28.507 CRHelper[3027:231297] read42016-07-09 14:46:28.546 CRHelper[3027:231205] execute in main thread2016-07-09 14:46:31.782 CRHelper[3027:231294] dispatch_after “execute in main thread”这句话在代码顺序中是第一个但是却在倒数第二个输出，因为是在main thread执行的，可以很明确的看出来这个代码是在下一个loop中执行的，还有就是dispatch_after也并不是严格的按照3秒后执行的. dipatch_apply的应用场合主要是循环在一个queue中调用某个block，可以用于处理集合。这个函数会想wait一样阻塞线程，因此在非主线程中用比较好。 123456789NSArray* arr = [NSArray arrayWithObjects:@1, @2, nil];for (NSInteger i = 0; i &lt; [arr count]; i++) { NSLog(@&quot;%@&quot;, [arr objectAtIndex:i]);}dispatch_async(concurrentQueue2, ^{ dispatch_apply([arr count], concurrentQueue2, ^(size_t i) { NSLog(@&quot;%@&quot;, [arr objectAtIndex:i]); });}); 拾遗：dipatch_semaphore、dipatch_suspend、dipatch_resume等。基本没用过，懒得写了。 5.2 NSThread和performSelector 看一组代码和结果。可以看出performSelector方法是在main线程执行，而且performSelectorOnMainThread这个方法的输出在4之后，应该是这个方法会在下一个main thread的runloop中执行。1和4在测试中先后顺序不定，也比较好理解。 1234567891011121314151617181920- (void)doSome:(NSString*)arg{ NSLog(@&quot;%@ -&gt; %@&quot;, [NSThread currentThread], arg);}- (void)startThread{ NSThread* th = [[NSThread alloc] initWithTarget:self selector:@selector(doSome:) object:@&quot;1&quot;]; BOOL state = [th isMainThread]; state = [th isCancelled]; state = [th isFinished]; state = [th isExecuting]; [th start]; [self performSelectorOnMainThread:@selector(doSome:) withObject:@&quot;2&quot; waitUntilDone:NO]; [self performSelector:@selector(doSome:) withObject:@&quot;3&quot; afterDelay:3]; [self performSelector:@selector(doSome:) withObject:@&quot;4&quot;];} 12342016-08-28 22:40:45.055 ARCTest[3619:236163] &lt;NSThread: 0x7fc0c3501b70&gt;{number = 1, name = main} -&gt; 42016-08-28 22:40:45.055 ARCTest[3619:236310] &lt;NSThread: 0x7fc0c3723f30&gt;{number = 2, name = (null)} -&gt; 12016-08-28 22:40:45.077 ARCTest[3619:236163] &lt;NSThread: 0x7fc0c3501b70&gt;{number = 1, name = main} -&gt; 22016-08-28 22:40:48.056 ARCTest[3619:236163] &lt;NSThread: 0x7fc0c3501b70&gt;{number = 1, name = main} -&gt; 3 5.3 NSOperation5.4 锁 使用：NSLock, @synchronized(self),或者使用DISPATCH_QUEUE_SERIAL这样的形式来实现锁。 比较： NSLock控制麻烦，而且要考虑死锁。 @synchronized(self)如果很多方法都用self做锁，那么会导致一个长时间执行的方法阻塞其它方法，所以如果用最好不要都使用一个对象来作为锁对象。 GCD的锁不需要关注实现，而且是深层次实现的，比较高效，并且方法众多，可以时间多种锁的需要。 5.5 多线程编程的选择 NSThread功能完善，比较基础，能够完成简单的任务。当需要同步执行或者有一定的依赖要求时编程较为复杂。 performSelector缺点很多，首先执行SEL这个东西，需要判定方法是否存在；第二、在ARC下使用如果方法创建并返回一些对象，此时如果不进行一定的处理会导致内存泄露，因为ARC下默认是不做对象的autorelease的。第三、参数传递个数有限，有时需要自己定义个对象传递多个参数。 NSOperation，功能强大尤其是对于依赖性的处理使用起来很方便。 GCD，其实使用GCD基本可以完成任何任务，包括有依赖性的任务，和NSOperation搭配起来灵活使用吧。 GCD和NSOperation的对比： 1）GCD是纯C语言的API,而操作队列则是Object-C的对象。 2）在GCD中，任务用块（block）来表示，而块是个轻量级的数据结构；相反操作队列中的『操作』NSOperation则是个更加重量级的Object-C对象。 3）具体该使用GCD还是使用NSOperation需要看具体的情况 4）需要注意，如果直接使用NSOperation的start方法是直接在调用线程执行的，这意味着可能是在UI线程执行。 NSOperation和NSOperationQueue相对GCD的好处有： 1）NSOperationQueue可以方便的调用cancel方法来取消某个操作，而GCD中的任务是无法被取消的（安排好任务之后就不管了）。 2）NSOperation可以方便的指定操作间的依赖关系。 3）NSOperation可以通过KVO提供对NSOperation对象的精细控制（如监听当前操作是否被取消或是否已经完成等） 4）NSOperation可以方便的指定操作优先级。操作优先级表示此操作与队列中其它操作之间的优先关系，优先级高的操作先执行，优先级低的后执行。 5）通过自定义NSOperation的子类可以实现操作重用， 5.6 并发","link":"/2016/09/16/05线程/"},{"title":"代码生成AnimatorController","text":"0.出发点 现在的项目需要设置多套动画组合，全部是由策划在XML文件中设置完成，如果完全的手动在AnimatorController中去做不但工作量大而且如果将来有配置修改了还要一个个去找到对应的自状态机并且修改。因此就萌生了用代码去生成状态机的想法，而且在网上也有了很多的教程可以参考，只是每个项目都不同，且对于一些参数和属性的设置也不尽相同，因此还是把自己的代码进行一些修改后分享出来，基本上应该是包含了状态机常用的功能。 需要注意我的具体代码中是在一个已有的AnimatorController基础上创建的。如果完全是从0开始可以参考别的资料，其实道理是一样的都是代码创建对象。 1.数据来源一个典型的XML文件 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;config&gt; &lt;datas&gt; &lt;data INDEX=&quot;1&quot; Clip1=&quot;jump&quot; Clip1Count=&quot;1&quot; Clip2=&quot;BackLeap&quot; Clip2Count=&quot;2&quot; Clip3=&quot;die&quot; Clip3Count=&quot;1&quot;&gt;&lt;/data&gt; &lt;data INDEX=&quot;2&quot; Clip1=&quot;BackLeap&quot; Clip1Count=&quot;3&quot; Clip2=&quot;jump&quot; Clip2Count=&quot;0&quot; Clip3=&quot;jump&quot; Clip3Count=&quot;0&quot;&gt;&lt;/data&gt; &lt;data INDEX=&quot;3&quot; Clip1=&quot;BackLeap&quot; Clip1Count=&quot;1&quot; Clip2=&quot;ForwardLeap&quot; Clip2Count=&quot;1&quot; Clip3=&quot;jump&quot; Clip3Count=&quot;1&quot;&gt;&lt;/data&gt; &lt;/datas&gt;&lt;/config&gt; 2.动画控制器中的主要元素 Unity中editor的功能十分的强大，能够加载项目中的各种资源，而AnimatorController就是其中之一。 一个AnimatorController的结构基本如下 AnimatorControllerLayer：一个AnimatorController由多个Layer组成，但是除了BaseLayer外其它的Layer并不主要负责动画逻辑，而是多用于动画遮罩。 AnimatorControllerParameter：顾名思义是状态机中使用的参数，这个参数可以在不同的Layer和子状态机中使用。在代码添加参数时会选择参数类型，它是个枚举AnimatorControllerParameterType。 AnimatorStateMachine：动画状态机，核心逻辑实线层。在一个状态机中可以有多个state，也可以有多个Sub AnimatorStateMachine。通过AddStateMachine方法来生成并添加子状态机。 AnimatorState：动画状态，也是这个系统中的基础单元。其可以设定各种属性，比较常用的是AnimationClip和Speed等。 AnimatorStateTransition：也就是动画转换，其中可以设定触发参数，而且其中还有一个很重要的东西就是动画过度的设定。 3.完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299using UnityEngine;using System.Collections;using UnityEditor;using System;using UnityEditor.Animations;using System.IO;using System.Xml;using System.Text.RegularExpressions;using System.Xml.Serialization;using System.Collections.Generic;using System.Linq;//[CustomEditor(typeof(EditorTools))]public class EditorTools : MonoBehaviour{ #region 创建动画控制器 /// &lt;summary&gt; /// 记录上一个state，用于自状态机中 /// &lt;/summary&gt; static AnimatorState lastAnimatorState = null; static string ParameterName; // 动画片段 static AnimationClip die; static AnimationClip jump; static AnimationClip BackLeap; static AnimationClip ForwardLeap; /// &lt;summary&gt; /// base layer AnimatorStateMachine /// &lt;/summary&gt; static AnimatorStateMachine mainASM; static int stateHeight = 100; static int stateWidth = 220; /// &lt;summary&gt; /// 根据配置文件创建特技组 /// &lt;/summary&gt; [MenuItem (&quot;Tools/CreateAnimatorState&quot;)] static void CreateAnimatorState () { // 获取动画片段 List&lt;object&gt; allAssets = new List&lt;object&gt; (AssetDatabase.LoadAllAssetsAtPath (&quot;Assets/Charactors/player2.FBX&quot;)); var animationClips = allAssets.Where (o =&gt; o.GetType () == typeof(AnimationClip)).ToList (); foreach (var item in animationClips) { AnimationClip x = item as AnimationClip; switch (x.name) { case &quot;die&quot;: die = x; break; case &quot;jump&quot;: jump = x; break; case &quot;BackLeap&quot;: BackLeap = x; break; case &quot;ForwardLeap&quot;: ForwardLeap = x; break; default: break; } } // 当每个动画是一个单独的FBX文件中时可以用下面的方法来获取 //die = AssetDatabase.LoadAssetAtPath (&quot;Assets/Charactors/player2.FBX&quot;, typeof(AnimationClip)) as AnimationClip; // 获取状态机 AnimatorController animatorController = AssetDatabase.LoadAssetAtPath (&quot;Assets/AnimatorController/demo.controller&quot;, typeof(AnimatorController)) as AnimatorController; AnimatorControllerLayer layer = animatorController.layers [0]; mainASM = layer.stateMachine; // 获取当前所有的参数 AnimatorControllerParameter[] paras = animatorController.parameters; List&lt;AnimatorControllerParameter&gt; listParas = new List&lt;AnimatorControllerParameter&gt; (paras); // 删除指定的参数 var acps = listParas.Where (p =&gt; p.name.Contains (&quot;GroupParameter&quot;)).ToArray (); foreach (AnimatorControllerParameter item in acps) { animatorController.RemoveParameter (item); } // 删除指定的子状态机 ChildAnimatorStateMachine[] childASM = mainASM.stateMachines; List&lt;ChildAnimatorStateMachine&gt; listCASM = new List&lt;ChildAnimatorStateMachine&gt; (childASM); var casms = listCASM.Where (c =&gt; c.stateMachine.name.Contains (&quot;Group&quot;)).ToArray (); foreach (ChildAnimatorStateMachine item in casms) { mainASM.RemoveStateMachine (item.stateMachine); } // 读配置文件 XmlConfig xc = ReadXml (); Vector3 startPos = mainASM.anyStatePosition; // 根据配置创建自状态机 for (int index = 0; index &lt; xc.datas.Count; index++) { Data data = xc.datas [index]; // 设置特技参数， ParameterName = &quot;GroupParameter&quot; + data.INDEX.ToString (); animatorController.AddParameter (ParameterName, AnimatorControllerParameterType.Trigger); // 创建子状态机 AnimatorStateMachine sub = AddSubStateMachine&lt;AnimatorEvent&gt; (&quot;Group_&quot; + data.INDEX, ParameterName, mainASM, startPos + new Vector3 (stateWidth * index, -stateHeight, 0)); // 创建子状态机中的state SetStateInSubMachine (sub, data); lastAnimatorState = null; } } /// &lt;summary&gt; /// 创建sub state machine用于放置特效组中的动画 /// &lt;/summary&gt; /// &lt;typeparam name=&quot;T&quot;&gt;&lt;/typeparam&gt; /// &lt;param name=&quot;stateName&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;sm&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;position&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;data&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private static AnimatorStateMachine AddSubStateMachine&lt;T&gt; (string stateName, string para, AnimatorStateMachine sm, Vector3 position) where T : StateMachineBehaviour { AnimatorStateMachine sub = sm.AddStateMachine (stateName, position); sub.AddStateMachineBehaviour&lt;T&gt; (); AnimatorStateTransition transition = mainASM.defaultState.AddTransition (sub, false); transition.AddCondition (AnimatorConditionMode.If, 0, para); return sub; } /// &lt;summary&gt; /// 根据配置数据在子状态机中创建state /// &lt;/summary&gt; /// &lt;typeparam name=&quot;T&quot;&gt;&lt;/typeparam&gt; /// &lt;param name=&quot;subSM&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;data&quot;&gt;&lt;/param&gt; private static void SetStateInSubMachine (AnimatorStateMachine subSM, Data data) { AnimatorState newState; string stateName; Vector3 pos; List&lt;AnimationClip&gt; acArray = new List&lt;AnimationClip&gt; (); SetAnimationClip (data.Clip1, data.Clip1Count, ref acArray); SetAnimationClip (data.Clip2, data.Clip2Count, ref acArray); SetAnimationClip (data.Clip3, data.Clip3Count, ref acArray); for (int x = 1; x &lt;= acArray.Count; x++) { stateName = &quot;GroupState_&quot; + data.INDEX + &quot;_&quot; + x.ToString (); pos = subSM.entryPosition + new Vector3 (stateWidth, -stateHeight * x, 0); newState = AddState (stateName, subSM, pos, acArray [x - 1], x, acArray.Count); lastAnimatorState = newState; } } static void SetAnimationClip (string clipName, int count, ref List&lt;AnimationClip&gt; acArray) { for (int i = 0; i &lt; count; i++) { if (clipName == die.name) { acArray.Add (die); } if (clipName == jump.name) { acArray.Add (jump); } if (clipName == BackLeap.name) { acArray.Add (BackLeap); } if (clipName == ForwardLeap.name) { acArray.Add (ForwardLeap); } } } static AnimatorState AddState&lt;T&gt; (string stateName, AnimatorStateMachine sm, float threshold, string parameter, Vector3 position, AnimationClip clip, bool first = false, bool last = false) where T : StateMachineBehaviour { AnimatorStateTransition animatorStateTransition; // 生成AnimatorState AnimatorState animatorState = sm.AddState (stateName, position); // 设置动画片段 animatorState.motion = clip; // 创建AnimatorStateTransition // entry连接到特技组的第一个动画 if (first) { animatorStateTransition = sm.AddAnyStateTransition (animatorState); animatorStateTransition.AddCondition (AnimatorConditionMode.Equals, threshold, parameter); } // 最后一个动画连接到stand if (last) { animatorStateTransition = animatorState.AddTransition (mainASM.defaultState); } // 特技组内的连接创建 if (!first &amp;&amp; !last) { animatorStateTransition = animatorState.AddTransition (mainASM.defaultState); } animatorStateTransition = lastAnimatorState.AddTransition (animatorState, true); //AnimatorStateTransition 的设置 animatorStateTransition.canTransitionToSelf = false; animatorState.AddStateMachineBehaviour&lt;T&gt; (); return animatorState; } static AnimatorState AddState (string stateName, AnimatorStateMachine sm, Vector3 position, AnimationClip clip, int index, int count) { AnimatorStateTransition animatorStateTransition = null; // 生成AnimatorState AnimatorState animatorState = sm.AddState (stateName, position); // 设置动画片段 animatorState.motion = clip; // 创建AnimatorStateTransition // AnyState连接到特技组的第一个动画 if (index == 1) { //animatorStateTransition = sm.AddAnyStateTransition(animatorState); //animatorStateTransition.canTransitionToSelf = false; } // 最后一个动画连接到main animator machine的default state if (index == count) { animatorStateTransition = animatorState.AddTransition (mainASM.defaultState); animatorStateTransition.hasExitTime = true; } // 特技组内的连接创建 if (lastAnimatorState != null) { animatorStateTransition = lastAnimatorState.AddTransition (animatorState, true); } return animatorState; } #endregion #region public method static XmlConfig ReadXml () { //string xmlStr = File.ReadAllText(Application.dataPath.ToString() + &quot;/StreamingAssets/XMLConfigFiles/Stunt.xml&quot;); //Debug.Log(xmlStr); //string objTxt = Regex.Replace(xmlStr, @&quot;&lt;!--[^-]*--&gt;&quot;, string.Empty, RegexOptions.IgnoreCase); //Debug.Log(objTxt); return DeserializeFromXml&lt;XmlConfig&gt; (Application.dataPath.ToString () + &quot;/StreamingAssets/XMLConfigFiles/data.xml&quot;); } /// &lt;summary&gt; /// 从某一XML文件反序列化到某一类型 /// &lt;/summary&gt; /// &lt;param name=&quot;filePath&quot;&gt;待反序列化的XML文件名称&lt;/param&gt; /// &lt;param name=&quot;type&quot;&gt;反序列化出的&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static T DeserializeFromXml&lt;T&gt; (string filePath) { try { if (!System.IO.File.Exists (filePath)) throw new ArgumentNullException (filePath + &quot; not Exists&quot;); using (System.IO.StreamReader reader = new System.IO.StreamReader (filePath)) { System.Xml.Serialization.XmlSerializer xs = new System.Xml.Serialization.XmlSerializer (typeof(T)); T ret = (T)xs.Deserialize (reader); return ret; } } catch (Exception ex) { return default(T); } } #endregion}#region 序列化需要的model[XmlType (TypeName = &quot;config&quot;)]public class XmlConfig{ [XmlArray (&quot;datas&quot;)] public List&lt;Data&gt; datas { get; set; }}[XmlType (TypeName = &quot;data&quot;)]public class Data{ [XmlAttribute] public int INDEX; [XmlAttribute] public string Clip1; [XmlAttribute] public int Clip1Count; [XmlAttribute] public string Clip2; [XmlAttribute] public int Clip2Count; [XmlAttribute] public string Clip3; [XmlAttribute] public int Clip3Count;}#endregion 4.最后的说明 其实整个过程基本就是读取XML文件内容，然后按照第二部分中描述的结构来一点一点构建状态机。 在设定具体属性时需要按照具体情况来做。 有个天坑，就是如果在Base Layer界面多次点击CreateAnimatorState按钮时会出现Unity的crash，或者出现界面所有元素消失并报错。我找了很多资料应该是UnityEditor的bug。有一个很简单的解决办法，就是创建一个新的Layer，切换到新Layer的界面，然后点击CreateAnimatorState按钮，再切回Base Layer，这样就不会出错了。","link":"/2016/11/12/代码生成AnimatorController/"},{"title":"每天一点UWA：第十五周","text":"AssetBundle我们想请教一个Unity的普适性的资源管理问题。举个例子，我们现在的一个特效Prefab包含的贴图打成AssetBundle时没有单独拆分出来，就会存在一个问题，这个特效AssetBundle会存在重复加载的问题进而导致重复的特效贴图在内存中。（针对“重复加载”说明下：我们首先通过AssetBundle出来一个Object，这个Object会缓存一段时间，在这段缓存时间过后这个Object会被Destroy掉，而需要释放的特效是通过Instantiate这个Object出来的。当这个Object过了缓存时间被destroy掉后，下次需要释放相同的特效还是通过load同样的AssetBundle进行再实例化出来，这样内存中存在两份贴图了。） 一般是团队中自行做一些资源的引用计数来进行管理。频繁调用UnloadUnusedAssets是不可取的（该函数的主要作用是查找并卸载不再使用的资源。游戏场景越复杂、资源越多，该函数的开销越大，一般在300~2000 ms范围内），但可以调用UnloadAsset来释放资源。 PS:典型的释放prefab后没有释放对于的资源。确实应该用UnloadAsset，或者一开始这个图片资源就应该做成单独的AssetBundle。 美术做粒子的时候，粒子与粒子之间共用资源的情况很多，例如某几个粒子共用一个Material，某几个粒子共用一个贴图等，应该如何组织AssetBundle？要是对应到最细的那个程度，凡是共用过的资源都单独打一个AssetBundle，好像又会很琐碎，假如不那么做，粒子与粒子之间的AssetBundle又会有冗余。这方面有什么好的建议？ AssetBundle打包没有标准的方式，单就粒子系统而言，因为其个体本身比较小，并且在项目中经常大量出现，所以并不建议将粒子系统逐个打包，而是建议根据其出现频率进行打包，比如将同一段时间、同一出现场景等的粒子系统打包在一起。同时，由于粒子系统的Shader基本上都是Unity内置Shader，因此，尽可能将Shader进行依赖打包。 Gameplay我把骨骼文件的Optimize Game Objects”开启了，然后骨骼信息就没有了，那Avatar换装时候需要处理的骨骼信息怎么办？ 在开启“Optimize GameObject”选项后，因为Avatar信息消失，所以并不能通过原始的合并骨骼、合并Mesh的方法再来实现换装功能。对于开启“Optimize GameObject”选项的模型，Unity本身有另外一套更为方便的换装方式，即只要所换装模型的骨骼结点信息与Avatar自身骨骼信息可以匹配，那么直接将换装模型挂在Avatar模型下做为子节点即可，而不必再通过骨骼合并的方式来进行换装。 PS:mark一下，没看懂。 UI关于Mipmap的设置 通过修改Texture的mipMapbias这个值可以改变使用的mipmap的层级。但是这个值目没有办法在全局设置，在导入图片的时候要用代码设置。 unit官方建议Note that using large negative bias can reduce performance, so it’s not recommended to use more than -0.5 negative bias.，但是Mipmap的层级数的确是一个整数。mipMapbias是由Unity引擎定义的一个参数，按照Unity官网解释来看整数代表了比当前层级更低（级数更大，更模糊）的Mipmap，负数代表了比当前层级更高的Mipmap。“-0.5”具体是偏移多少层级目前也不是很清楚。 Trilinear应该是会比Bilinear效果好一些，但是也差强人意。原因是这样：传统的Mipmap（不采用Anisotropic Filtering）都是每层将u，v两个方向缩减一半，即：512x512的下一层是256x256。这就导致在两层交界处在不同层采样出来的纹理在u，v两个方向都被拉伸（或者叫变模糊）。Anisotropic Filtering的方式可以简单理解为在交界处只在某一个方向上被拉伸，另一个方向保持原有采样率（或者叫纹理分辨率），这样才能明显降低突变的模糊感。 使用Anisotropic Filtering不仅纹理内存占用会增高，而且采样率也增高（因为有一个方向的保持不变），因此它比传统的mipmap更耗时，耗时在于GPU端对纹理进行采样时增加了访存，在CPU端没有影响。虽然Anisotropic Filtering 耗时增加，但是相比于直接增加mipmap level（也就是设置-0.5的偏移），要达到相同的效果，Anisotropic Filtering的时间耗时还是相对更低的。 我在改血条，我原来是一个Canvas里放了所有血条，后来改成每个血条一个Canvas，再改成每个血条完全不用UGUI，直接用SpriteRenderer绘制，感觉性能越来越差了，怎么办呢？ 对于“所有血条放一个Canvas”和“一个血条放一个Canvas”做一个比较： 前者的开销主要在于网格的更新，在Unity5.2之后主要是在子线程中通过Timeline来查看。因此只看主线程的话，这种方法肯定是更高效的； 后者的开销主要在于DrawCall的数量（前者理论上能做到只用1个DrawCall，后者一个Canvas即一个DrawCall），开销被包含在了Camera.Render或者Canvas.RenderOverlays中。 因此，在选择时，需要考虑的就是“网格更新”和“DrawCall”的权衡。 还是建议尽可能降低血条的顶点数，然后选择前者。 模型&amp;动画优化动画精度时发现针对Generic效果明显，而Humanoid变化不大。 精度优化降内存（并非通过减少位数降低文本体积降内存），其实质是将曲线上过于接近0的数值（例如有效数字出现在小数点6位以后）直接归零，使部分曲线变为constant曲线来降低内存消耗。 在Generic中，大量曲线存在这样的数值，因而降低精度后，constant曲线增加，内存降低。 但在Humanoid中，动画信息被转化到Muscle空间后，muscle曲线上的数值很少约等于零，很难因为精度降低变为constant曲线，因此内存占用受精度降低的影响不大。 但归一化的Muscle空间本身就对动画信息进行了精简，自身内存占用相比Generic已经降低了不少，如果需要继续降低，可以尝试提高压缩选项下的Error值。 Animator会把所有状态的AnimationClip加载到内存，有什么好的办法可以动态加载？ Animator Controller结构不需要改变，但动画需要变化。比如随着人物等级或技能升级，同种的攻击动作随着变化等。该种需求可以通过AnimatorOverrideController来进行完成，即按需加载新的AnimationClip，然后替换AnimatorOverrideController中相应的AnimationClip即可。目前，Unity的AnimatorOverriderController不仅可以进行单个替换，同时也可以ApplyOverrides成组替换； Animator Controller结构需要改变，类似于Animation老版本动画的AddClip功能。这种需求需要替换AnimatorController，研发团队可以在动态加载AnimationClip的同时，动态加载相应的Animator Controller，然后进行替换即可。 为什么Transform.设置Parent会触发Animator的初始化吗？Parent是等于null的。 把 Parent 设为null，相当于把这个 GameObject 变为根节点。如果在设置之前这个 GameObject 本身是激活状态，但其的父节点是未激活状态，那么设置之后，相当于把这个GameObject 激活。而激活GameObject 时就会触发 Animator.Initialize 等操作了。 物理在Unity 的 Profiler里，有些记录右边会有Warning的个数信息，请问这个是否影响性能，或者是否有必要修改呢？ 这种字符的出现很可能会导致后续的物理更新出现较大的性能开销，包含在Physics.Simulate/Processing中。 针对这个图是受限于Unity版本中的PhysX在移动静态碰撞体是开销较高的问题（虽然文档中说5.x下已经解决，但我们确实发现在5.x的项目中该项仍然存在）。 建议给需要移动的Collider加上RigidBody并勾选Is Kinematic复选框，从而将其变为动态碰撞体。对于不移动的物体，则直接将模型的Apply Root Motion选项进行关闭，从而直接省去Static Collider.Move的性能开销。 性能综合我们设置了TargetFrameRate为30，想避免过高的耗电和发热，请问这样做是合理的么？ 这种设置仅在帧率本身很好的情况下，才会起到减少耗电和发热的作用。但如果本身游戏已经较为卡顿，那么该设置方法意义不大。对于耗电和发热，研发团队需从CPU、GPU和IO入手，尽可能降低这三方面的负载压力。 项目渲染中Material.SetPassFast的开销高 Material.SetPassFast是Unity引擎在渲染过程中Material的轮循切换开销，一般在Unity5.0~Unity5.3版本中出现。它的开销主要分为两种： Shader.CreateGPUProgram峰值开销：这种情况主要出现在Shader第一次渲染时。在Unity5.0以后，引擎为了避免Shader加载时过高的CPU峰值出现，已经将Shader.Parse和Shader.CreateGPUProgram两种操作分开执行，前者在Shader加载时，后者在Shader第一次渲染时。 渲染状态切换开销：这种情况是几乎每一帧都发生的，有渲染的地方就会有Material的切换。从问题图中可以看出，在运行的16000帧中，Material.SetPassFast一共被调用137万次。这里可以认为几乎全部是渲染时Material的切换操作。因此，该项较高的主要原因还是材质切换操作过多所致。所以，建议研发团队在报告中的详细材质页面查看是否有过多“冗余”的材质出现，如有则尽可能降低材质的使用冗余度。 渲染将需要的Shader打到一个AssetBundle包中（包含一个关联了所有Shader的Shader Variants），分别用Shader.WarmupAllShaders和ShaderVariantCollection.WarmUp两种方式进行预加载，后者耗时更少。 根据官方的文档的描述，确实是ShaderVariantCollection的效率更高，详见：https://docs.unity3d.com/Manual/OptimizingShaderLoadTime.html 因为在ShaderVariantCollection中，是可以给每个Shader添加指定的Keyword的，ShaderVariantCollection.WarmUp的调用只会对ShaderVariantCollection中指定的Keyword进行Warmup操作；而Shader.WarmupAllShaders则是对所有的Keyword全部进行Warmup操作（其中大多数很可能都不会用到）。 因此在Shader.WarmupAllShaders的文档中也提到，建议使用ShaderVariantCollection.Warmup来进行细粒度的Warmup操作，避免大量多余的Keyword被Warmup，造成严重的卡顿，大家可以参考下文：https://docs.unity3d.com/ScriptReference/Shader.WarmupAllShaders.html 在Unity 5.6版本中如何解决预渲染缺少高光的问题？该版本中光照预渲染Directional Mode选项中少了Directional Specular选项，渲染出来的效果场景缺少高光。 如果需要在使用Lightmap时渲染高光，替代方案是采用Mix Lights模式下的Shadow Mask以及Distance Shadow Mask选项。即将场景中的Directional Light改成Mix Lighting类型，并且在Lighting Mode选Shadow Mask或者Distance Shadow Mask。 其原理是：LIghtmap中仅仅存储indirect的光照，而direct光照是实时计算的，所以包括高光、阴影等都可以是实时的（阴影也可以是预计算好的）。这样做的好处是给Lightmap光照一定的灵活度，原来的Lightmap是完全静态的，现在是部分静态（direct的实时，indirect静态）。 Unity 5 的 Shader Variant Collection 功能 经过测试，在较新的版本中（如Unity 5.5.3），将ShaderVariantCollection与Shader打包在相同的AssetBundle中后，其中会包含该Shader在ShaderVariantCollection中指定的Variant。 使用 Shader 变体之后，Shader 是否还能走资源更新？抑或 Shader 不推荐走资源更新？ 使用 ShaderVariantCollection后依然可以进行资源更新（通过更新AssetBundle，来更新Shader的实现或者ShaderVariantCollection中包含的Variant）。 Shader 变体和 Shader Always Include 的主要区别是什么？二者对内存和帧率影响如何？ ShaderVariantCollection与Always Included Shaders的区别主要在于打包时所包含的Variant。Always Included Shaders中的Shader，其所有的Variant都会被包含，好处是，理论上不会出现Variant丢失的情况；坏处是，会导致更大的发布包以及额外的内存占用，而影响最大的是手动进行Warmup时的耗时以及ShaderLab的内存占用。因此一般来说，对于Variant特别多的Shader（如Standard Shader），并不推荐放入Always Included Shaders中。 在 Unity 5 较早的版本中，Shader 变体功能似乎有一些Bug，现在是否可靠？ 目前即使是较新的版本，其可靠性我们也并不能确保，依然建议在使用前进行一些测试来验证。 ==PS: 需要关注的问题==","link":"/2017/11/13/每天一点UWA：第十五周/"},{"title":"每天一点UWA：第十三周","text":"Gameplay求教一个屏幕后处理的问题。我们期望角色不受屏幕后处理影响，所以目前采用双相机的方案，根据Layer划分，但是这种情况下角色的影子也就没有办法投影到地表上，请问这种需求有什么好的实现方式？ 可以尝试根据地表模型的局部细节来动态生成接受阴影的网格（比如Fast Shadow Receiver插件），这样既可以保证地表模型进行屏幕后处理操作，同时也可以生成相关角色的动态阴影。 TextureUGUI用Resource来动态加载图片，有什么好的方法? 我的理解是：Resource目录下的图片都不能被打包成图集，而且会增加DrawCall和包大小。 需要打图集的Sprite确实不建议放置在Resources下，如果需要动态加载，并且不希望使用AssetBundle，则可以尝试把需要动态加载的Sprite统一引用到Prefab上进行管理（类似于NGUI的管理方式，一个图集对应一个Prefab），然后动态加载Prefab并查找其管理的Sprite即可。 另一种方式是，可以直接关闭Unity的Sprite Packer功能，通过第三方的工具来进行图集的打包，导入Unity时转为Multiple类型的Sprite资源，那么即使放在Resources文件夹下，也不会造成DrawCall无法合并的问题。 纹理图片通过文件流形式加载到内存，这样的资源还可以使用Resources.UnloadUnusedAssets()和Resources.UnloadAsset(m_Asset)进行资源卸载吗？ 如果是自己载入内存并初始化为Unity的Texture2D，则还是要重点查看Texture2D对象的创建方式。一般来说，会用new Texture2D的方式创建，并用LoadImage的接口将一块内存载入，那么这样就要用DestroyImmediate来销毁这个纹理对象了。 UI请问UGUI的重绘是针对于拥有Canvas组件的Canvas物件，还是针对于拥有CanvasRenderer组件的Panel物件？ UGUI中，Canvas组件可以认为是容器，Image，Text等组件（都需要CanvasRenderer组件）可以认为是元素。在Unity5.2版本之前，在网格重建时，会以Canvas为单位，即一个Canvas中所有的元素最终都是合并到一个Mesh中的，而其中可以被合并渲染的元素则被合在同一个SubMesh中。 在Unity5.2版本之后由于引入了多线程的网格合并方式，据我们所知，目前并没有官方的原理解释。 工具对于Animators.DirtySceneObjects这个参数，它是和哪些因素有关，以及如何优化？ 该参数是更新场景中受Mecanim动画系统影响的每个GameObject的Transform，所以当这类的GameObject数量越多时，其CPU占用也会越高。对于它的优化方式，主要有如下两种： 如果是蒙皮网格物体，则可以开启“Optimize GameObject”选项来对其进行优化； 如果是非蒙皮网格（比如具有动画的UI界面、2D Sprite等），则只能建议研发团队尽可能减少同一时刻运动的GameObject数量（一般都不会太多），如果是被缓存的屏幕外的物体，则切记要在移出时关闭其Animator组件。 编辑器模式下，Prefab用Select Dependencies选项找依赖资源的时候，会把以前旧Shader引用的贴图也给关联上，怎么刷新这种引用关系？ 在切换Material所使用的Shader时，其上的纹理引用确实是不会自动清除的（除非被覆盖）。因此，我们的建议是，在编辑Material时，如果要切换Shader，那么在切换好之后，进行一次Reset的操作（如下图所示，该操作会重置所有使用中的属性，同时去掉未使用的属性），然后再开始编辑其属性。 如果希望在不改变当前使用属性的前提下，去掉未使用的属性，那么据我们所知，只能启用Editor的Force Text模式，打开对应的.mat文件进行手动去除。 请问怎么优化下图这两者的GC Alloc？每次AddComponent 都会有这么多的开销。 不可避免，只有减少AddComponent。 物理请问Physics.Processing的占用过大一般是因为什么原因导致的？ 影响物理系统耗时的因素主要为Contacts数量（碰撞对数量）、Rigidbody API的使用情况和每帧的调用次数。 第一种情况是最为常见的引发物理模块耗时较大的原因，因此，我们在UWA性能报告中对其进行了详细的分析，如果你的报告中Contacts数量较高，切记要验证其合理性。 第二情况造成较大CPU开销的情况不多，不过如果你的项目是多角色游戏（比如MMO、MOBA、ARPG割草游戏等），那么你需要注意了。在我们优化过的一些项目中，通过Rigidbody API来移动GameObject位置（设置velocity、改变center等）确实会存在较高的性能开销。如果你的项目也有类似的做法，那么要时刻关注物理模块的开销了。 第三种情况同样也是目前引发物理模块耗时较高的原因。因为Unity引擎默认情况下，物理的更新频率是0.02s，即每20ms更新一次，所以，当你的项目比较卡时（开发过程中的项目在中低端设备上恐怕没几个是不卡的），物理模块会让你的项目更卡。举个例子，如果上一帧CPU耗时为100ms的话，那么物理模块会执行5次，从而进一步加大物理系统的耗时。这种情况下，物理模块的耗时是很有欺骗性的，你花了好长时间去研究物理的耗时，最后发现原来这个“锅”不是它的…所以，如果你的项目也遇到了这种情况，切记不要再上当了。 性能综合5.0后批处理修改 从Unity 5.0开始，Static Batching的合批机制就已经出现了变化，不再进行索引数组的合批，因此并不会使得Draw Call降低，而是会降低Batches和SetPassCall，因此从图中来看，Static Batching 开启后的统计数据是没有问题的。也因此，UWA在统计时，使用的就是Batches的数值。具体的原因可见Unity官方在论坛中的回复：https://forum.unity3d.com/threads/regression-feature-not-bug-static-dynamic-batching-combining-v-buffers-but-not-draw-calls.360143/ 尽量开启“Dynamic Batching”这个选项 详见此处 匿名函数造成GCAlloc 结论：当不使用外部变量的匿名函数时，编译器会把这个函数变成静态函数，在首次调用时初始化，之后就再也不会new新的对象。 当使用外部变量时，每次调用都会生成一个临时action变量，这个就是alloc的原因。 解决方案: 1234567891011121314public Action&lt;int, int&gt; pCall;void Start(){ pCall = CallVariable; ... // 其他初始化代码}void FixedCall(){ table.Forecah(pCall);}void CallVariable(int k, int v){ count = k + v;} 原文 渲染请教Lightmap相关的优化问题。我现在的场景中有N个GameObject共用一个Prefab，烘培Lightmap时，会生成出N个Lightmap贴图。有没有办法把这些生成的Lightmap合成一张？ 如果场景中某些物件在Lightmap纹理中占据的空间较大，但实际上并不需要较高的精度，那么可以选中该物体，并在Lighting面板的Object子面板中将其Scale in lightmap数值调低，从而可以降低其在Lightmap纹理中的空间，甚至减少Lightmap纹理的数量。 PS:为何会有N个lightmap？并没有回答能不能合并的问题。 Unity里的Shader能不能用关键字#ifdef #endif把整个pass包起来？ #ifdef 和 #endif 并不能写在Pass之外，如果有动态开关Pass的需求，可以通过Shader Lod来实现，即设置两个Level不同的SubShader分别包含1个和2个Pass，直接通过改变该Shader的局部Lod值，即可实现SubShader的切换。关于Shader Lod的细节，可见官方文档：http://docs.unity3d.com/Manual/SL-ShaderLOD.html","link":"/2017/10/30/每天一点UWA：第十三周/"},{"title":"每天一点UWA：卡通渲染笔记","text":"描边的方法基于视角的勾边 PS：这个是最简单的绘制边界的做法。计算方式就是dot(viewDir, normal)。根据 三角函数的定义值越小说明视角与模型某个点的表面法线的夹角越大，夹角为90°时说明这个triangle是视角看不到的，也就是边界了。 基于几何生成方法的描边shell method 首先在绘制结束正常的模型后，将需要描边的物体改用正面剔除再绘制一遍，在VS中将顶点沿着法线方向膨胀一定距离，然后在FS中将模型用纯色输出。 z-bias 也是绘制背面，但不膨胀，而是把背面顶点的Z值稍微向前偏移一点点，使得背面的些许部分显示出来形成描边效果。 基于图像处理的描边什么是“边缘”呢？ 边缘就是在深度或者法线上不连续的位置。 做法： 需要将深度信息和法线信息以贴图的形式传入，运用边缘检测算法去寻找这些像素。 这类方法的优点是描边的线宽一致，缺点是需要额外的法线和深度信息，当然，由于近年来流行的延迟渲染框架，法线和深度本来就是G-Buffer的一部分，因此往往不需要额外绘制法线和深度的信息。 美式卡通中的做法 美式卡通中往往倾向于使用基于图像处理的描边方法来生成均匀一致的描边效果。在《英雄联盟》中小兵和英雄的勾边效果就是用Sobel算子对深度信息进行边缘检测来获得的。 当物体较多时在进行正常绘制的阶段用stencil buffer标记出需要描边的物体，然后用一个全屏的后处理，对stencil buffer标记的像素进行边缘检测，当然这样的话，就很难给每个物体单独指定描边颜色了。 日式卡通中的做法 日式卡通中往往倾向于使用基于几何体生成的方法去描边，这类描边方法相较于另两类方法的好处在于线宽更容易为美术所控制。 在《GUILTY GEAR Xrd》中，角色的描边就是通过几何体生成的方法，结合了shell method和z-bias method，并引入了逐物体的顶点色来控制描边细节，同时也是为了保证描边粗细不会随着摄像机视距发生变化，具体来说，顶点色存储的信息包括： R通道：控制toon shading的阈值，和描边无关，和着色有关，这个我们后面描述 G通道：控制顶点根据视距膨胀的强度（这个部分具体操作我也没有完全弄清楚，希望了解的朋友来补充） B通道：控制描边的z-bias，越大则描边越不可见 A通道：控制描边的粗细 着色Cel Shading 只考虑光线 同时考虑光线和视角 Tone Based Shading Tone Based Shading的风格化是基于美术指定的色调插值，并且插值得到的色阶是连续的。首先需要由美术指定冷色调和暖色调，而最终模型的着色将根据法线和光照方向的夹角，在这两个色调的基础上进行插值，具体算法如下： 其中，Kd仍是模型自身色彩贴图，Kblue，Kyellow和alpha，beta则均是自定义的参数。 基于tone based shading绘制的球体 日式卡通中的着色 以《GUILTY GEAR Xrd》为例，它也一定程度上包含了Cel Shading和Tone Based Shading的部分思想，将色阶离散成为“明暗”两个色调，并由美术指定冷暖色调的颜色： 上述公式表示了这个卡通渲染的漫反射部分 threshold表示明暗交界的阈值，在游戏中通过顶点色的R通道来实现逐顶点的控制。 Kcool和Kwarm由美术逐物体地指定，Ksss是对模型次表面散射效果的模拟，对皮肤而言一般呈粉红色，通过美术绘制的SSS贴图来实现逐像素控制，并且只有暗部的像素才会受SSS贴图的影响。Kd是模型自身的颜色贴图。darkness表示了某个像素的明暗程度，用于确定色调的冷暖。 美术绘制的AO贴图，来实现一些边角缝隙的暗部效果。 高光的计算更简单一些：基本上与blinn-phong一样 美式卡通中的着色 Valve在其游戏《军团要塞2》将卡通渲染着色分为了view dependent term和view independent term。两部分的计算分别如下： PS：从公式中可以看到不依赖view的版本是l也就是光照向量，而依赖view的中是r，也就是反射计算。 风格化高光和阴影可变形状的高光 从日式着色的高光公式看，改变形状的关键在于H向量。这个H就是半角向量，参考Blinn-Phong公式。具体做法有： 平移，改变高光的位置： 有方向的缩放，沿着切线空间的某个轴缩放高光形状： 分割，将一块连续的高光切分成两块： 方块化，将趋于圆形的高光变成方形： 风格化阴影 类似于风格化的高光，风格化的阴影也是在标准的阴影计算流程之后，定义了一系列针对标准阴影的操作，通过这些操作，配合用户自定义的参数，便可以达到风格化阴影的效果，总的来说，共有四类操作： 膨胀/腐蚀（Inflation）：扩大或者缩小阴影范围，用参数i来控制 亮度（Brightness）：阴影区域的亮度，可以用于模拟半影区的效果，用参数b控制 柔度（Softness）：阴影边界处的柔和程度，用参数s控制 抽象度（Abstraction）：阴影形状的抽象程度，用参数alpha控制 几种操作和相应的效果 整个风格化阴影的生成是基于图像空间的，从一个已经生成的精确阴影图开始。可以分成五个阶段： 精确阴影的生成，由于是基于图像空间的，因此对精确阴影图的生成方法没有特别要求，可以是shadow volume，shadow map，ray tracing或者其他阴影生成技术，但必须要注意的是这里的阴影值一定是二值化的。 有向距离场的生成，基于图像空间的精确阴影，计算每个像素距离最近阴影边界的有向距离，这是文中算法的核心，也是后面风格化的基础，在文中给出了一种有向距离场的计算方法，当然也可以采用其他方案。 有向距离场的高斯模糊，这一步是抽象阴影生成的关键。 过滤，通过一个转移函数，将模糊后的有向距离场重新映射为阴影图。 使用过滤后的阴影进行光照计算。 PS：如果是unity的话可能要做屏幕后处理，如果是延迟渲染的的话G-buffer不确定有没有阴影信息。而且移动平台也不推荐。 结束语 除了好好学习还能有啥好说的呢╮(╯▽╰)╭","link":"/2017/11/14/每天一点UWA：卡通渲染笔记/"},{"title":"浅析Timeline结构","text":"结构 PlayableDirector Timeline PlayableGraph Graph … TrackGroup TrackGroup TrackAsset AnimationTrack PlayableTrack CinemachineTrack CustomTrack … … TimelineClips TimelineClips TimelineClips TimelineClips … PlayableAsset AnimationClip (Motion) CustomPlayableAsset CinemachineShot CustomClip … PlayableBehaviour PlayableBehaviour PlayableBehaviour CinemachineShotPlayable PlayableBehaviour … 从表中可以看出是一个树结构，在Timeline Editor中也是一目了然。核心的类就是最左边一列中列出的。 组件TimelineTimeline &amp; PlayableDirector的关系 本质是个PlayableDirector，作用顾名思义。 PlayableGraph &amp; PlayableDirector的关系 从测试情况看，一个PlayableDirector对应一个PlayableGraph 通过PlayableDirector pd = graph.GetResolver() as PlayableDirector;可以反向得到PlayableDirector，在PlayableAsset中可能会比较有用。 TrackAsset TrackAsset从视觉上看就是Timeline Editor中左边preview中的一项，每个track可以约束它所影响的 GameObject的类型，也可以设置它上面clip的类型。 从实际的操作上来看，PlayableTrack上可以放置任何继承自PlayableAsset的clip，但是其它的track上就必须放置约定类型的clip了。 如何自定义一个Track1234[TrackColor(1f, 1f, 0f)][TrackClipType(typeof(LightControlClip))][TrackBindingType(typeof(Light))]public class LightControlTrack : TrackAsset {} 从上面的代码看TrackBindingType定义了绑定的类型，TrackClipType定义了clip的类型。而TrackColor是定义了在Timeline Editor中最左边的那条很细的彩色线条。 经过测试，在自定义的TrackAsset中可以不实现CreateTrackMixer方法，但是如果要去override它，代码中不能用return Playable.Create(graph);,而是用return ScriptPlayable&lt;CustomMixer&gt;.Create(graph, inputCount);哪怕这个CustomMixer是个空类都可以，很坑爹。 PlayableAsset（Clip） 要说PlayableAsset就离不开PlayableBehaviour。在旧版本的Timeline中BasePlayableBehaviour实现了PlayableAsset和PlayableBehaviour的功能。但是因为已经被舍弃了，因此想实现既可以放到track上，又能监控状态的对象需要用PlayableAsset配合PlayableBehaviour。做法为在自定义的PlayableAsset中写： 1234public override Playable CreatePlayable(PlayableGraph graph, GameObject go){ return ScriptPlayable&lt;CustomBehaviour&gt;.Create(graph, template);} PlayableBehaviour 核心类，其定义了事件函数涵盖了自身的状态变化、graph的状态变化和PlayableDirector创建销毁时触发的事件。 PrepareFrame函数可以在每一帧对timeline中的元素进行访问和设置。可以说是在做自定义blend中不可缺失的功能。 执行顺序 目前来看应该是： CreateTrackMixer-&gt;CreatePlayable-&gt;OnPlayableCreate-&gt;OnGraphStart-&gt;OnBehaviourPause-&gt;OnBehaviourPlay-&gt;OnGraphStop-&gt;OnPlayableDestroy 这个顺序是一个clip的。当一个track上有多个clip时OnPlayableCreate、OnGraphStart、OnBehaviourPause会无序的出现，但是一定是在OnBehaviourPlay之前。 在真正的clip的执行期间，OnBehaviourPlay和OnBehaviourPause是按顺序执行的。 基本上可以判断当一个PlayableBehaviour准备好后，会先被pause。然后按照设计好的顺序执行，当开始执行时触发play，结束后再次触发pause。所以如果是要在一个clip结束后处理什么事情需要做一个判断，是否是第一次触发pause。 组件之间互相获取的方法Timeline(PlayableDirector)的获取方式 通过脚本中设置PlayableDirector类型变量获得。 如果是自定义的TrackAsset，则通过CreateTrackMixer方法的go参数获得。 1234public override Playable CreateTrackMixer(PlayableGraph graph, GameObject go, int inputCount){ PlayableDirector playableDirector = go.GetComponent&lt;PlayableDirector&gt;();} 如果是自定义的PlayableAsset，则通过 1234public override Playable CreatePlayable(PlayableGraph graph, GameObject go){ var pd = graph.GetResolver() as PlayableDirector;} PlayableBehaviour脚本中函数都是有playable参数，通过这个参数也可以获得 1234public override void OnBehaviourPlay(Playable playable, FrameData info){ PlayableDirector pd = playable.GetGraph&lt;Playable&gt;().GetResolver() as PlayableDirector;} Timeline中获取track、clip和PlayerBehaviour 从上面的代码可以看到，获取director的过程比较符合最上面的那个表里的层级关系。但是从timeline获取其它的元素会比较困难。或者说比较不符合这个层级关系。我个人认为在API的设计上是有问题的。 那么要如何通过timeline获取这些元素呢？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public PlayableDirector pd;// Use this for initializationvoid Start(){ var binding = pd.playableAsset.outputs; foreach (var item in binding) { switch (item.sourceObject.GetType().Name) { case &quot;AnimationTrack&quot;: { var at = item.sourceObject as AnimationTrack; foreach (TimelineClip clip in at.GetClips()) { Debug.Log(clip.animationClip.name + &quot;\\n&quot;); } } break; case &quot;CinemachineTrack&quot;: var item2 = item.sourceObject as CinemachineTrack; foreach (TimelineClip clip in item2.GetClips()) { CinemachineShot cs = clip.asset as CinemachineShot; Debug.Log(cs.VirtualCamera.Resolve(pd) + &quot;\\n&quot;); } break; case &quot;PlayableTrack&quot;: var pt = item.sourceObject as PlayableTrack; foreach (TimelineClip clip in pt.GetClips()) { NewPlayableAsset cs = clip.asset as NewPlayableAsset; } break; case &quot;CustomTrack&quot;: var ct = item.sourceObject as CustomTrack; foreach (TimelineClip clip in ct.GetClips()) { CustomClip cs = clip.asset as CustomClip; CustomBehaviour cb = cs.template; cb.Foo(); } break; default: break; } }} 从代码上看pd.playableAsset.outputs获得了一个IEnumerable&lt;PlayableBinding&gt;类型的集合。这个设计让人非常费解。然后遍历集合，得到item.sourceObject，这个对象就是track了。然后可以根据不同的类型转换成不同的Track。然后就和表中的结构一致了，获得clip-&gt;playableasset-&gt;playablebehaviour。 获得场景对象 Timeline中获取对象在API设计上也不合理，在unity的通用做法是在代码中定义一个Public变量或者使用[SerializeField]标记一个private的变量，然后拖拽。又或者用过GameObject.Find来获取。但是对于策划和美术来说最多的还是拖拽。 Timeline相关的脚本中可以继续使用GameObject.Find。但是如果你想用拖拽的形式需要这样定义对象： 1public ExposedReference&lt;T&gt; object; 而当你想真正使用这个变量的值的时候需要用 1object.Resolve (graph.GetResolver()); 需要说明的是在Timeline的那些脚本类里面是可以用public定义变量的，在inspector面板上也可以显示出来，但是退拽无效。 获取Track绑定的对象 目前来看似乎只有用GameObject.Fine或者直接用属性值了。","link":"/2017/11/02/2017-11-2-浅析Timeline结构/"},{"title":"每天一点UWA：动画重定向笔记","text":"基本原理 动画重定向技术主要是针对骨骼动画的方案，由骨骼来描述动作信息，用蒙皮来表示模型网格与骨骼之间的关系，从而得到模型最终的样子。 PS：这张图很形象 动画就是每一帧为模型制作一个Pose（姿势），在每帧之间的姿势可以通过差值获得。 最简单的情况：只有骨骼大小不一致的情况 此时因为骨骼在模型空间中具有一个对应的位置，因此以大人和小孩的骨骼为例，是没办法直接将大人的动画信息用在小孩的骨骼上的。 如何解决这个问题的呢？unity使用了一个参考姿势（通常情况下，会把T-Pose作为参考姿势）来计算不同大小骨骼之间的差值，然后应用到动画数据上。 a1是A骨架的参考姿势，b1是B骨架的参考姿势，动画中某一帧的姿势是a2，我们想得到的结果是b2，我们认为，a2与参考姿势a1的差异应当和b2与其对应的参考姿势b1的差异相同，即： a2 - a1 = b2 - b1 我们可以得到计算过程为： b2 = a2 - a1 + b2 = a2 + (b1 - a1) 参考姿势a1和b1都是提前得到的，因此可以进行预先计算好b1-a1的值。要知道这里的加法和减法要转换为每根骨骼的PRS计算，因此还是有不少CPU消耗的。下图给出了使用一个简单整数代替骨骼的PRS数据来模拟动画重定向的计算过程。 不同引擎的实现上可能不一样，文中提到了Havok的实现。 以上就解决了骨骼长度不一致的问题。 真实的世界：骨骼名称、数量、父子关系不一致的情况 首先在如果项目中确定使用动画重定向，那么在模型制作时就需要约定好名称、数量和关系。 骨骼名称不一致 对于CS骨骼，由于在3DS Max中通常美术只会添加不同的前缀，因此可以通过去除前缀的方式进行模糊匹配来做骨骼映射； Unity的做法细节不清楚，但是感觉会根据整个骨架的父子关系和结构来进行映射关系的计算； 而对于Bone骨骼，在没有预先定义好类似最大化骨骼这样规范的情况下，非常难通过程序来判断映射关系，可以提供可视化编辑的功能来让美术自己定义它们之间的映射关系。 骨骼数量不一致在非CS骨骼或者不重要的部分存在多余的骨骼 如果动画文件的骨架中存在多余骨骼，通常的做法是把这些骨骼忽略掉，而如果目标骨架上存在多余的骨骼，即有些骨骼原始动画中并不存在，这其实没有办法为它生成动画，只需要保证其保留在原始姿势的local space当中，即让其跟着父骨骼移动。比如身上的飘带，如果原始动画中没有，在不使用布料系统等物理方案的情况下，只能让其按照参考姿势中的样子，“僵硬”地跟随角色移动。 在重要的位置存在骨骼不一致 多图，请直接看原文。解决的办法就是使用链式映射。 链式映射要做的就是将多根骨骼组成的骨链A和另外一个骨骼中多根骨骼组成的骨链B进行映射，做到整条B骨链的样子和A骨链的样子相近。 骨骼父子关系不一致 当两套骨骼的父子关系都不一致的情况下，其实很难得到正确的映射，简单的不一致可能可以容忍，但是可以想象，把一个人形骨骼的动画映射给四足动物甚至蜘蛛这样的八脚动物，是一件非常难做的事情。 也因为这样的原因，目前大范围应用的动画重定向，基本还是在人形骨骼上，当然，用相同的算法，把四足的战马动画映射到不同的体型的战马上也是可以的。基本的原则是骨架尽量具有更多的相似性，重定向的效果也就会更好。 Unity中的重定向 Unity引擎中动画重定向的实现不是一个直观的方法，而是封装在了Humanoid类型的动画系统里面，==也就是必须是人形的骨架、==使用Humanoid才可以使用它====。 Unity没有像前文描述的基本原理那样去定义两套骨架之间的映射关系，而是自己在内部定义一套骨架模板，所有的Avatar骨骼都必须映射到这套模板上才可以由同一个Animator来驱动产生Retargeting之后的动画效果。 关于如何预览一个重定向之后的动画的效果，只能把模型放到Scene中，设置同一个Animator来观察。在动画文件的预览窗口，如果拖拽另外一个模型文件到其中，并不能预览到正确的效果。 PS：话说我以前都是这么干的。。 PS：具体操作过程参考原文或者unity文档吧，就是avatar设置那套流程。不过unity的avatar里面还能改变肌肉控制。 使用中的一些问题角色的武器或者飘带在使用Humanoid类型的动画系统之后不会移动了，或者移动的位置有了很大的偏差。 这时候可以在动画文件的属性设置里，查看Mask下的Transform选项，里面可能存在没有被勾选的骨骼。目前的做法是把Transform下的所有骨骼对象都勾选上。 角色的武器在动作中出现了乱飘的情况，与手部无法紧密地绑定在一起 由于我们最初为了方便美术制作武器的动作，把其父骨骼设置给了盆骨这样一根相对稳定的骨骼，但是经过Retargeting计算之后，由于角色身材不同产生了一些偏差导致。最终我们还是把武器骨骼的父骨骼设置为手部的骨骼，才解决了这一问题。 某些角色在重定向之后的动画中表现为脚不贴地，和地面之间有缝隙，原始动画中没有 可能是重定向算法或者是参考姿势这两个因素导致 在avatar设置中，可以看看目标骨骼在T-POSS是否正常。 性能消耗 通过前面的原理分析可以看出，即使在有预计算的情况下，与普通的动画计算，Retargeting的过程还是有一定的CPU消耗的，但是这与通常会造成CPU瓶颈的蒙皮、渲染指令提交等相比，其实消耗并不算大。 Unity与Retargeting相关的还制作了肌肉控制的功能，Humanoid形式的动画系统相对于Generic形式的动画系统虽然有一部分额外的性能消耗，但是Unity内部做了比较好的优化，差别不是很大，因此可以放心使用。 补充一些概念 CAT和CS之前都是插件形式出现的 CS主要是用来创建两足动物的比如人类 CAT不但可以创建两足动物还能创建多足动物，这就是CAT相对于CS最大的优势了。 bones是3DMAX原始的骨骼系统，这个骨骼你需要自己手动创建才行，而CAT和CS可以自动生成 skin是蒙皮系统，就是用骨骼对模型进行蒙皮后模型和骨骼产生关联，这样模型就能跟着骨骼一起运动了。 原文 https://blog.uwa4d.com/archives/AnimationRetargeting.html","link":"/2017/11/08/2017-11-8-每天一点UWA：动画重定向笔记/"},{"title":"Unity特效学习：动画","text":"Unity动画创建 选中物体后按Ctrl+6可以开启动画编辑器。 点击Add Property可以选中你要编辑的物体对象上的属性。可以看到几乎物体上所有组件的可编辑的属性都可以通过动画来编辑。这也意味着很多东西不需要编码来完成，比如你要做物体transform的变化、要做shader属性的变化等。以往可能需要进行代码编辑，在update或者某个corroutine中来使用Time.deltatime来做变化，但是现在只要通过动画编辑器就可以实现了。 有时间线的区域就是帧动画编辑区 红线是时间线 可以右键然后选项add key来实现关键帧的添加。也可以拖动红线到某个位置，测试在inspector中改变对于属性的值时会自动的添加一个key。 最下面有Dopesheet和Curves的不同模式。下图是选择了rotation后的curves，可以看到X和Z就是一条直线没有变化，因为这个动画我确实只是选择了Y轴，而Y所对应的黄色曲线有明显的变化。 Curves的编辑：和unity中其他的curves一样，右键添加key，然后key有各种的设置，总之动画效果完全是可视化编辑的。 使用3D软件制作动画 事实上unity能够制作的动画比较简单。一个真正游戏中的复杂模型的动画还是靠的3D软件来制作。 还有我不会3D软件 (｡◕ˇ∀ˇ◕) 如何修改动画软件导入的动画信息 通过FBX得到的动画信息可以通过Animation编辑器打开，但是会显示为read-only。这有有个小机器，就是我们选择FBX的动画片段后，Ctrl+D 复制一个动画出来，在打开后就可以编辑啦。 另外一个小技巧是，在运行unity时播放某个动画的时候，暂停然后选择Hierarchy面板中的对象，选择copy，然后停止unity play。在hierarchy中paste，此时会粘贴模型到hierarchy中，而且模型的动作就是copy的瞬间的动画动作。好神奇！！！ 说明 Demo的地址为https://github.com/klkucan/UnityEffect","link":"/2017/12/09/2017-12-9-Unity特效学习：动画/"},{"title":"Unity特效学习：粒子","text":"参数 只记录一些特别的参数 Prewarm: 预热，效果是直接播一个周期后的效果。也就是呈现一个周期的最终效果。目前来看应该是用到一些一开始就呈现效果的场合。 StartSpeed：这个是很常规的参数，但是当为负数时粒子方向会相反。值得留意。 Color： Gradient：梯度，更像是设定一个颜色的变化范围。但是某个粒子从创建之后颜色不会变化。 Random：粒子颜色从两个值随机取 还有梯度随机 纯粹随机：这个可以自定义N个颜色区间。 梯度编辑器很强大。注意：点击颜色条上沿添加的节点是调整alpha的，下沿是调整颜色的。藏的好深啊。 Emission: Rate over Distance:按照移动距离发射粒子。不动的情况下就不发射。可以用来模拟移动的汽车的尾气。动起来才有，不动就没有了。必须配合world模式。 Shape: 发射器可以选择不同的形状。当选择了Emit from为Base shell，并且将start speed设置为0时粒子就会出现在外轮廓的固定位置。可以呈现比较特殊的粒子效果。尤其是圆形或者柱状时。 mesh:想做特殊形状的粒子需要这个，很特别，看下图。 Velocity over lifetime: 简单来说就是在生命周期中给与一个3D方向的移动速度。比如我们只给x一个5的值，那么看上就是有粒子北风吹走的感觉了。目前想到的就是风吹的效果。 Limit Velocity over lifetime: 速度的衰减。speed为最终速度、dampen为删减的速度。基本上的公式应该是speed = start speed - dampen * time。只给可以配合Velocity over lifetime实现一个更为真实的风吹效果。 Rotation over left：这个主要是旋转粒子，材质球选择一个具体的纹理图后比较明显。现在看效果比较适合做技能特效。 External Force：配合风场更适合做各种风的效果。具体设置看Demo。 Sub Emitters:自发射器可以实现多个粒子的配合效果，最常用的就是烟花。 birth：主粒子产生时产生子粒子 collision：主粒子碰撞时产生子粒子 death：主粒子消失时产生子粒子 在death粒子如果想做出一次性的烟花效果需要注意：首先lifetime要短，其次总离子数量要小于rate over time，这样才能实现一次性发射所有的粒子。具体设置见demo。 Texture Sheet Animation：粒子序列帧动画。需要在材质球中配合特别的序列动画纹理图。最常见的就是做火焰。这个功能极其强大。 Tiles：动画纹理中动画的横轴纵轴的数量。我demo中的图是8x8的，所以这里也要设置成8x8。 说明 Demo的地址为https://github.com/klkucan/UnityEffect","link":"/2017/12/09/2017-12-9-Unity特效学习：粒子/"},{"title":"《Unity預計算即時GI》笔记：一、基本概念与一些设置","text":"说明 这篇文章是对《Unity預計算即時GI》这个系列文章的笔记。 基本概念 在Unity裡，可以用兩種不同的技術來計算全域光照GI或光源反射，就是烘焙全域光照(Baked GI)和預計算即時全域光照(Precomputed Realtime GI)。 當啟用PRGI時，一個光照預計算就是用來計算靜態幾何物件周圍光的反射，並存成資料給Runtime執行使用的一個過程。這個過程減少了原本必須在Runtime執行時的光照計算數量，讓專案得以在保持FPS的穩定之下還能計算光的反射。 与Baked GI有什么不同 先看下5.X中Baked GI的定义 當啟用烘焙GI(Baked GI)時，預計算的過程會計算並產生傳統的光照貼圖(Lightmap)，這些貼圖會以資源(Assets)的形式存在專案中，而且無法再Runtime執行時更改。PRGI並非用一樣的方法產生光照貼圖，相反的，PRGI算好的結果會被存成一個光照資料檔(Lighting Data Asset)，這個資料檔存的資料能讓專案在Runtime執行時能即時產生一組低解析度的光照圖。 从本质上看就是PRGI还是实时计算的，只不过光的反射路径已经提前计算了，因此在实际的光照计算时会减少计算量，进而提升效率。而Baked GI仍旧是传统的light map的机制。 PRGI的相关设置Realtime Resolution的设置 设置的依据 Realtime Resolution的值可以由你的遊戲規模來制定，例如，是否你的場景是一個小小的，卻有豐富光照變化的室內環境? 在這種情況下，高一點的值比如2-3，可以捕捉更詳細或”高頻”的光照。 如果你的場景是一個世界規模較大的大型戶外環境。可能有著幾千或幾百個物件表面幾乎不會去修改光照反射顏色。在這樣的情況下，把適合計算複雜室內場景的設定用在有大量相同特徵的室外環境是很浪費的。我們會浪費寶貴的CPU時間和記憶體儲存/更新那些對整體外觀貢獻不大的光照貼圖。為了教學目的，我們會提高PRGI期間必須考慮貼圖像素的量，這會對預計算的時間造成很大的影響。 在場景裡有大物件的室外環境情況下，合適的設定可以設在0.5-1之間，針對地形可以設定0.1-0.5之間。 場景與Realtime Resolution值對照表 室內:2-3 像素/單位 戶外:0.5-1 像素/單位 地形:0.1-0.5 像素/單位 与Baked GI在数值上的差异 Unity PRGI所需要的Realtime Resolution值比傳統光照貼圖密度要小好幾個等級，這是因為我們只從這些光照圖裡擷取間接光源資料，這些資料通常解析度都很低。所以使用PRGI時，清晰的陰影通常都是即時運算而非從高解析度的光照圖來提供。 在這裡使用傳統光照慣用的值，例如:30 texels，可能會導致預計算失敗或無法計算。 关于Realtime Resolution的使用 當設定場景即時解析度時，Unity會指定給場景內的靜態物件。帶有Mesh Renderer且標有靜態光照標籤(Lightmap Static)的物件，會引用這個值一直到它被外力修改。 除了幫場景加上解析度設定外，我們還能針對每個物件調整光照貼圖的解析度，在需要高解析度來提供更高真實感的情況下，我們可以選擇性的提高這個值。通常是將場上最多的物件解析度設為預設值，然後手動調高需要更多照明細節物件的值。 最后放一个不同数值对光照图的影响，可以看出数值越小单个光照图越小，数值 大时导致光照贴图单位面积中像素越多，从而使得对应的光照图变大。（个人理解） runtime resolution 0.5 runtime resolution 1 runtime resolution 2 物件的设置 需要设置为static Light面板设置 auto与否个人认为不重要。只不过在auto模式下如果已经在某些参数的情况下生成过一次后续改动参数再改回来不需要再次生成。这个东西是否在非auto模式下奏效没试过。 光照探测 what &amp; why 我們已經理解場景裡的圖表數量對預計算時間的影響，這樣我們就能從預計算流程裡想辦法降低一些物件計算來讓光照效能大躍進，同時也會減少圖表產生的數量．取而代之的，我們可以對這些物件做光照探測(Probe Lighting)處理，它是一種讓物件接收場景間接照明的好方法，雖然被光照探針指定的物件無法計算場景的光照反射，但通常影響不大。這種方法非常適合用在場景裡的小物件，因為小物件對光照反射計算幾乎沒什麼影響。 光照探測技術是一個能在遊戲裡讓即時光照更逼真的快速演算法，通常會用在處理遊戲世界的人物角色或是動態物件的光照，它的優點在於Runtime處理效能佳而且還能預先計算好。 弊端 使用光照探測是有些限制的，其中一個限制是在不提高探針數量的前提下很難在球型範圍上表現出高頻或斑駁的光照，但精度和消耗成本成正比，代表在效能的前提下，我們必須限制較低階的球諧函數。 實際上一個3D座標只能用一個球體來紀錄照明資料，所以光照探測不適合用在有大量光照投射在大物件的狀況。另外一個限制是當用球諧函數在一個球體上編碼時，通常不擅於處理用有廣大平面的物件或帶有很深的凹洞的物件．如果你正計畫要把光照探測技術用在大型物件上，Unity有提供另一個光照探測代理體(Light Probe Proxy Volumes,LPPV)的技術可以參考手冊說明。 适用于 儘管有這些限制，光照探測還是很適合和符合條件的小物件一起搭配使用，產生成本低廉效果卓越的結果。","link":"/2017/02/22/2017-2-22-《Unity預計算即時GI》笔记：一、基本概念与一些设置/"},{"title":"游戏设计模式读书笔记：双缓冲","text":"第三篇：序列模型 双缓冲模式算是书中第三篇：序列模型中的一个，它与游戏循环和更新方法组成了第三篇。后两者可以说是在我做Unity中最常用到的，而且也是游戏引擎本身已经实现了的。谨以下文来说明下序列模型部分的重要性。 电子游戏之所有有趣，很大程度上归功于它们会将我们带到别的地方。 几分钟后（或者，诚实点，可能会更长），我们活在一个虚拟的世界。 创造那样的世界是游戏程序员至上的欢愉。 大多数游戏世界都有的特性是时间——虚构世界以其特定的节奏运行。 作为世界的架构师，我们必须发明时间，制造推动游戏时间运作的齿轮。 这本篇的模式是建构这些的工具。 游戏循环是时钟的中心轴。 对象通过更新方法来聆听时钟的滴答声。 我们可以用双缓冲模式存储快照来隐藏计算机的顺序执行，这样看起来世界可以进行同步更新。 双缓冲一个典型的例子 这个例子非常经典，就是渲染时候的双缓冲。只有当一帧的色值数据完全计算出来后，才能在屏幕上展示出来，如果在计算的同时就开始渲染，那么屏幕只会出现一部分的色彩。所以我们在屏幕看到的色彩值其实往往是GPU算出的上一帧的数据。 使用场景 我们需要维护一些被逐步改变着的状态量。 同个状态可能会在其被修改的同时被访问到。 我们希望避免访问状态的代码能看到具体的工作过程。 我们希望能够读取状态但不希望等到写入操作的完成。 我对双缓冲的理解 说白了，双缓冲是为了维护完整性。它展示给外界的永远是一个完整的，已经准备好被使用的内容。在其内部，有一个缓冲是用于写入数据的，写入的过程可能是缓慢的，但是没关系，另一个缓冲已经做好了被使用的准备，外界读取的是这个已经写好的缓冲。 当写入完成时，两个缓冲互换，刚刚写完的这个缓冲变为准备被读取的一个，而被读取的缓冲开始作为写入缓冲使用。 设计决策 缓冲区如何交互？ 在文中作者使用的是C++，因此交换只不过是一个指针重定向的过程。 如果不能指针重定向，就要考虑数据拷贝了。 C#中一个集合对象表现出来的也是一个指针（引用），可以直接做重定向。 缓冲的粒度 书中提到两个粒度，一个是缓冲区是单个整体，也就是渲染的时候一个图像的内容就在一个缓冲区中。 另一种情况就是多个对象中都存在一个缓冲数据。","link":"/2017/02/25/2017-2-25-游戏设计模式读书笔记：双缓冲/"},{"title":"游戏设计模式读书笔记：观察者模式与事件队列","text":"观察者模式定义 定义：在此种模式中，一个目标对象管理所有相依于它的观察者对象，并且在它本身的状态改变时主动发出通知。这通常透过呼叫各观察者所提供的方法来实现。此种模式通常被用来实时事件处理系统。 看图 模式的理解 观察者模式由来已久，其目的就是为了解耦。观察对象保存观察者的链接，使得观察者与被观察者解耦。这一点与C#中的事件刚好相反。 传统的观察者模式也有其弊端。比如书中提到的使用链表作为观察者集合时，如果删除某个观察者需要遍历。并且每个观察者只有一个next指针的情况，这就使得它只能观察一个对象。当然作者也给出来解决的办法，就是使用链表节点池来解决一个观察者注册多个被观察者的问题。不过在C#的事件系统中这个是不需要的。 当出现被观察者或者观察者销毁时需要额外的注意。一个被观察者销毁产生的问题比较小，因为最多就是不发送消息了。而如果一个观察者销毁但是被观察者还不知道，那么被观察者会发送一个消息给空指针，这样问题就大。 在C#中这个问题也是一样的，当要dispose的时候，需要使用-=操作来去掉观察引用。 观察则模式和事件的区别 长久以来我都认为C#中的事件就是观察者模式，当然实际上有所差别。因为按照经典的设计模式来说观察者是需要类的支持的，当你需要让某个对象可被观察，并为此创建几个观察者时你需要执行诸如继承这样的典型的面向对象编程，需要做一大摊子的事情。但是，很多情况下我们只是希望一个类中的某个对象被观察，也就是一个对象中可能发生多个事件。这也是C#中事件系统所作的事情，在C#中我们观察的是一个对象，而不是一个事情。（参考原文的旁白说明。） 在unity中的使用 这个其实没啥说的，就按照标准的C#程序中使用事件的方式即可，只不过我比较习惯用Action或者Func来替代delegate+event。 事件队列 对于事件队列，不要只认为是事件，它也包含消息或者请求等等。按照我的理解来说就是一个具体要做的事情。 为何要把事件队列和观察者模式写到一起，因为在我看了它们的作用是一样的，就是为了解耦消息的发送者（被观察者）和接受者（观察者）。事件队列在复杂度上要高于观察者模式，这个是因为事件队列在时间上做了进一步的解耦。 怎么理解时间上的解耦？事件队列在接收到一个事件后，何时执行是不确定的。考虑到事件会带上发生时的数据，那么在执行时是不需要依赖时间的。 时间的解耦有个弊端，就是如果你需要实时反馈，那么这个做不到。 还有一个需要注意的是不要形成消息和处理者的循环。 消息汇总与合并 书中作者提到了一个声音播放系统，当队列中存在多个相同音频的请求时需要进行合并。当然这个是因为同一音频短时间内容播放会出现音爆。不过这个也提醒了我们，如果在实际的业务中有这样需要合并的时候，在每个update（也就是要开始执行某个事件时）中要进行合并。 如何实现队列 作者提到了循环缓冲区的问题，通过使用一个数组来实现消息队列，这样可以有效的减少内存的使用。不过我认为弊端就不好定一个数组的大小，如果过小可能来不及做循环，而如果太大一样存在内存的浪费。 从C#角度看，这个队列可以Queue来实现，可以说是完美契合的。 设计决策 入队的是什么： 事件：如果是事件需要考虑多监听器的情况下让监听器做过滤。其实这个就是一个观察者模式。在这里就有点像异步观察者模式。 消息：一般消息都是一对一的，这个其实也是异步的意思。 谁能从队列里读取： 事件的话轮到了执行就好，有没有监听者无所谓。如果是一个固定类型的消息，那么可能就是一个具体的业务的方法来获取队列中的消息了。 谁能写入队列： 如果只有一个写入者，那么这个东西在时间上会执行的很快，和同步的观察者模式差不多。 如果是多个写入者，需要将发送方本身的引用加入到事件的数据当中。就像我们在C#中开发基于UI的程序一样，如果你有经验会知道每个事件处理函数中第一个参数总是某个具体的控件。 队列中对象的生命周期 在我看来应该就是事件出队列时就是其周期的结束，当然因为GC的问题这个对象也许并不会立刻被销毁。 书中提到了可以将对象的所有权进行转移，到具体的执行方去。也可以让队列一直拥有它。这个方面我还没有觉得有这个必要保留对象，也许是没有遇到一个典型的例子吧。","link":"/2017/02/25/2017-2-25-游戏设计模式读书笔记：观察者模式与事件队列/"},{"title":"AssetBundle学习笔记：2、压缩","text":"格式 谈压缩就要谈到格式，unity目前在制作AssetBundle时默认就是压缩的，当然也可以设置为不压缩，但是显然不科学尤其是在移动端的开发上。 LZMA：这个是一个序列化数据文件流，也是AssetBundle的默认压缩格式。LZMA提供最佳的压缩比，但是在使用的时候需要完全解压后才能使用，因此加载时需要的事件比较多。 LZ4：5.3以后才加入的一种压缩格式，被unity自己大量使用。这是一种基于块的压缩方式，当一个对象从LZ4压缩的AssetBundle中加载时，会按照需要解压部分的块。这样的好处在于快速的加载对象，后面会提到一个最佳实践。当然，按照这个原理，你也可以想象如果一个LZ4AssetBundle中只包含了一个GameObject，那么也不存在什么按需加载了。当使用AssetBundle.LoadFromFile加载LZ4格式的文件时，其实不会将问价加载到内容，而是加载AssetBundle的Header。 AssetBundle也可以选择不压缩，这样体积最大但是加载最快。 缓冲被压缩的AssetBundle WWW.LoadFromCacheOrDownload方法下载并缓冲AssetBundle到磁盘，5.3以后缓冲的文件可以是LZ4格式的压缩文件了，这直接导致了一个很2的事情。就是当你下载了LZMA格式的AssetBundle后，每当你通过socket下载到足够的数据后，unity就在后台悄悄的解压然后重新压缩为LZ4格式的文件直到下载结束，这个压缩发生在下载流（download streaming）中。当用到缓冲中的数据时，就会按照解压LZ4的套路走了。也就是按需按块解压。 缓冲压缩是默认的，然后可以通过 Caching.compressionEnabled属性来控制。会影响到包缓冲到磁盘和保存在内存中。 指导方针，满满的干货 如果是将AssetBundle打包到游戏中，也就是AssetBundle跟着安装包走的话，推荐LZ4+AssetBundle.LoadFromFileAsync，既有压缩省空间，又有最快的加载性能可能性，给你读取内存buff的快感。 如果是网络下载可下载内容（DLC），则使用LZMA+LoadFromCacheOrDownload/WebRequest，这样可以获得最好的压缩比。缓存到本地后使用AssetBundle.LoadFromFile加载。这里需要注意，如果是一些需要持久化的内容，是需要实实在在的保存到本地的，否则进程结束后内存中的cache会清除。 如果是加密的AssetBundle，则使用LZ4+LoadFromMemoryAsync。其实也可以理解，毕竟需要加载到内容后进行解密。而且这个差不多是LoadFromMemory[Async]唯一的使用场景。 当使用自定义压缩时，请使用不压缩来创建AssetBundle，然后自己解压后使用AssetBundle.LoadFromFileAsync来加载。 为了节约内存，如果是不含prefab的AssetBundle，比如是texture的。最好用LoadFromCacheOrDownload，前提是通过网络获取，因为只有少量的序列化文件在内存。如果是保护prefab比较多的，用new WWW可能占用的内存会比序列化文件的都少。 总之，AssetBundle的使用需要进行灵活的应用。","link":"/2017/03/20/2017-3-14-AssetBundle学习笔记：2、压缩/"},{"title":"游戏设计模式读书笔记：原型模式","text":"原型模式定义 定义：原型模式是创建型模式的一种,其特点在于通过“复制”一个已经存在的实例来返回新的实例,而不是新建实例。被复制的实例就是我们所称的“原型”，这个原型是可定制的。原型模式多用于创建复杂的或者耗时的实例，因为这种情况下，复制一个已经存在的实例使程序运行更高效；或者创建值相等，只是命名不一样的同类数据。 看图 模式的理解 当需要快速并且尽可能少的占用内存的情况下，创建一个新的对象可以采用这个模式。前提是浅拷贝，因为深拷贝就是创建一个新的对象。 如果在必须是深拷贝，那么这个模式只是在使用上有便利，或者说代码上更优雅而已。 在扩展一个基础类型时，可以使用原型模式。但是C#中如果是结构体还好说，如果是个类完全可以用继承。 根据定义这个不是新建一个实例，那么本质上是浅拷贝。至于到底是深拷贝还是浅拷贝我认为可以根据自己的需要去做。 Unity中的实现 其实在C#中已经实现了ICloneable接口，直接继承接口，然后实现方法即可。而且.net还提供了MemberwiseClone方法，直接实现了浅拷贝。 要做深拷贝就是new一个对象返回即可。 吐槽 这个文章不知所谓。作者自己都不喜欢这个模式。或者说他用这个模式的方向应该不是这个模式原本希望人们使用的方式吧。","link":"/2017/03/16/2017-3-16-游戏设计模式读书笔记：原型模式/"},{"title":"我所了解的法线贴图","text":"两篇文章 本文大多数内容来自这两篇文章，看完后基本明白了法线贴图的种种细节。 凹凸映射 写给笨人的法线贴图原理 一些基本的概念1.法线贴图的定义顾名思义，法线贴图保存的是法线的信息贴图。 2.用来干什么用来进行凹凸映射。 凹凸映射的目的是使用一张纹理来修改模型表面的法线，以便为模型提供更多的细节。这种方法不会真的改变模型的顶点位置，只是让模型看起来好像是“凹凸不平”的，但可以从模型的轮廓处看出“破绽”。 有两种主要的方法可以用来进行凹凸映射：一种方法是使用一张高度纹理(height map)来模拟表面位移(displacement)，然后得到一个修改后的法线值，这种方法也被称为高度映射(height mapping);另一种方法则是使用一张法线纹理(normal map)来直接存储表面法线，这种方法又被称为法线映射(normal mapping)。尽管我们常常将凹凸映射和法线映射当成是相同的技术，但要知道它们之间的不同。 3.种类 世界空间下的法线纹理 模型空间下的法线纹理 切线空间下的法线纹理 对比不同的法线贴图 首先按照不同的坐标系得到了不同类型的法线贴图。模型顶点的法线根据所处坐标系的不同，在成图后表现也是不同的。以模型法线贴图和切线法线贴图为例： 上图 左边: 模型空间下的法线纹理 右边: 切线空间下的法线纹理 不同的颜色是因为法线作为一个Vector3类型的需要转换到2D的颜色，而通常来说我们可以把颜色的RGB看成一个坐标系，这样法线就对应了一个RGB颜色。但是法线的范围是[-1,1]，而颜色是没有负值的，因此有以下的转换过程。 法线纹理存储的是表面的法线方向。由于法线方向的分量范围在[-1, 1]，而像素的分量范围为[0, 1]，因此我们需要做一个映射，通常使用的映射就是：pixel=(normal + 1) / 2这就要求，我们在Shader中对法线纹理进行纹理采样后，还需要对结果进行一次反映射的过程，以得到原先的法线方向。反映射的过程实际就是使用上面映射函数的逆函数：normal=pixel × 2 - 1 1.world space normal map 一旦从贴图里解压出来后,就可以直接用了,效率很高.但是有个缺点,这个world space normal 是固定了,如果物体没有保持原来的方向和位置,那原来生成的normal map就作废了。 世界坐标下的顶点的法线是现成的，因此好用。不过如果进入模型在U3D里面进行了位置或者方向的转换，那么在没有转换矩阵的情况下，法线信息就是错误的，也就无法使用了。进一步思考如果场景中存在大量的静态模型，可以考虑用这个。 2.object space normal map 对于模型顶点自带的法线，它们是定义在模型空间中的，因此一种直接的想法就是将修改后的模型空间中的表面法线存储在一张纹理中，这种纹理被称为模型空间的法线纹理(object-space normal map)。 对象空间的法线贴图，这个贴图中记录的法线信息是基于模型空间的，因此数值是相对的，这样模型在场景中是可以位移和旋转的，只要在计算的时候乘上对应的矩阵即可。而且从上面的图里可以看到贴图是彩色的，因为模型上的顶点法线在这个空间中是朝各个方向的。 对象空间的法线贴图比起世界空间的在使用了已经有了很大的进步，不过它仍旧有自己的局限性，就是这样的贴图还是依赖于模型本身。从其定义也可以看出来，它也是一种“绝对位置”。如果模型发生了形变，则这个贴图的信息就是错误的。从目前来看，我只能想到模型在场景中存在动画这个问题。 3.tangent space normal map 对于模型的每一个顶点，它都有一个属于自己的切线空间，这个切线空间的原点就是该顶点本身，而z轴是顶点的法线方向(n),x轴是顶点的切线方向(t)，而y轴可由法线和切线叉积而得，也被称为副切线(bitangent, b)或副法线。这种纹理被称为是切线空间的法线纹理(tangent-space normal map)。 定义很好理解，从本质上讲切线空间的法线贴图解决了模型变形的问题。因为在另一个模型上的顶点的切线空间坐标系里面，法线贴图中的信息是可以使用的，它不依赖于模型本身、也不依赖于模型所处的坐标系。 4.切线空间下的法线贴图如何生成 以3DMAX为例，法线贴图需要高模和低模配合，具体过程不说了，网上大把的视频。 重点是法线贴图的生成需要高模和低模，因为没有高模就不知道法线方向,没有低模,就不知道高模上某点的法线对应于低模上哪个点。 下面才是重点，因为多个高模的面使用了同一个低模的面，因此在生成法线贴图时，高模不能使用自己的tangent space，而是使用低模的tangent space。这样一些高模上的点的法线与低模面上的法线出现了不一致，你可以想象低模上的某个面上的法线指向一个方向，但是对应了几个高模的点，可能一些点的法线与低模面的法线方向一样，那么很好，完美融入低模的切线空间，颜色呈现出淡蓝色。但是其它那些和低模面法线不一致的点的法线就产生了夹角，就造成了在切线法线贴图上那些不是[0.5,0.5,1]色值的点。 低模上的这个tangent space，也必须与高模上的坐标系tangent space。因为低模上的一个面,可能对应了高模上的几个面(精度高)，按照新方法每个面都有一个局部坐标系，那对于低模上的每个面，高模因为存在好几个面，就会出现好几个局部坐标系，这肯定是不行的。所以高模所用的tangent space，就是低模上的。生成法线贴图，必定会确认高模上哪些面都对应低模上的哪个面，然后高模上的这几个面的法线，都会转换为低模这个面上所构建的tangent space的坐标。这样，当低模变形时，即三角面变化时，它的tangent space也会跟着变化，保存在贴图里的法线乘以低模这个面的tangent space到外部坐标系的转换矩阵即可得到外部坐标。顺便再提一点，高模保存的这个法线，是高模上object space里的法线。 对于上述的内容，这张图做了很好的诠释。 如何将高模的法线贴图用在低模上 对于object space normal map，低模的object space坐标系与高模中的object space坐标系是重合的。所以不需要构建,所以低模上某点才能直接用高模的法线替换自己的法线。","link":"/2017/03/16/2017-3-20-我所了解的法线贴图/"},{"title":"关于AssetBundle解压的讨论结果","text":"一切的起源在于这篇文章，在文中对AssetBundle的加载进行了详细的描述，但是疑问也由此而生。以下是我在UWA讨论群的提问： 在讲WWW的时候有这样一段话【解压后的内容，通常为原Bundle文件的4~5倍大小，纹理资源比例可能更大】，在我理解就是www这样的方式获取到的资源（压缩形式的）会被解压缩，并放置到webstream中。而在【AssetBundle加载进阶】部分的【前者劣势】部分，又有【每次加载都涉及到解压操作】，请问这个【加载】指的是什么？是www.assetBundle还是AssetBundle.Load？还有【解压缩】是指的什么？不是在WWW的时候已经解压缩了吗？ 张鑫大神是这样回答的 是这样的，我们所说的AssetBundle【加载】指的是New WWW（或其他加载AB的API）和www.assetbundle的统称，而真正的【解压】过程，是在New WWW进行的。同时，需要说明的是，这个是5.3版本之前Unity对于AssetBundle的处理方式，5.3版本后，由于Unity新增了LZ4压缩方式，所以如果AssetBundle在制作时已经是LZ4格式的，那么在加载时就已经不会在进行解压了。 身为一个程序猿一定要弄清楚才行，所以有了另一个疑问 那么【每次加载都涉及到解压操作】是不是可以这样理解：对于new WWW实际是解压到webstream。而如果是用的LoadFromCacheOrDownload，那么资源是在磁盘的，所以在调用www.assetbundle时才做解压。或者正如你说的只要是加载AB的API，都会有一个解压过程。那么有个问题，如果使用直接获取AssetBundle的那些API，解压过程是怎样的呢？CreateFromFile是在调用assetbundle.load的时候从磁盘解压，CreateFromMemory是直接解压到webstream？还有个问题，对于WebStream来说，同一个www对象多次调用www.assetbundle方法时，得到了栈上的多个变量，但是这些变量都指向同一个WebStream中的对象吗？ 其实在这里我犯了一个错误，就是对于资源最终放到磁盘上的AB来说在调用LoadFromCacheOrDownload和LoadFromFile（5.3之前是CreateFromFile）方法的过程中就已经解压缩了，LoadFromCacheOrDownload是上面文章中说明了我自己看漏了，但是LoadFromFile是有一个演进的过程的。 在5.3之前，如果需要解压，都在四个API（New WWW、CreateFromFile、LoadFromMemory、LoadFromCache等）中进行，而不是在后面执行 CreateFromFile在4.x的API，只能加载非压缩的AB，而在5.0以后，对应的是LoadFromFile，5.3之后可以加载任何压缩格式的AB了 至此可以总结一点就是解压缩发生在New WWW、CreateFromFile、LoadFromMemory、LoadFromCache函数调用过程中。 至于张鑫大神提到的LZ4不要解压缩这个事情，从文档上看LZ4还是需要解压缩的，只不过是基于块的，也就是说当你从LZ4文件中加载一个object的时候，只会解压缩这个object对应的压缩块，这个当然效率就高了很多。但是这句我甚是不解，如果一个LZ4文件压缩了一个很大的对象且只有这个对象，解压的时候难道不要时间？？在群里问完大神在来补充吧。 This occurs on-the-fly, meaning there are no wait times for the entire bundle to be decompressed before use. 第二天的更新： 看了文档也和群里讨论了一下，应该还是我理解上有误。所谓5.3版本后，由于Unity新增了LZ4压缩方式，所以如果AssetBundle在制作时已经是LZ4格式的，那么在加载时就已经不会在进行解压了。的前提是在AB的基础上的，5.3以后的AB压缩格式3种：LZMA、LZ4和不压缩（Uncompressed Format，原文如此），LZMA是默认的AB压缩格式，unity在使用socket下载LZMA格式的文件时，一边下载，一边解压，并且一边压缩为LZ4。和大家讨论了下认为应该是考虑到传输的流量成本、节约内存和磁盘的空间，所以解压后再压缩为LZ4。一是因为LZMA压缩比高，适合传输，但是解压后会占用内容和磁盘空间比较大，而且是整体解压并且过程较慢，不适合用时在解压。所以解压后使用LZ4压缩一下节约空间，而且LZ4前面也说了是按需逐块解压的速度比较快，因此适合已经是内存中或者本地的解压。从这个角度说，如果直接AB压成LZ4就可以直接在需要的时候解压了，没有了解压再压缩的过程。 最后还是要刷这个才行。","link":"/2017/03/05/2017-3-5-关于AssetBundle解压的讨论结果/"},{"title":"SendMessage测试","text":"5.5.2中没有了以前那种参数是对象的SendMessage方法，WTF. obj.SendMessage(“Foo”, 1, SendMessageOptions.DontRequireReceiver);如果设置了DontRequireReceiver，那么找不到Foo方法不会报错，如果没有写这个参数默认是RequireReceiver，则报错。 如果Foo的参数不对，会提示MissingMethodException: The best match for method Foo has some invalid parameter. 1234public void Foo(string s){ Debug.Log(s);} 如果Foo是没有参数的，SendMessage有参数也没关系。 总之最好指定的函数是存在的，参数是匹配的。","link":"/2017/03/08/2017-3-8-SendMessage测试/"},{"title":"AssetBundle学习笔记：3、AssetBundle内部结构","text":"本质 AssetBundle在本质上是一些被分组保存在一个序列化文件中的对象。被部署为一个数据文件，这些文件按照普通包和场景包的不同，在结构上有些差别。 Normal AssetBundle structure 对于第一个块中的main serialized file应该是可以通过AssetBundle.mainAsset获取的，而谁是mainAsset呢？在build的时候第一个放置进去的资源就是mainAsset，所以可以采用将AssetBundle中所有的资源的名称写入一个文件，然后文件作为mainAsset来使用。具体代码参考引用的第二部分 Streamed scene AssetBundle structure 虽然结构不同，但是是一样的压缩方式。 AssetBundle compression LZ4（ chunk-based compression）将原始数据分隔后独立压缩，在解压的时候是随机读取的开销很小。而LZMA(stream-based compression)提供了高压缩比，但是解压时必须按照顺序读取。 总结: 这篇的内容基本都是图，但是从normal bundle和Streamed scene bundle的区分可以看出对于一般的资源和场景资源，unity在AssetBundle中是有很大差别的。一般的资源中，可以将每个不同的类型的资源打包成一个AssetBundle(当然我们也可以将多个资源打包到一个AssetBundle中)。而在场景的AssetBundle中，主场景序列化文件是预加载的数据(场景中对象相关的InstanceID，对于的prefab对象等)、其它场景中使用的AssetBundle资源和对象。而后面的内容包含共享的数据，光照数据和其它一些资源文件。 通过使用unity官方的AssetBundleBrowser可以看到不同类型的资源打包所带的资源文件。在使用这个工具打包的时候场景资源会默认包含光照的信息。","link":"/2017/04/04/2017-4-4-AssetBundle学习笔记：3、AssetBundle内部结构/"},{"title":"写点东西，证明我还在更新","text":"最近的一些情况 很久没有更新博客了，从4月份开始为了项目赶进度开始了996模式，实在没有什么时间写东西。这个是公司也是我自己做的第一个VR旅游项目，可以说从零开始吧，毕竟与游戏开发不一样，期间学到了多东西，也走了不少的弯路。 在项目期间很神奇的看了一大半冯乐乐写的《Shader入门精要》，在这给这本书打打广告，这是一本很适合入门的Shader书籍，而且紧密的结合了Unity5。对于我这样想要编写shader的人来说是很好的入门。 后续的计划 本来今年的计划是搞定AssetBundle和热更新，然后看完《游戏编程模式》这本书。之前的blog中也陆续写了一些读书笔记，其实在写AssetBundle的最后一篇时的最后一个link指向了AssetBundle的一个官方实践教程，是必须读的文章。我基本已经看完了，后续会写读书笔记，现在年纪大了不写点东西感觉自己记不住了。XD 另外就是上面提到的项目完成后会写一点总结。 还有就是上半年最大的收获，学会了写unity shader。以前一些特效总要找特效的同事做，而且有时候用了一些特效发现很影响性能但是不知为何，在学了shader之后很多事情知道是怎么回事了，虽然PBR这样的shader还是不能完全写出来，但是基本的写法和理论都已经知道了，遇到问题的时候不会再一脸懵逼。这算是上半年最大的收获吧。当然，读书笔记必不可少，等我刷第二遍书的时候会开始写。 下半年的项目计划已经出来了，做一个VR教育的产品，涉及到AssetBundle和热更新，好吧真是太巧了，刚好在项目中要好好学学热更新了。","link":"/2017/06/04/2017-6-4-写点东西，证明我还在更新/"},{"title":"AssetBundle学习笔记：Resources文件夹","text":"Resources文件夹 这个章节内容不多，但是也很有用。我们可以从这个章节中学习如何更合理的使用它。 Resources系统的最佳实践 不要使用它 是的，不要使用它。因为它有以下问题： 使用 Resources 文件夹会让内存颗粒度管理变得更困难 不正确的使用 Resources 文件夹会增加应用启动时间（因为要创建上一章讲的映射图）和包的大小，随着在 Resources 文件中的文件增加，管理这些文件会变得很困难。 Resources系统降低了项目自定义分发内容到具体平台的能力，消除了增量更新的可能。AssetBundle 变体是 Unity 用来在不同设备上调整内容的基础。 正确的使用资源文件夹 下面两种情况 Resources 系统很有用处： 1.因为 Resources 系统很容易使用，它很适合是在快速原型制作和试验。但是当项目要转成产品时，强烈建议不要使用 Resources 文件夹. 2.Resources 文件夹对一些满足如下条件的案例很有用： 存储在 Resources 文件夹下的内容不要很大的内存 存储在 Resources 文件夹下的内容在整个项目周期都有用 内容基本不用升级 在各平台都一样的 序列化资源 一个工程中可能包含了多个名叫Resources的文件夹，所有这些文件夹下的对象和资材会在build的时候全部序列化到一个文件中，这个文件可以理解为一个特殊的AssetBundle。想来这就是为何不利于增量更新的原因了。 AssetBundle包中索引信息里面包括了处理对象名字到对应的文件 GUID 和本地ID 的查找树。它也用来定位对象在序列化文件中的偏移位置。 用于查找的数据结构是平衡搜索树[1]（在大多数平台上），它的构建时间增长到了 O(nLog(N)), 其中 N 是在查找树内的对象的个数。这个增长也使 Resources 文件夹内的对象增加时，索引的加载时间会比线性增长时间长。 说了这么多就是告诉大家，应用启动时初始化resources文件夹（按照上一章说的应该是建立实例ID的映射图）这个事是不可避免的，当resources文件夹中内容太多时会严重影响启动速度。","link":"/2017/07/23/2017-7-23-AssetBundle学习笔记：Resources文件夹/"},{"title":"Unity返回Value的协程","text":"起因 其实一直以来就有个想法，希望能让unity中的coroutine返回一个具体的数值，比如int，比如string或者一个GameObject。最近也查了些资料，然后总结一下这个功能如何实现。 回调函数实现 这个算是一个取巧的办法，在调用协程时传递一个回调函数，在执行过程中根据情况调用回调即可。不废话，直接上代码： 1234567891011121314151617181920212223 IEnumerator CoroutineWithCallback(Action&lt;string&gt; callback){ WWW www = new WWW(&quot;https://caihua.tech&quot;); yield return www; if (string.IsNullOrEmpty(www.error)) { callback(www.text); } else { callback(&quot;www fail&quot;); }}// 调用方式IEnumerator Start(){ yield return StartCoroutine(CoroutineWithCallback(s =&gt; { Debug.Log(s); }));} 利于协程的原理来制作一个可以返回数值的包装器 协程本身就是利用IEnumerator的可遍历来实现的，在运行期间如果约到yield语句就会等后面的代码执行完成后返回结果。如果在代码块的后面还有yield就会继续执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 包装器public class CoroutineWithData{ public Coroutine coroutine { get; private set; } public object result; private IEnumerator target; public CoroutineWithData(MonoBehaviour owner, IEnumerator target) { this.target = target; this.coroutine = owner.StartCoroutine(Run()); } private IEnumerator Run() { while (target.MoveNext()) { result = target.Current; yield return result; } }}// 真正执行逻辑的代码IEnumerator LoadSomeStuff(){ WWW www = new WWW(&quot;https://caihua.tech&quot;); yield return www; if (string.IsNullOrEmpty(www.error)) { yield return www.text; } else { yield return &quot;fail&quot;; }}// 使用...CoroutineWithData cd = new CoroutineWithData(this, LoadSomeStuff());yield return cd.coroutine;Debug.Log(&quot;result is &quot; + cd.result);...","link":"/2017/07/23/2017-7-23-Unity返回Value的协程/"},{"title":"Lua学习笔记：迭代和闭包","text":"关系 迭代是一种遍历一种集合中所有元素的机制，在遍历的过程中需要在每次成功之间保持一些状态，比如当前变量的index等。而闭包的机制恰好很适合迭代，因为闭包是一种可以访问外部嵌套环境中的变量的函数，而这个变量可以用来保持状态。在lua中闭包结构通常由闭包函数本身和一个创建该闭包函数的工厂函数组成。 以下面代码为例，GetValue就是个工厂，它生产出一个闭包，这个闭包将状态保持在t和i这两个变量中。其实在我看来主要是i中。在循环中每次调用闭包（迭代器）都是在更新它的状态i。这段代码完美的展示了迭代器的概念，看完之后对于迭代的理解更近了一步。 12345678910111213141516171819tt = {10,20,30}function GetValue(t) local i =0 return function () i=i+1 return t[i] endenditerator = GetValue(tt)while true do local v = iterator() if v == nil then break end print(v)end 泛型for 泛型for在内部保存了3个值，分别是一个迭代器函数、一个恒定状态和一个控制变量。其形态如下，其中var-list是变量列表，exp-list表达式列表。var-list第一个原始就是控制变量，在循环中它不会是nil，如果是nil了循环就结束了。 123for &lt;var-list&gt; in &lt;exp-list&gt; do &lt;body&gt;end 迭代器是for中内部保存的，恒定状态应该是你需要循环的数据，比如一个table，控制变量是返回值变量列表的第一个变量，同时它也是用恒定状态和控制变量调用迭代器后得到的结果。假设迭代器函数是f，恒定状态是s，控制变量初始是a0，那么有a1 = f(s,a0) a2 = f(s,a1)... lua中将for的迭代器返回值固定为了3个，因此得到的是next\\t\\nil. 无状态迭代器 不保存任何状态的迭代器，可以在多个循环中使用同一个迭代器。例子：ipairs。准确说ipairs是个工厂，它生产了一个简单的迭代器。 一个简单的迭代器 1234567891011121314151617181920local function getNext(list, node) if not node then return list else return node.next endendfunction tra(list) return getNext,list,nilendlist = nilfor line in io.lines() do list = {val = line, next = list}endfor node in list do print(tra(node.val))end 关于迭代的的一些理解 在lua中for迭代的迭代器其实主要是个生成器，它生成了iterator，然后依靠for来循环调用。注意生成迭代的函数的返回值必须是函数、恒定状态、控制变量这个顺序。","link":"/2017/08/14/2017-8-14-Lua学习笔记：迭代和闭包/"},{"title":"Lua学习笔记：函数深入","text":"闭包 lua中的函数都可以认为是闭包，只不过为了便于理解还是用了函数的概念。 lua中函数的返回值可以是匿名函数，也就是闭包。以下面的代码为例，提出一个概念：非局部的变量。在下面的代码中，匿名函数访问了一个变量i，它对于newCount来说是局部变量，对于匿名函数来说是既不是局部变量也不是全局变量，在lua中这个称谓非局部的变量。 在lua中一个闭包指的是一个函数和该函数所需要访问的非局部的变量。lua会把它们看做是一个整体，因此在下面的代码中多次允许c1和c2，会发现变量i是在递增的。这是因为c1 = newCount()这句代码相当于给c1赋值了一个闭包，它包含了i这个变量。因此多次执行相当于就是在反复执行一个对象，这样i就一直是原来那个i。 1234567891011121314151617181920212223function newCount() local i =0 return function () i=i+1 print(i) endendc1 = newCount()print(c1())print(c1())c2 = newCount()print(c2())print(c2())print(c1())-- 结果12123 利用闭包的沙盒 下面这段代码中，修改了math库的sin方法。类似的还可以用来处理一些不安全的代码，这样的方式类似沙盒，将不安全包装了起来。 12345678print(math.sin(45))oldSin = math.sinmath.sin = function (x) return oldSin(x*math.pi/180)endprint(math.sin(45)) 直接使用非全局函数做递归会报错 当你尝试调用下面的代码时，会提示attempt to call global 'foo' (a nil value)，很奇怪对吧，明明定义的foo是个local的，怎么会提示是global呢？这个是因为在调用foo(x-1)时，这个foo函数还没有定义完，因此表达式在尝试调用一个全局的函数foo，但是显然这个全局函数是不存在的。 12345678local foo = function (x) if x == 1 then return 1 else return x*foo(x-1) endendprint(foo(3)) 正确的递归函数姿势，第二种local function foo(x)其实是第一个方法的语法糖。 12345678910111213local foofoo = function (x) if x == 1 then return 1 else return x*foo(x-1) endendprint(foo(3))-- 相当于local function foo(x)... 正确的尾调用 本质是为了不记录函数的返回位置，这样在栈中就可以无限的调用函数。在lua中只有return &lt;func&gt;(&lt;args&gt;)这样的形式才是尾调用。","link":"/2017/08/14/2017-8-14-Lua学习笔记：函数深入/"},{"title":"bat学习","text":"概念 批处理的本质，是一堆DOS和cmd命令按一定顺序排列而形成的集合。 熟悉DOS语法，然后按照正确的顺序来进行指令的运行。 系统教程 使用/?查看if的功能，使用与很多指令，%似乎不行。 123456789101112131415161718192021222324252627282930if /?pause--------------------------------------------C:\\Users\\Administrator\\Desktop&gt;执行批处理程序中的条件处理。IF [NOT] ERRORLEVEL number commandIF [NOT] string1==string2 commandIF [NOT] EXIST filename command NOT 指定只有条件为 false 的情况下，Windows 才 应该执行该命令。 ERRORLEVEL number 如果最后运行的程序返回一个等于或大于 指定数字的退出代码，指定条件为 true。 string1==string2 如果指定的文字字符串匹配，指定条件为 true。 EXIST filename 如果指定的文件名存在，指定条件为 true。 command 如果符合条件，指定要执行的命令。如果指定的 条件为 FALSE，命令后可跟 ELSE 命令，该命令将 在 ELSE 关键字之后执行该命令。ELSE 子句必须出现在同一行上的 IF 之后。例如: IF EXIST filename. (请按任意键继续. . . 从一个demo中学习 这个demo的作用是用来更新游戏客户端的。一般来说我们的端游客户端会有一个launcher来启动真正的游戏，它还要负责来更新游戏。同时，它还要更新自己，以前WOW中的做法是有个专门的update.exe来做更新（不过现在是靠battle.net来更新了），我觉得bat文件一样可以做，因此写了这个demo。下面代码中TL代表launcher，TC代码client。 12345678910111213141516171819202122232425262728293031323334@echo oncls:: 当前程序所在目录set LocalPath=%~dp0:: TL更新包完全路径名,不带后缀，同时也是解压缩后的文件夹名称set TLZipFile=%~dp0TLUpgradeData\\TL_%1:: TL更新包解压路径set TLDecompressPath=%~dp0TLUpgradeData\\echo 执行更新，请稍后...echo ----1.关闭客户端进程----tasklist /nh|find /i &quot;TL.exe&quot;if ERRORLEVEL 1 (echo TL客户端进程已经结束) else (taskkill /f /im TL.exe)tasklist /nh|find /i &quot;TC.exe&quot;if ERRORLEVEL 1 (echo TC客户端进程已经结束) else (taskkill /f /im TC.exe)echo ----2.开始解压缩安装包----if exist %TLZipFile%.zip %LocalPath%7z x %TLZipFile%.zip -o%TLDecompressPath% -aoaecho ----3.开始复制文件----xcopy %TLZipFile% %LocalPath% /e /f /k /y:: xcopy switch说明：:: /E 复制目录和子目录，包括空目录。:: /F 复制时显示完整的源文件名和目标文件名。:: /K 复制属性。一般的 Xcopy 会重置只读属性。:: /Y 取消提示以确认要覆盖echo ----4.删除临时文件----del %TLZipFile%.ziprmdir %TLZipFile% /s /q:: 删除当文件夹和里面的所有文件，/s 表示包含子文件夹，/q 表示不需要确实提示 pause @ 它的作用是让执行窗口中不显示它后面这一行的命令本身。行首有了它的话，这一行的命令就不显示了。首行的@echo off中，@的作用就是让脚本在执行时不显示后面的echo off部分。 :: -双冒号 类似注释符号 &gt;和&gt;&gt; &gt;指示将内容写入某个文件 &gt;&gt;的作用，和&gt;的相同，区别是把结果追加到前一行得出的结果的后面，类似写文件时的append。 echo的三个用法 命令显示与否的开关，有off和on两个选项。设置为off后，后续所有的命令都不会显示命令本身，只显示命令的结果。 类似于print，用于输出信息。 可以直接编辑文本文件。 pause 就是字面意思 :和goto goto用于与其它语言是一样的，就是跳转到一个指定的标签 :是定义一个标签 if123456789101112@echo offif &quot;%1&quot; == &quot;1&quot; goto goto1if &quot;%1&quot; == &quot;2&quot; goto goto2:goto1echo 参数是goto1:goto2echo 参数是goto2pauseexit 就是条件判断，只不过跟着不同的命令产生不同的功能 if exist判定存在 结果判断 if not 否定判定 变量 使用set来进行变量设置，set还有几个switch。当变量的来源是输入内容时用set /p。 set variable=value注意这个语句中等号前后没有空格，我发现有空格的话变量赋值有问题。 使用变量时用%variable%的形式，即两个百分号夹住变量名。 与传统的编程语言不同，bat中变量不能连接使用，比如下面这样是不行的。 12set a=1set b=%a%2 外部参数 %（0-9）来表示参数，其中%0代表自己，demo中只有一个参数是当前最新的版本号，用的是%1。 bat中参数有很多用法，具体不描述了。 其它的cmd命令 demo中还是有tasklist、taskkill、del、rmdir这样的命令，这些就不一一解释了。其实这些全部都是cmd的命令，这样验证了开始时说的，其实bat就是顺序执行一些dos和cmd命令。 资源 这个demo的完整资源在GitHub的这个位置。 另外推荐一篇bat学习的文章，写的很不错。","link":"/2017/08/27/2017-8-27-bat学习/"},{"title":"5.6混合光照","text":"原文地址原有混合光照的问题 5.6之前的光照存在一个严重的问题就是: 混合光照仅当只有一个定向光时才能正常工作。 这是什么个意思呢？ 首先说一下unity的GI一直以来都是依靠烘焙来做的，但是在unity5中加入了PRGI。 目前的unity在一个场景中可以混合使用烘焙光照和实时光照，一部分静态对象使用烘焙好的光照和影子，而一些非静态的对象可以继续接受实时光照的影响。这个需要我们把Light Type设置为Mixed。 不过静态对象会既受烘焙的影响又受实时光的影响，从而产生不好的效果。mixed模式就是为了解决这个问题而出现的，理想情况下，混合模式会为你料理好一切，照亮相同平衡范围内的动、静态对象（从而保留了视觉逼真度与一致性）。只是一切都不是那么的美好，事实上是动态物体不会从spotlight上产生阴影。 需要特别声明一下，我自己的测试中完全没有发现上面的问题，目前不知道原因。 5.6引入的混合光照模式Subtractive 这个就是以前的混合方式。 Shadowmask 在Shadowmask模式中，静态对象通过shadowmask从其他静态对象接收阴影，不必考虑阴影距离。来自动态对象的阴影仅能通过阴影距离内的阴影贴图获得。动态对象通过阴影距离内的阴影贴图接受来自其他动态对象的阴影。来自静态对象的阴影仅能通过光照探针获得。 这段读着有点绕口，其实分析起来就是针对静态和动态物体获得阴影进行了区分。相对来说静态物体获取阴影会比较简单（至少我认为是）。而动态物理为了得到静态物体的阴影需要使用光照探针。而文中的阴影距离内的阴影贴图这个推测是阴影图，熟悉unity shader中阴影产生的人应该知道这个东西。 Distance Shadowmask Distance Shadowmask的行为是由阴影距离决定的。在阴影距离内，动、静态对象都会渲染进阴影贴图，静态对象可以在动态对象上投射锐阴影。超出阴影距离，静态对象会通过预计算shadowmask接收来自其他静态对象的高质量阴影，而动态对象则通过光照探针与LPPV，接收来自静态对象的低分辨率阴影。普通的Shadowmask模式要比Distance Shadowmask模式产生更少的Draw Call，因为阴影贴图的性能消耗要高于烘焙阴影（因为它们在每帧都进行渲染，而烘焙阴影是保存在一个纹理/光照贴图中的）。 这个就有意思了，根据阴影距离决定对象是否渲染金阴影贴图（这里的阴影贴图应该就是阴影映射纹理，它是通过ShadowCaster这个pass产生的），动态和静态的对象满足条件时都会参与渲染，所以会有性能消耗。因为每个对象的都要执行一次pass，而这个pass造成了draw call。（这个不是很能理解了，为何不是在一次DC中执行这个pass？） Distance Shadowmask模式更适合高端PC或游戏主机。而Shadowmask则作为一种更廉价的解决方案，推荐在中低端设备使用。 Baked Indirect Baked Indirect没有使用任何Shadowmask。所以在这个模式中没有远距离阴影。在阴影距离之内，所有静态和动态的对象都投射 实时阴影贴图。但超出阴影距离后，就没有阴影。在Baked Indirect中，除了间接照明之外所有的东西都是实时的。这意味着，实时光照、实时阴影以及实时镜面高光，但是反弹的光照信息储存在光照贴图中，是静态的。 这个东西和shadowmask的区别在于超出阴影距离后就没有阴影了。还有非间接照明是实时的难道说明烘焙出来的静态物体在直线光下其实和没烘焙一样？只有间接光是在lightmap中。 总结一下： 5.6可以说是unity在渲染上又迈进了一步。处理更加精细的影子效果外，还加入了简单的后处理流程，让开发者能够更简单的做出优美的画面。 本文只是对官方内容的简单的总结，在实际使用中不同的硬件环境应该有不同的选择。 文中的各种不同的选项对应的物体的影子的互相影响需要参考Reference card for Light Modes 如何烘焙 主要光的baking是baked，静态物体勾选哪里Lightmap Static。点击bake进行烘焙。","link":"/2017/07/09/2017-7-9-5-6混合光照/"},{"title":"每天一点UWA：加载模块深度解析","text":"专题 因为UWA上会对一些技术进行系列的专题讲解，而且文章并不连续，如果按照每周的形式就会割裂这些内容，因此针对这样的情况统一写成专题形式。 概述 载模块中最为耗时的性能开销可以归结为以下几类：资源加载、资源卸载、Object的实例化和代码的序列化等。 资源加载是加载模块中最为耗时的部分，其CPU开销在Unity引擎中主要体现在Loading.UpdatePreloading和Loading.ReadObject两项中。 Loading.UpdatePreloading，这一项仅在调用类似LoadLevel（Async）的接口处出现，主要负责卸载当前场景的资源，并且加载下一场景中的相关资源和序列化信息等。下一场景中，自身所拥有的GameObject和资源越多，其加载开销越大。 Loading.ReadObject，这一项记录的则是资源加载时的真正资源读取性能开销，基本上引擎的主流资源（纹理资源、网格资源、动画片段等等）读取均是通过该项来进行体现。可以说，这一项很大程度上决定了项目场景的切换效率。 纹理篇只给出结论 同一的格式下（ETC1（Android）和PVRTC（iOS）、且关闭Mipmap功能），图片分辨率越大加载越慢，但是在Android上中（红米NOTE2）高（S6）端机在加载效率上差不多。 同一分辨率（1024x1024）上 -不同格式（对于Android平台，使用ETC1、ETC2、RGBA16和RGBA32四种格式，对于iOS平台，使用PVRTC 4BPP、RGBA16和RGBA32三种格式） 所占的内容首先是有差异的（三组纹理的内存占用分别为1MB、1MB、4MB 和 8MB（Android平台）/1MB、4MB 和 8MB（iOS平台））。 加载效率上，ETC1、ETC2、RGBA16基本一致；PVRTC 4BPP、RGBA16基本一致。 开启Mipmap功能会导致资源加载更为耗时，且设备性能越差，其加载效率影响越大。打破了Android上同一分辨率下ETC1、ETC2、RGBA16基本一致的情况，需要慎用。 PS：压缩后的文件大小，和解压缩的效率与纹理的内容相关，这是因为图片的压缩本质是用矩阵对图片数据进行变换，最终得到一个较小的数据。解压缩也是一样，数据的内容影响了反向计算的效率。 UWA给出的建议 严格控制RGBA32和ARGB32纹理的使用，在保证视觉效果的前提下，尽可能采用“够用就好”的原则，降低纹理资源的分辨率，以及使用硬件支持的纹理格式。 在硬件格式（ETC、PVRTC）无法满足视觉效果时，RGBA16格式是一种较为理想的折中选择，既可以增加视觉效果，又可以保持较低的加载耗时。 严格检查纹理资源的Mipmap功能，特别注意UI纹理的Mipmap是否开启。在UWA测评过的项目中，有不少项目的UI纹理均开启了Mipmap功能，不仅造成了内存占用上的浪费，同时也增加了不小的加载时间。 ETC2对于支持OpenGL ES3.0的Android移动设备来说，是一个很好的处理半透明的纹理格式。但是，如果你的游戏需要在大量OpenGL ES2.0的设备上进行运行，那么我们不建议使用ETC2格式纹理。因为不仅会造成大量的内存占用（ETC2转成RGBA32），同时也增加一定的加载时间。下图为测试2中所用的测试纹理在三星S3和S4设备上加载性能表现。可以看出，在OpenGL ES2.0设备上，ETC2格式纹理的加载要明显高于ETC1格式，且略高于RGBA16格式纹理。因此，建议研发团队在项目中谨慎使用ETC2格式纹理。 网格篇 总结一下：网格的加载效率的影响因素在于网格面数、顶点信息（tangent、color）数和read/write是否开启。 结论很简单，面数多、信息多、开启会造成内存的变大和加载的变慢。 建议 在保证视觉效果的前提下，尽可能采用“够用就好”的原则，即降低网格资源的顶点数量和面片数量； 研发团队对于顶点属性的使用需谨慎处理。通过以上分析可以看出，顶点属性越多，则内存占用越高，加载时间越长； 如果在项目运行过程中对网格资源数据不进行读写操作（比如Morphing动画等），那么建议将Read/Write功能关闭，既可以提升加载效率，又可以大幅度降低内存占用。 Shader篇 Shader资源的效率加载瓶颈并不在其自身大小的加载上，而是在Shader内容的解析上。 总结一下：，Mobile-Bumped Diffuse、Mobile-Diffuse、Mobile-VertexLit和Mobile-Particles Additive加载耗时依次减少，对于的normal版本也是一样。 影响shader解析的因素 一般情况下，Shader加载的CPU耗时与其Keyword数量有关，Keyword数量越多，则加载开销也越大。（具体数据看原文） Shader的Keyword数量是会随着场景设置的不同而变化的。在Unity 5.x中，Unity默认会根据场景设置、Shader Pass等来调整Shader的Keyword，比如如果存在Lightmap的使用，则会默认将对应的Keyword打开，而对于没有使用Fog的项目，则会直接将相关Keyword关闭。 如何提高解析速度 就是减少keyword数量。 首先可以使用skip variant来减少 其次去掉Fallback选项，因为文中认为目前不支持Mobile/Diffuse和Mobile/Bumped Diffuse的设备已经相当少，没有必要做这层保险了。 避免重复解析 因为一个游戏内用到的shader的数量不会太多，如果shader打包到场景或者模型的AssetBundle中，那么在资源加载卸载的过程中会出现同一个shader多次加载解析的问题。因此建议shader单独打包。 注意：对于Unity4.x版本，Shader的AssetBundle加载后只需LoadAll即可完成所有Shader的加载和解析，但对于Unity5.x版本，除执行LoadAllAssets操作外，还需要进行Shader.WarmupAllShaders操作，因为在Unity5.x版本中，Shader的解析和CreateGPUProgram操作是分离的。 对于Unity 5.x版本且正在使用Resources.Load来加载资源的研发团队，可以尝试使用ShaderVariantCollection来对Shader进行Preload，同样也可以达到避免相同Shader重复加载的效果。 注意：对于Unity5.x版本，如果可以通过AssetBundle来加载和解析Shader，则不建议通过ShaderVariantCollection来处理Shader的加载。 总结 综上所述，shader的处理就是减少keyword、对于简单的渲染去掉Fallback、尽量对shader进行单独打包。","link":"/2017/08/27/2017-8-27-每天一点UWA：加载模块深度解析/"},{"title":"每天一点UWA：第五周","text":"AssetBundleshader加载 首先 Shader. WarmupAllShaders 并不影响 Shader 的加载，因为该函数的作用是将所有已加载的 Shader 都做一次快速渲染(渲染单个像素，GPU 在首次使用某一个 Shader 时会有额外开销，Warm 相当于是将这部分开销提前)。 可以通过AssetBundle.LoadAll等接口预加载 AssetBundle 中的 Shader。而对于 Always Included Shaders 中的 Shader 则可以通过 Shader. Find 来预加载。 StreamingAssetPath 和 PersistantDataPath直接load非AssetBundle资源？ 可以但是只能用WWW这样的有限的API. 如果load MP3、JPG这样的非内部资源格式效率低，尤其是JPG还要软解码，效率更低。 还是推荐AssetBundle。 在Unity 5.x 的打包机制下确实无法手动为 FBX 下的 Mesh 或 AnimationClip 单独资源设置 AssetBundle Name。如果Animator是直接引用了FBX里的动画文件，而不是复制了FBX的动画文件出来再引用，那么打包的时候不会把FBX打进AssetBundle。Resources.UnloadUnusedAssets同样可以卸载由AssetBundle.Load加载的资源，只是前提是其对应的AssetBundle已经调用Unload(false)，且并没有被引用。总结一下AssetBundle的加载和卸载加载 AssetBundle的各种创建函数可以从本地文件(LoadFromXXX)或者内存中将AssetBundle加载到一块内存区域（use from memory or unitywebrequest）或者只是建立一个序列化引用(use loadformfile)。 AssetBundle的各种load函数会将真正的asset从AssetBundle中加载出来到内存中。 instantiate函数创建GameObject实例 卸载 AssetBundle的实例函数unload（false）会卸载内存中的AssetBundle（虽然函数的说明中是Unloads all assets in the bundle.），参数是true的话删除AssetBundle和用它创建的asset。 上面的函数针对的单个AssetBundle，而UnloadAllAssetBundles这个静态函数就是针对所有当前已经load的AssetBundle了。 对于一个具体的asset可以使用Resources.UnloadAsset来卸载，或者使用Resources.UnloadUnusedAssets将多有没有引用的asset卸载。前提就是调用过AssetBundle的Unload（不论参数是false还是true）。 BuildOptimize Mesh Data选项 build时我们在player setting里面有这个选项，它只针对Build Player或者Bundle 时才生效的，所以提前做的AssetBundle是无效的。 模型导入时也有个Optimize Mesh选项，是调整面片排序的，和build时的是两回事。 UIUGUI做的一个界面中有一个背景图片，关闭销毁这个界面后调用 Resources.UnloadUnusedAssets，图片还在内存中 在使用 Resources.Load 加载 UI 界面的情况下，即使“关闭销毁这个界面”后，Resources.UnloadUnusedAssets 确实还是无法卸载对应的图集的。因为此时该图集依然被 Resources.Load 加载出来的 Prefab 引用。 建议是手动调用 Resources.UnloadAssets 来手动释放图集（可以通过 Sprite.texture 来找到对应的图集），在重新实例化该 UI 界面时，图集也会自动进行 Reload 的。 模型MeshBaker 烘焙的Mesh可以保存到Prefab中，但是不能像FBX一样，设置Model导入设置中的Generate Lightmap UVs 等信息，请问有没有大招可以处理此情况？ 首先从理论上说，一个 Mesh 只能有一个 LightmapIndex 和 LightmapOffset 属性，这就决定了 Mesh 的合并必须在 Lightmap 的烘焙之前。 做Mesh合并时，需要注意到UV2对于一个Mesh而言，其所有三角面的UV区域都必须是互不重叠的，所以不能简单直接地合并。考虑到合并前每一个Mesh的UV2区域都应该是在[0,1]x[0,1]的区间中，在合并时可以给每一个UV2区域做一个缩小和平移，从而可以把每个区间在互不重叠的情况下，放到同一个[0,1]x[0,1]的区间中。在UV2也正确拼合后，重新进行Lightmap的烘焙即可得到正确的效果。 关于静态batch 勾选Static的GameObject下的Mesh都会被合入CombineMesh（无论什么材质），且每个Mesh都作为SubMesh存在。 在Unity 5.3之前，对于渲染顺序相邻且材质相同的SubMesh则会动态将其索引数组拼合，从而合成一个Draw Call。 而Unity 5.3之后（还是在同材质，渲染顺序相邻的前提下）则不再拼合索引数组，因为在不切换材质时产生多个Draw Call的开销并不大，而这多个Draw Call会被统计为一个Batch。 如何删除StaticBatchingUtility.Combine会产生Combined Mesh的内存 通过某个使用了该Combined Mesh的MeshFilter来获取其引用（MeshFilter.sharedMesh），然后通过Destroy接口来将其卸载。因为Combined Mesh不属于真正的Assets（在Deep Memory中不属于Assets下，而是在Scene Memory下），所以不能用Resources.UnloadAsset来卸载。 内存AssetBundle内存占用问题 在webStream仍旧存在时（似乎是5.4之前），一个AssetBundle（1mb）解压到websream后如果是2mb，那么这个AssetBundle最终所占的内存就是2mb，因为webstream中已经包含了AssetBundle。 AssetBundle资源卸载AssetBundle加载好以后立刻通过Instantiate实例化一个对象，然后通过Resources.UnloadAsset和Resources.UnloadUnusedAssets来进行卸载，如果无法卸载，则该资源一定被缓存了。","link":"/2017/08/27/2017-8-27-每天一点UWA：第五周/"},{"title":"游戏设计模式读书笔记：组件模式","text":"为什么是组件意图 允许单一的实体跨越多个领域而不会导致这些领域彼此耦合。 实体-组件-系统(ECS) 组件模式在游戏中常见的体现就是ECS 为什么是组件 在游戏开发中一个实体会有多个不同的功能，比如音频的播放、动画功能、渲染、物理、输入等等，如果所有的功能都按照类的形式写到一个类文件中会非常的庞大且不易维护。 将不同类型的功能切分成不同的组件，既是对结构的优化也是实现了功能的复用。 为什么不是类的继承 因为可能一个实体的在继承多个父类（C++，但是C#这样的语言在语法上就不行）时出现重复继承的问题。比如实体的父类的父类出现重复的问题。 模式 单一实体跨越了多个领域。为了保持领域之间相互分离，将每部分代码放入各自的组件类中。实体被简化为组件的容器。 何时使用 组件通常在定义游戏实体的核心部分中使用。 有一个涉及了多个领域的类，而你想保持这些领域互相隔离。 一个类正在变大而且越来越难以使用。 想要能定义一系列分享不同能力的类，但是使用继承无法让你精确选取要重用的部分。 一些问题 组件之间的通信问题 组件的获得需要先获取实体，才能获得组件对象。 实现 建议直接看原书代码。 进化过程 1.先将不同的功能模块分为不同的组件，实体类本身只是调用组件中的方法（作为容器），参数为自身。 2.对组件类进行接口化，最后变成实体类中只要使用继承自接口的类即可。对于接口的不同实现就可以实现不同的功能。 设计决策对象如何获得组件对象创建组件 自己创建所以一定能拿到需要的组件 组件模式的优势在于自由的将不同的组件赋予一个对象，从而让对象获得不同的能力，或者说变成了某个特定的游戏对象。但是如果用硬编码的方式获得组件，那么这个对象就定型了。 外部提供组件 对象更加灵活。我们可以提供不同的组件，这样就能改变对象的行为。 通过共用组件，对象变成了组件容器，我们可以为不同目的一遍又一遍重用它。 对象可以与具体的组件类型解耦。 如果我们允许外部代码提供组件，好处是也可以传递派生的组件类型。 这样，对象只知道组件接口而不知道组件的具体类型。这是一个很好的封装结构。 PS：细细体会unity的组件实现。 组件之间如何通信通过修改容器对象的状态： 这个可以参考unity的实现。在unity中每个GameObject都必须有transform组件，以为位置、角度和缩放信息算是所有对象都必须有的，而且在物理组件、渲染组件中都需要用到。 但是这个方案的问题就在于，如果一个GameObject使用了多个组件，而这些组件在修改数据时可能需要一定的顺序才行，比如计算移动的组件需要限制性，在执行物理相关和渲染相关的，因为可能一个对象在一帧中已经离开了摄像机范围而不需要渲染了。 互相引用 这个没什么好多解释的，掌握了对象的引用自然可以获得其数据和方法。 但是这个是一种倒退，因为耦合了。 消息机制 恩恩，尤其是使用订阅发布模式的消息系统。 参考 原文 一个不错的框架，我是先学习了这个框架在看这个文章的，醍醐灌顶之感。","link":"/2017/08/28/2017-8-28-游戏设计模式读书笔记：组件模式/"},{"title":"Lua学习笔记：高级概念","text":"高级概念 这部分中会记录一些lua语言中的高级概念和技术。 模块概念 从我的理解看，模块更像是一个类。但是因为lua中没有类的概念，模块的实现是依赖于table。 一些公共或者私有的变量+函数组成了模块的主体，最后一个return module完成了基本的构造。其实这个return就是返回了这个table。 具体实现看教程 使用123456789101112131415161718192021-- 创建一个叫Class的模块Class = {}Class.Name = &quot;name&quot;Class.Grades ={ &quot;Grade1&quot;, &quot;Grade2&quot;, &quot;Grade3&quot;}temp = &quot;a&quot;local temp2 = &quot;b&quot;Class.temp3 = &quot;c&quot;function Class.FindGrade(key) return Class.Grades[key]endreturn Class 12345678910111213141516171819-- temp = &quot;local temp1&quot;-- 导入模块require(&quot;Class&quot;)-- temp = &quot;local temp1&quot;print(temp)print(Class.temp2)print(Class.temp3)-- 调用模块函数print(Class.FindGrade(1))-- 结果anilcGrade1-abc 分析一下模块的变量，从例子中可以总结，模块中的以模块名+.形成的变量（Class.temp3）是全局变量，而且即使在模块内部调用用也要用模块名+.的形式使用。 没有加模块名的变量其实也是全局变量，外部代码也可以直接访问。注意代码中在require的前后分别定义了一个和模块中名字相同的变量，这里有一个很有意思的事情，就是如果是之前定义的，那么在print时是模块中的值，如果在之后定义那么就是本地定义的值。这说明require这种过程实际上等于在本地定义了一些变量。所以最终输出的值可以按照后定义的输出。 显示标记为local的变量是本地变量，在模块内部使用是没有问题的，但是外部代码无法访问。 加载机制 基本上遵循C的加载机制，也就是先找同一目录下的文件，然后会找全局变量中path里面定义的文件。 通常我们在编写代码的时候肯定是会有物理的文件夹结构的，此时如果我们不去改package.path的值，那么可以在引用时加速文件夹名字，比如我把class和student放到了Module文件夹下，那么代码中写require(&quot;Module/Class&quot;)即可正常调用。 协程 首先是真的多线程，并非unity的那种主线程内部的线程。 1234567891011121314151617181920212223242526272829303132333435363738394041require(&quot;MyCoroutine&quot;)cor1 = MyCoroutine.CreatCor()print(cor1)for i = 1, 10 do MyCoroutine.RunCor(cor1)endcor2 = MyCoroutine.CreatCor()print(cor2)for i = 1, 10 do MyCoroutine.RunCor(cor2)end-- 结果thread: 0089D628123runningthread: 0089D62845678910thread: 00897D60123runningthread: 00897D6045678910 用法比较繁琐，但是可以明确的控制协程的执行步骤。有点类似python。 建议直接看教程。 元表（MetaTable） metatable更像是lua为table提供的依赖倒置的接口，以__index这个函数为例，本身如果lua提供了固定的函数，那么我们在取值时候只能遵从lua的规定。但是现在提供了一个__index，你可以自定义这个__index的行为，而lua在运行期间遇到了需要用到__index的时候就会按照你所规定的准则行事了。这个思维是很好的。 下面是__index的用法，metatable。 Lua查找一个表元素时的规则，其实就是如下3个步骤: 1.在表中查找，如果找到，返回该元素，找不到则继续 2.判断该表是否有元表，如果没有元表，返回nil，有元表则继续。 3.判断元表有没有index方法，如果index方法为nil，则返回nil；如果index方法是一个表，则重复1、2、3；如果index方法是一个函数，则返回该函数的返回值。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748mt = {}mt.__index =function (t,key) if key == &quot;key3&quot; then return 5 elseif key == &quot;key4&quot; then return 6 else return 0 end endmt.__newindex =function (t,key,value) t.key = valueendmt.__tostring = function (t) local tempTable = {} local index = 0 for i,v in pairs(t) do index = index + 1 tempTable[index] = v print(i..&quot;/&quot;..v) end return &apos;{&apos; .. table.concat(tempTable, &apos;, &apos;) .. &apos;}&apos;end-- 一旦定义了__metatable，就代表getmetatable只能得到这个函数的值，-- 而不能再次赋值,否则会报错“cannot change a protected metatable”mt.__metatable = &quot;不能看啊不能看&quot;local t = {1, 2, 3, key1 = 3,key2 = 4}setmetatable(t, mt)print(t)print(getmetatable(t))print(t[&quot;key4&quot;])mt2 = {}-- 下面的代码会报错--setmetatable(t,mt2) 这个东西有个好处，如果我写的key不存在，那么我是可以自定义它的行为的。我可以返回一个数值，也可以执行一段代码。但是一般来说还是提前预置好数据比较好。 PS：元表本身是一个table，如果按照table就是类这个概念来看的话，元表对应了类类型，而实际的使用中它也是起了这样的作用。元表中以__开头的方法们算是它保留的方法，我们可以给一个元表定义这些方法实际是一个什么样的行为。比如__tostring方法，我们可以在一个元表中重新定义它的实现，有点像C#中override ToString方法。 面向对象 lua的oop是基于table的，table中可以设置全局或局部的变量、方法等。 继承通过子类调用父类的构造函数（其实lua没有构造函数一说，只是我们人为的在代码中创造出来了一个创建对象的函数）来创建，然后在扩展，从而实现了继承。 从本质上说，lua的继承和C的继承是一样的，依赖的是table嵌套table，而C中是结构体嵌套结构体。 具体看下链接里教程的例子吧。 一些体会 其实只要学过一个脚本语言，lua就不算陌生，还算是上手比较快。 所有语言的核心在api的使用，所以熟悉标准库是关键。 lua与C/C++的交互也是大头，不过目前暂时不用就先不学了，等后续学了再填坑。 多写，多写，多写。 一个学习lua编程的方法是看WOW的插件源码。 调试 因为用的是LuaStudio，在调试的过程中也遇到了很多的问题。首先正常的自己写的代码都可以require成功，os\\io\\math这样的库也都没有问题，但是用到socket库的时候怎么都无法require。最后发现在LuaStudio中必须这样设置才行 参考 table参考 lua教程 我在学习中写的所有代码 脚本之家-lua","link":"/2017/08/07/2017-8-7-Lua学习笔记：高级概念/"},{"title":"每天一点UWA：第七周","text":"UINPOT采用 ToLarger 的模式拉成POT，如果是UI界面（开启Pixel Perfect）的话，可能显示时会有较大视觉损失。在Unity 5.x版本下，我们在用UGUI的过程中发现它把图集都打进了包里，这样就不能自动更新了，请问图集怎么做自动更新呢？ 在Unity 5.x中UGUI使用的Atlas确实是不可见的，因此无法直接将其独立打包。 建议，可以把Packing Tag相同的源纹理文件，打到同一个AssetBundle中（设置一样的AssetBundle Name），从而避免Atlas的冗余。同时这样打包可以让依赖它的Canvas的打包更加自由，即不需要把依赖它的Canvas都打在一个AssetBundle中，在更新时直接更新Atlas所在的AssetBundle即可。 ScrollRect在滚动的时候，会产生Canvas.SendwillRenderCanvases，有办法消除吗？ ScrollRect在滚动时，会产生OnTransformChanged的开销，这是UI元素在移动时触发的，但通常这不会触发Canvas.SendWillRenderCanvases。 如果观察到Canvas.SendWillRenderCanvases耗时较高，可以检查下ScrollRect所在的Canvas是否开启了Pixel Perfect的选项，该选项的开启会导致UI元素在发生位移时，其长宽会被进行微调（为了对其像素），而ScrollRect中通常有较多的UI元素，从而产生较高的Canvas.SendWillRenderCanvases开销。因此可以尝试关闭Pixel Perfect看效果是否可以接受，或者尝试在滚动过程中暂时关闭Pixel Perfect等方式来消除其开销。 对NGUI字体错乱有什么好的解决方案吗？ 有这么几种可能： 一次展开文字太多了。这种情况在部分高通机型和Unity早期版本上都经常出现，现在也偶尔有，究其原理是FontTexture的扩容操作做得不够快或者收到了硬件驱动的限制。 一般来说有两种方法可以解决：（1）减少面板中的字体内容；（2）一开始就用超大量的字体去扩容，将动态字体的FontTexture扩大到足够大；文字渲染与开发团队编写的多线程渲染发生了冲突。这种情况也常有发生，特别是通过GL.IssuePluginEvent方式来开启多线程渲染的项目，就会容易出现问题。 就我们的优化经验来看，第一种情况发生的可能性比较大。 工具Draw Call和Setpass Call，这两个指标主要是看哪一个？关于这点众说纷纭，很多地方都是说看SetPass Call，但是在UWA的性能测试中，还是把Draw Call当成唯一指标。 在 Unity 5.x 中，SetPass Call与 Draw Call相比，SetPass Call的指标与性能相关性更大（比如Static Batching的开启不影响Draw Call数，而SetPass Call通常会明显下降）。但 SetPass Call在某些情况下也同样存在问题，比如往一个场景中添加任意个相邻且材质相同的大网格物体（使Dynamic Batching失效）时，SetPass Call并不会变化。因此在UWA中，我们所使用的是类似Profiler 中 Total Batches 这一项指标，通常该数值与 Frame Debugger 中的数值基本一致，因此可以通过该工具来查看每个Batch的内容，从而更有针对性地进行优化。 脚本Editor 下，当调用GetComponent() 且 T组件并不在当前的GameObject 上时，确实会出现GC Alloc。 首先在发布后是不会出现的。 这是因为在Editor下，Unity的MissingComponentException实现所致，在出现以上情况时，Unity 并不是直接返回一个 NULL，而是返回一个代理 Object用来储存一些相关信息，在后续被访问时可以给出更详细的报错信息。 EventSystem.Update()占用过高怎么优化？ EventSystem.Update 的开销分为两个部分： 来自被触发的响应事件，这部分的开销实际上并不属于事件系统本身，比如：某次点击触发了一个开销很高的逻辑函数，尤其是涉及到资源的加载和实例化。对于这类开销，我们建议通过Profiler.Begin/EndSample或者UWA提供的UWA API，对这些逻辑函数进行进一步的分析。 事件检测的开销，在默认情况下所有的UI元素都是事件检测的目标，因此当界面上UI元素数量很多，且长时间接触屏幕时，会有较高的持续开销。对于这类开销，我们建议通过以下几种方式来优化： 合理划分子Canvas，只有需要检测事件的界面才需要挂上GraphicRaycaster组件。 在Unity5.2之后的版本中，尽可能将不需要参与事件检测的UI元素的 Raycast Target 属性的勾选去掉。而对于Unity 4.x的版本，则可以尝试对UI部分的源码来进行修改以达到类似的效果。 模型&amp;动画动态替换Animator Controller后删除旧的Animator Controller，但是其中的动画片段资源没有被删除。 销毁Animator Controller并不会释放其内所引用的AnimationClip资源的，所以内存没有明显下降是正常的。建议按照以下方式做个试验： 销毁Animator Controller 后，通过Unity Profiler立刻真机Take Sample，查看Animation Clip的Ref count是否为0； 如果不是，则需要进一步查看这些资源的索引出处；如果为0，则可以通过UnloadUnusedAssets或UnloadAsset来将其从内存中去除。 PS:在unity中很多对象只是个包装器，或者只是包含了其它资源的引用，因此消耗这些包装器并不会真正的销毁资源对象。 渲染我使用Shader.WarmupAllShaders操作，在后续加载资源还是有CreateGPUProgram出现。(Shader都在一个AssetBundle文件中，都是常驻内存的，不会删掉)是必须使用ShaderVariantCollection来加载Shader吗？ WarmupAllShaders仅能对当前内存中的Shader进行warm up。后续如果又有Shader加载进来，则仍然会出现CreateGPUProgram操作。 所以如果出现问题中的现象应该还是有shader打包到别的AssetBundle中了。 Material.SetPassFast占用很高，这是在第一次实例化一个特效，但是第二次实例化就不会出现高值了，请问能怎么优化吗？ 该过程是在处理Shader，Unity 5.3以后在第一次显示时才会将Shader进行Warmup，所以就会造成一次峰值卡顿。 上面那个问题就很好的解决了这个问题，加载完shader后可以主动调用一次Shader.WarmupAllShaders函数。 在Unity 3D中，shader是何时编译的，在何时加载入显存中的（本条来自知乎）？ Editor中：修改shader并保存时立即编译。 Runtime下，无论哪个平台，都是在进入场景时加载shader object内容到内存，但是首次实际调用渲染时才编译，编译完成之后会cache下来。 有两种优化方法： 调用Shader.WarmupAllShaders()，自动编译该场景中用到的所有shader。该方法在Unity5中已经废弃。 在项目设置的GraphicsSettings中，可以导出ShaderVariantCollection，并在Preloaded Shader中导入，这样的话就可以在载入场景时一并编译需要预加载的shader，这样的优化在移动平台上用得比较多。 具体见","link":"/2017/09/10/2017-9-10-每天一点UWA：第七周/"},{"title":"每天一点UWA：UI优化小结","text":"说明 经过一个半月的学习，对UI的优化有了一些心得，同时也希望把零散的知识点总结到一起，因此有了这个专题。 那些需要关注的性能指标函数UGUI参考的函数 1、Canvas.SendWillRenderCanvases()该API为UI元素自身发生变化（比如被Enable或者被缩放，移动并不算）时所产生的调用。发生在canvas被渲染之前。 2、Canvas.BuildBatch该API为UI元素合并的Mesh需要改变时所产生的调用。通常之前所提到的Canvas.SendWillRenderCanvases()的调用都会引起Canvas.BuildBatch的调用。另外，Canvas中的UI元素发生移动也会引起Canvas.BuildBatch的调用。 NGUI参考的函数 UICamera.Update()该函数通常在点击时出现开销。因此，当该函数的CPU开销较高时，通常都是因为调用了其他的较为耗时的函数引起。 UIRect.Update()该函数通常在需要更新锚点位置时出现开销。因此，当该函数的CPU开销持续较高时，通常是因为当前场景中有较多的UI元素绑定了OnUpdate模式的锚点。 UIPanel.LateUpdate()该函数为NGUI最主要的CPU开销，包含了对所有UI界面包括其下UI元素的状态更新、网格重建、DrawCall合并等操作。大量的UI变动或者不合理的UIPanel布局都有可能导致该函数出现较高的峰值。 UIRect.Start()该函数主要涉及到UI元素的初始化操作，通常在UI界面被实例化时出现并产生一定的CPU开销。 一些需要知道的UI原理mesh合并 一个Canvas下的所有UI元素都是合在一个Mesh中的。 而在Batch前，UGUI会根据这些UI元素的材质（通常就是Atlas）以及渲染顺序进行重排，在不改变渲染结果的前提下，尽可能将相同材质的UI元素合并在同一个SubMesh中。所以同一Canvas下不同的材质的UI可能会合并为多个SubMesh。 UI重建 关于UI重建的说明。UI其实是一些3D的quad，这一下就能够理解为什么存在UI的减少少drawcall了，这个和模型的减dc完全一个原理。 在UGUI中，网格的更新或重建（为了尽可能合并UI部分的DrawCall）是以Canvas为单位的，且只在其中的UI元素发生变动（位置、颜色等）时才会进行。因此，将动态UI元素与静态UI元素分离后，可以将动态UI元素的变化所引起的网格更新或重建所涉及到的范围变小，从而降低一定的开销。而静态UI元素所在的Canvas则不会出现网格更新和重建的开销。 在这再次对更新和重建进行一些详细的说明： 更新指的是UI元素本身的某些属性发生变化，从而需要重新生成，或者更新顶点属性。比如颜色变了，在UGUI中颜色的变化是通过修改顶点色实现的，所以就需要更新UI元素对应的每个顶点的顶点色属性（可以认为就是修改下某个数组里的数值）。位置移动一般是不会造成顶点属性的变化的。所以总的来说，“网格更新”更新的是顶点属性。 UI元素和别的网格不同点在于，UI的网格是需要进行合并的，并且在UGUI中是以Canvas为单位的，在提交GPU之前，同一Canvas下的所有UI元素都会被合入一个Mesh中（但包含多个SubMesh）。所以位置的移动，顶点属性的变化，都会导致这个Mesh要重新合并，也就是网格重建。这也是为什么说要“动静分离”的原因，完全静态的Canvas是不需要重建的，但只要里面有一个UI元素在动，就会引起Canvas的重建。 在UGUI里更改了Image的Color属性，其原理是修改顶点色，因此是会引起网格的Rebuild的（即Canvas.BuildBatch操作，同时也会有Canvas.SendWillRenderCanvases的开销）。通过修改顶点色来实现UI元素变色的好处在于，修改顶点色可以保证其材质不变，因此不会产生额外的Draw Call。 Unity自带的UI Shader处理颜色时，改 _Color属性不会触发顶点重建吗？ 在UI的默认Shader中存在一个Tint Color的变量，正常情况下，该值为常数(1,1,1)，且并不会被修改。如果是用脚本访问Image的Material，并修改其上的Tint Color属性时，对UI元素产生的网格信息并没有影响，因此就不会引起网格的Rebuild。但这样做因为修改了材质，所以会增加一个Draw Call。 综上所述，移动不一定会更新，但是会重建。而颜色变化或者大小变化带来的都是重建。 优化建议： 动静分离，动的频率不同也分离，减少Mask组件的使用，使用Mask不仅会增加GPU端渲染的压力，同时也会造成CPU端DrawCall的明显上升。可尝试用RectMask2D来进行替换。 减少OnEnable和OnDisable，通过移动位置、改变摄像机culling mask。后者可能会一定程度地提高内存的开销（UIDrawCall中存储的Mesh）。 修改material改颜色和直接改color属性在性能消耗要权衡。一个加drawcall一个会重建，要根据测试结果来。","link":"/2017/09/10/2017-9-10-每天一点UWA：UI优化小结/"},{"title":"每天一点UWA：第九周","text":"AssetBundle关于AssetBundle依赖的问题 如果Panel A和Panel B，它们均依赖一个共享Atlas C。如果在加载完AtlasC后卸载它所在的AssetBundle，再创建A和B，此时会失败。因为他们的依赖关系在AssetBundle上。 请教一下，SerializedFile的卸载规则是什么呢？会跟随这AssetBundle一起卸载么？ 绝大部分的SerializedFile均由AssetBundle产生，当AssetBundle被卸载时，与其对应的SerializedFile也将销毁。 WWW.LoadFromCacheOrDownload只是在内存中有个引用，没有实际加载资源，调用WWW.assetbundle后也是么？ 那么依赖此AssetBundle的资源加载的时候，会自动触发此AssetBundle从磁盘加载对应的引用资源么？ 在调用WWW.assetBundle之后，内存中也只是存在较小的SerializedFile（不包含资源数据）。“那么依赖此AB的资源加载的时候”确实会触发该AssetBundle通过磁盘IO加载资源。 Build细谈Optimize Mesh Data选项 第五周的时候说过Optimize Mesh Data选项的问题，但是只是说了和模型上的optimize的区别和一些问题，下面详细说说这个选项，以下内容来自这里。 Unity 在底层默认希望为你做尽可能多的优化，降低使用门槛，比如 BuildSetting 中的 Optimize Mesh Data 选项就是一个典型的例子。这个选项到底有什么用呢？文档描述为： Optimize Mesh Data Remove any data from meshes that is not required by the material applied to them (tangents, normals, colors, UV). 即是说：如果开启了此选项，将会在 Build 过程中根据场景中 Mesh 所使用的材质（或者说 shader）进行静态分析，来去掉 Mesh 中“无用”的数据（材质不使用的数据），比如：切线，发现，定点色，多余的 uv 等，以此减少数据量和最终构建的游戏包的大小。 这是一个非常好的功能，如果 unity 不提供自己写插件恐怕还是比较麻烦的，但是在使用过程中有没有“坑”呢？有没有要注意的地方呢？答案当然是：有！ 如果你在场景中有动态切换材质（主要是 shader 的改变），比如原始模型中带有法线，默认的材质没有使用法线，但是动态切换的材质却需要使用法线，那么你得注意很可能在编辑器中运行正常，一旦发布到真机就会出现很怪异的现象，会让人以为是 shader 在不同平台的兼容性或者数据精度等问题。譬如描边效果就是一个很好的例子。 结论：如果使用此选项，请务必注意自己动态切换材质的游戏对象是否在场景中以静态的形式存在，shader 使用了哪些模型的数据，并根据实际情况做相应的调整。 有没有什么办法可以提升Unity编辑器中代码的编译速度？我们现在每修改一次代码，等待的编译时间都将近半分钟。 对于大型项目来说，这确实是大家经常遇到的情况。一般来说，Unity Editor会按照脚本的依赖关系编译代码，其主要分为以下四个步骤： 编译Standard Assets、Pro Standard Assets和Plugins文件夹中的Runtime Script； 编译以上三个文件夹中Editor文件夹下的Script； 编译项目中所有剩余的Runtime Script（Editor文件夹以外Script； 编译剩余Script（即Editor文件夹中Script）。 建议研发团队可以将一些长时间不需要改动的脚本代码（比如各种插件代码）放入到Standard Assets、Pro Standard Assets或Plugins文件夹中，这样这些代码只需要编译一次，后续的时间就都能节省下来。 纹理如果纹理尺寸长宽不相等，那么即便是2的幂次，也不会被压缩成PVRTC格式纹理。建议在iOS平台中，尽可能保证纹理尺寸为2的幂次且长宽相等。UINGUI中不同panel下的Widgets使用同一个Atlas，会导致DC比较多，而且从profile中会有多个同名的mesh，以为NGUI中这些widgets的mesh是动态生成的，名字采用的就是Atlas的名字。对于NGUI而言，如果界面元素的坐标是非整数的数值，会导致界面元素模糊么？还有哪些原因会造成界面元素模糊？ 导致界面元素模糊的原因主要分为两个， 一是像素未对齐（通常就是因为坐标非整数造成），在相邻像素色差较大的情况下容易出现模糊，特别是文字部分； 二是纹理分辨率相对于屏幕的分辨率被缩小或放大，纹理被缩小通常会表现出锯齿感，而纹理被放大则会表现出模糊。 而对于动态字体，通常只需要确保像素对齐即可使其不模糊，但需要注意的是，UGUI与NGUI都有全局缩放的功能(分别在Canvas Scaler和UIRoot组件上)，是为了确保不同分辨率下布局相同，也会使动态字体出现缩放，从而造成模糊的问题。 工具Draw Call和Setpass Call，这两个指标主要是看哪一个？关于这点众说纷纭，很多地方都是说看SetPass Call，但是在UWA的性能测试中，还是把Draw Call当成唯一指标。 在 Unity 5.x 中，SetPass Call与 Draw Call相比，SetPass Call的指标与性能相关性更大（比如Static Batching的开启不影响Draw Call数，而SetPass Call通常会明显下降）。 但 SetPass Call在某些情况下也同样存在问题，比如往一个场景中添加任意个相邻且材质相同的大网格物体（使Dynamic Batching失效）时，SetPass Call并不会变化。因此在UWA中，我们所使用的是类似Profiler 中 Total Batches 这一项指标，通常该数值与 Frame Debugger 中的数值基本一致，因此可以通过该工具来查看每个Batch的内容，从而更有针对性地进行优化。 Shader.Parse 和 Shader.CreateGpuProgram 到底是做什么的？它们什么时候执行？ Shader.Parse体现的是Shader的加载和解析， Shader.CreateGpuProgram 是将Shader传入GPU的一次提交，GPU驱动会对其进行编译，以适应于特定的设备或平台。 在Unity 5.x版本中，Shader.Parse在Shader资源加载时进行执行，而 Shader.CreateGpuProgram在所在GameObject第一渲染时进行执行。 模型&amp;动画 关于Mesh合并的问题勾选了static的对象 只要是勾选的static的对象都会合并mesh，而不考虑材质使用问题。每个对象会变成submesh。 Unity 5.3之前，对于渲染顺序相邻且材质相同的SubMesh则会动态将其索引数组拼合，从而合成一个Draw Call。而Unity 5.3之后则不再拼合索引数组，因为在不切换材质时产生多个Draw Call的开销并不大，而这多个Draw Call会被统计为一个Batch。对于动态合并的对象 Unity对于任何Mesh的面片都有65536的个数限制，拼合后的面片数也是如此。 请教，角色分部件换装可行吗？比如衣服裤子分开，都是用Skinned Mesh Render，有没有办法合并降低Draw Call？ 可以通过合并网格的方式来达到降低Draw Call的效果，具体可查看Asset Store中的换装例子：Character Customization。但是，在角色换装时需要注意以下几点： 装备与角色必须是共用一套骨骼的； 各装备之间所用的材质必须相同。 开发者需要注意，只有同时满足以上两个条件时，才能达到只使用少量Draw Call来进行动态换装的效果。 渲染要达到后续Shader都不出现加载开销，需要满足以下两个条件： 包含Shader的AssetBundle文件常驻内存； Shader已经全Load加载好；","link":"/2017/09/25/2017-9-25-每天一点UWA：第九周/"},{"title":"侯捷C++学习笔记：基础","text":"1.类 带指针的类 不带指针的类：大多数不需要析构函数 2.定义头文件 防御式代码，避免多次include时重复导入 123456#ifndef _COMPLEX_#define _COMPLEX_...#endif 头文件布局: 前置声明 类声明 class head class Complex class body : 定义数据和函数 类定义 123456789101112131415Class A{Public: A(int arg1, int arg2) : x(arg1), y(arg2) {} operator double() const { return (double)(x/y); } private: int x; int y;} 3.函数构造函数 默认参数 initialization list，只有构造函数有 用法： 12A(int arg1, int arg2) : x(arg1), y(arg2) {} 如果构造函数的参数是类型本身，那么叫拷贝构造。 只要类带指针必须有拷贝构造函数。PS: 同时要有拷贝赋值函数。 编译器会默认生成，但是需要根据情况自己写。 inline函数： 当一个函数在class body内定义并且实现了功能，则会自动成为inline函数。 在外部实现并且加上inline关键字的函数，只是作为inline函数的一个候选人，是否成为一个inline函数完全看编译器会不会这样来编译它。 函数重载 CPP中重载函数在代码中同名，但是在编译后不同名。 如果出现一个函数foo()和foo(int i = 0)这样的情况，实际上是不行的，因为编译器认为在调用的无参版本时两个函数都可以，这样就出现了错误。 const member functions (常量成员函数) 以下面的函数为例，参数括号后加上const修饰符，则说明这个函数是不改变对象中数据的值。 1double real () const { return re; } 在函数的使用上可能与如下的方式，说明我生成的对象c1中的数据是不希望修改的，那么如果real函数中没有const的话编译时会报错。因为如果没有const，说明real函数可能会修改对象中的数据的值，但是我们定义的c1又是一个不会被修改的，那么就有矛盾了。 12const complex c1()c1.real() pass（return） by value vs pass（return） by reference (to const) &amp;这个符号在c中是取地址的操作，在C++中也有这个用发，但是多了一个用法。比如如下的代码中： 1complex&amp; operator += (const complex&amp;); 参数类型后面加&amp;说明这个参数是按引用传递，本质就是指针。如果不加const修饰，则函数中可以修改参数的值，如果加了则说明这个参数就是按指针传递给函数使用，但是不能修改其值。 通常来说尽可能用按引用传递，因为毕竟指针只有4个byte，对于多数情况来说是比较快速和省资源的（栈上的数据少）。但是如果遇到传递的值是char的，也可以安值传递。 传递者无需知道接受者是以reference的形式接收。传递者把对象传递个函数，但是函数是使用值形式的参数还是引用形式的参数完全看函数的定义，但是调用者无需关心。 何时使用value来传递呢？ 如果函数的返回值是函数内部的一个local object就需要安值传递。因为在函数结束后对象就从栈中销毁了，此时用引用的话在获取值的时候，对象已经没了。 ++所以是返回引用还是值，根本上要看这个返回值内存是在函数内还是函数外。++ 友元函数 加friend修饰符，只是告诉类某个函数是友元的，可以直接访问private的变量。 ++相同class的各个对象互为friend（友元）++ 1234567891011int foo(const complex&amp; param){ return param.re + param.im;}...complex c1(1,2);complex c2;c2.foo(c1); 静态函数 与C#不同的是CPP中静态函数可以通过对象来调用，同时当有也可以用类+函数名的方式调用。即 1234Class::StaticFuntion();Class c1;c1.StaticFunction(); 总结 数据一定放在private里面 参数和返回值尽可能用reference来传递，加不加const根据实际情况 class body中函数如果没有修改数据则加const 构造函数尽量用初始列表","link":"/2018/01/01/2018-1-1-侯捷C-学习笔记：基础/"},{"title":"侯捷C++学习笔记：对象的创建和销毁","text":"概述 本文会记录CPP中对象的创建和销毁的过程中的细节 big three函数 拷贝构造函数 拷贝赋值函数 析构函数 用途：这三个函数是在类中包含了指针的情况下使用的。 当有一个成员变量是一个指针时，就有了给这个变量赋值的问题。如果这个赋值需要深拷贝，那么就需要申请内存空间。这样在析构函数中就需要对指针进行delete。 这个成员变量可以是在对象构造函数中被赋值的，比如是个拷贝构造函数。也可以是在拷贝赋值函数中被赋值的。 对象创建 使用Complex c1(1,2)这样的形式还是Complex* c2 = new Complex(1,2)这样的形式，都可以创建对象。 构造函数不能直接被指针调用p-&gt;P::P()，这样写在某些编译器下可以通过编译但是某些不行。 new做了什么 生命周期 对于c1这样在栈上的，生命周期就是C1的作用域。 对于C2这样指针的，生命周期也看C2的生命周期，比如C2是个函数的局部变量，那么在函数结束时因为要调用delete c2，此时对象也就被销毁了。 如果一个c3是static的，那么按照C里面的约定这个变量的生命周期就是进程的生命周期，不管这个C3是全局还是局部。 对象在内存中是什么样的布局 看图说话 图是VC中的内存布局，一个对象的大小必须是16字节的倍数。 灰色部分是debug模式下才有的，用于debug。 Release模式下一个对象包含上下hook共4*2=8个字节，对象本身的字节数（complex那个例子下就是实部和虚部共2个double，即4*2=8字节）。如果不够16的倍数就会出现墨绿色部分的pad，也就是填补内存。 对象的销毁 生成的对象c1和c2都会在作用域结束后销毁。如果是c1那么它这个对象本身就在栈上保存，因此销毁后全部内存就释放掉了。但是指针的形式，因为对象是在堆上的，如果c2指针被销毁了，那么堆上这块内存就无法找到并销毁了（直到进程结束），造成了内存泄漏。 因此对于指针形式的c2，在其使用完成后就可以直接调用delete c2来实现销毁。 析构函数 如果一个对象中动态的分配了内存，那么需要在析构函数找那个对分配的内存进行删除。 如果不显式的去写析构函数编译器应该会生成一个，如果我没有记错的话。 上面的c1中如果是在栈上的，那么变量离开作用域后会自动销毁并调用析构函数。 构造函数执行两个步骤，第一个执行 delete做了什么 数组删除 如果动态生产了数组内存，则在析构函数或者当需要删除对象时需要用delete[]。在这个过程中具体干了什么呢？ 上面也说了，delete会先执行析构函数，其实对于一个对象来说，由于上下hook的存在因此析构函数可以完美的删除这个对象所占用的内存。所以图中左右两个delete都可以删除p所指向的数组，但是因为数组中是string的指针， 所以删除数组后string指针对指向的string对象本身并没有删除。而这个string对象本身其实就是char[]。这才是不用delete[]造成内存泄漏的本质。","link":"/2018/01/16/2018-1-16-侯捷C-学习笔记：对象的创建和销毁/"},{"title":"七周七并发模型：线程与锁","text":"为何使用多线程和锁 为了能够并行的计算一些东西 因为在多线程下，如果要修改同一个对象是值会出现竞态条件（即代码行为取决于各操作的时序）。它的表现可能是值的不对，甚至某些时候这个值的前半段是一个线程修改的，后半段是另一个线程修改的。因为这个对象可能不是原子的。 锁，或者说是并行控制的进化第一阶段：锁与同步方法基础的锁 从代码层面看就是一个lock函数 同步方法 在java或者C#中可以通过attribute来让方法同步执行，但是这个的效率是很低的。 同时还引出了另外一个问题，当同时使用多个锁的时候不但效率会进一步降低，而且容易产生死锁。 基础锁带来的问题死锁 当出现多个锁的时候，因为执行顺的问题，导致多个对象都持有一个锁，同时在等待其他人释放锁。例子就是哲学家进餐问题。 哲学家进餐问题的解决方法就是: 一个线程想使用多把锁时，就需要考虑死锁的可能。幸运的是，有一个简单的规则可以避开死锁——总是按照一个全局的固定的顺序获取多把锁。 外星方法问题 所谓外星方法指的是在锁的block中调用了一个外部的方法，但是这个方法中可能会要求获得当前锁的权限，但是因为这个锁正在被使用，导致了代码出现死锁。 解决方案： 唯一的解决思路是避免持有锁时调用外星方法； 一种方法是在遍历之前对listeners进行保护性复制（defensive copy），再针对这份副本进行遍历； PS：但是我的理解是这个情况只有当数据是并发read时，如果是并发的write想来就有问题了。 第二阶段： 进击的锁中断死锁 死锁问题是很让人沮丧的，而且也是很多时候都会遇到的。在我们的C#代码中使用lock来做锁，如果遇到死锁，我们是没有办法终止这个被锁的线程的。但是好在还有办法可以结束锁，在java中就是书中说的ReentrantLock，对应的在C#中是Monitor。 PS：java的部分可以看下这篇文章 PS2：两个类的功能基本是一致的，都包含了超时的功能。 问题是否得到了解决？ 虽然tryLock()方案避免了无尽地死锁，但这并不是一个足够好的方案。首先，这个方案并不能避免死锁——它只是提供了从死锁中恢复的手段。其次，这个方案会受到活锁现象的影响——如果所有死锁线程同时超时，它们极有可能再次陷入死锁。虽然死锁没有永远持续下去，但对资源的争夺状况却没有得到任何改善。 有一些方法可以减小活锁的几率。比如为每个线程设置不同的超时时间，来减少所有线程同时超时的几率。但通过设置超时来处理死锁不能说是一个好的方案——以后我们还可以做得更好。 条件变量 C#中的Monitor有wait、Pulse和PulseAll，对应了ReentrantLock的reachSixCondition对应。用法参考这里 该方法可以显著调高并发度 原子变量 C#中可以使用Interlocked.Increment来做计算，这个是原子性的。在计数类的场景比较实用。 这个是为了解决基础锁使用过程中对于数据的操作比较繁琐的问题。比如对于计数类的变量，需要保证其get\\set都有锁的保护，这样写的方法就比较多了。 原子变量是无锁（lock-free）非阻塞（non-blocking）算法的基础，这种算法可以不用锁和阻塞来达到同步的目的。无锁的代码比起有锁的代码更为复杂。 第三阶段：终极形态 书中以一个大数据的单词解析为例。 线程池 好处就是可以节约线程数，因此往往不能无限制的使用多线程。 影响线程池最优大小的因素有很多，例如硬件的性能、线程任务是CPU密集型还是IO密集型、是否有其他任务在同时运行。还有很多其他原因也会产生影响。 话虽如此，但也存在经验法则：对于CPU密集型的任务，线程池大小应接近于可用核数；对于IO密集型的任务，线程池可以设置得更大些。当然，最佳的方法是建立一个真实环境下的压力测试来衡量性能 解决方案的进化生产者消费者模式 将数据的解析与计算分割为生产者与消费者。从而分析出性能的瓶颈在消费者（统计单词量）这边。 使用多线程分别进行生产和消费。 关键在于生产者和消费者可能不会（几乎肯定不会）保持相同的速度。比如，当生产者的速度快于消费者的速度时，队列会越来越大。Wikipedia的dump差不多有40 GiB，很容易就让队列大小超过内存容量。相比之下，阻塞队列只允许生产者的速度在一定程度上超过消费者的速度，但不会超过很多。 消费者端的并发执行 将解析出来的数据放入到一个HashMap中 在计算上，使用多线程来对HashMap进行统计，但是真正的计算方法本身采样lock。 问题是从结果统计看并没有提高效率。其原因为： 答案是因为过度竞争——过多的线程尝试同时使用一个共享资源。在我们的程序中，消费者花费大量时间等待被其他消费者锁住的counts，它们的等待时间比实际运算时间还要长，最终导致惨烈的性能下降。 使用ConcurrentHashMap来解决共享资源的并发访问 C#中对应的是ConcurrentDictionary&lt;TKey, TValue&gt;.AddOrUpdate Method (TKey, TValue, Func&lt;TKey, TValue, TValue&gt;)。也就是并发集合，依赖于内置的并发集合来提高并发的访问。 使用多个ConcurrentHashMap 使用ConcurrentHashMap并没有完全的释放多核的威力。 对原来的数据进一步拆分，进而分配给不同的线程来统计，极大的利用了多核。 优缺点优点 线程与锁模型的最大优点是其适用面很广。它是其他许多技术的基础，适用于解决很多类型的问题。同时，线程与锁模型更接近于“本质”——近似于对硬件工作方式的形式化——正确使用时，其效率很高。这也意味着它能够解决从小到大不同粒度的问题。 另外，这个模型可以被轻松地集成到大多数编程语言中。语言设计者们可以轻易让一门指令式语言或面向对象语言支持线程与锁模型。 缺点 线程与锁模型没有为并行提供直接的支持。 线程与锁模型仅支持共享内存模型。如果要支持分布式内存模型（无论是地理分布型或者容错型），就需要寻求其他技术的帮助。这也意味着线程与锁模型不适用于单个系统无力解决的问题。 多线程的难点不在于难以编程，而在于难以测试。 我们要全程保证所有对象的同步都是正确的、必须按照顺序来获取多把锁、持有锁时不调用外星方法。","link":"/2018/01/17/2018-1-17-七周七并发模型：线程与锁/"},{"title":"侯捷C++学习笔记：偏特化","text":"什么是偏特化 泛化（泛型）的反义 分为个数的偏特化和范围的偏特化 数量偏特化 举个例子，如果有如下class的定义，第一个class的就是泛型的，而第二个class，也是两个参数，但是第一个参数是个确定类型的，第二个是泛型的。这样就叫个人的偏特化。这固定类型的位置必须是从左至右的，不能跳着写。 123456template&lt;typename T, typename U&gt;class vector {}template&lt;typename U&gt;class vector&lt;bool, U&gt; {} 范围偏特化 说白了进一步约束泛型的类型。这个和C#中泛型的where约束有点像。 对于下面的例子来说，第一个C约束几乎没有，但是第二个就约束为指针类型了。 123456template&lt;typename T&gt;class C {}template&lt;typename U&gt;class C&lt;U*&gt; {}","link":"/2018/01/02/2018-1-2-侯捷C-学习笔记：偏特化/"},{"title":"侯捷C++学习笔记：面向对象","text":"Composition 组合 其实就是一个类（Container）中包含了另一个类的实例（Component），注意是实例。 delegate 组合的一种 但是包含的是一个类的引用(reference)。 组合的使用 用这样的方式可以做出adapter模式，比如A功能很多但是如果只要暴露出一部分，可以用B来包含A，然后只在B中定义一些方法，这些方法都是直接调用A的即可。 还可以引申出面向接口编程。比如A中要调用某一类的功能，但是这些功能可以由B\\C\\D来提供，或者说不通的条件下使用不通的提供者，那么我们就可以为这些功能定义一个接口，然后让BCD实现接口，A中只要是一个对接口类型的引用即可。 PS：目前我看到C++里面的接口是用虚函数实现的。 no-virtual&amp;virtual C++的函数使用virtual关键字标记为虚函数。 虚函数分为纯虚函数和虚函数，区别就是虚函数是有实现的，哪怕只是个空的函数体{}。但是纯虚函数是没有实现的，定义方式为virtual void Foo() = 0 虚函数不要求子对象一定实现override，但是纯虚函数要求一定实现。","link":"/2018/01/02/2018-1-2-侯捷C-学习笔记：面向对象/"},{"title":"侯捷C++学习笔记：类型转换","text":"自己转换为别的类型 做法：使用operator关键字，无需返回值，函数名称就是返回值。如有需要加上const修饰。 123456789101112131415Class A{Public: A(int arg1, int arg2) : x(arg1), y(arg2) {} operator double() const { return (double)(x/y); } private: int x; int y;} non-explicit-one-argument ctor 本质是编译器将别的对象转化为我们定义的对象 要求的自定义构造函数比较特殊 在实例代码中编译器会把4装换为A，然后执行+ 操作。 123456789101112131415161718Class A{Public: A(int arg1, int arg2) : x(arg1), y(arg2) {} A operator +(const A&amp; a) { return A(....); } private: int x; int y;}A a(2,3);double d = a + 4; 编译器有时会不清楚-下面的代码中a+4时编译器发现可以用double操作，也可以用+操作，在这样的情况下编译器会不知道如何选择进而报错。 1234567891011121314151617181920212223Class A{Public: A(int arg1, int arg2) : x(arg1), y(arg2) {} A operator +(const A&amp; a) { return A(....); } operator double() const { return (double)(x/y); } private: int x; int y;}A a(2,3);double d = a + 4; explicit-one-argument ctor explicit关键字几乎都是用到构造函数前面的，告诉编译器不要随便的把别的类型转换为我自定的类型。 下面的例子中，编译器不会再把4转成A，因此这个表达式是错误的。 123456789101112131415161718Class A{Public: explicit A(int arg1, int arg2) : x(arg1), y(arg2) {} A operator +(const A&amp; a) { return A(....); } private: int x; int y;}A a(2,3);double d = a + 4;","link":"/2018/01/02/2018-1-2-侯捷C-学习笔记：类型转换/"},{"title":"侯捷C++学习笔记：Reference","text":"本质 通过指针实现，所以本质就是指针 意义 是某个变量的代表，因此下面的代码中，x的值为5。在给x赋值后i和x都是6。 12345int i = 5;int&amp; x = i;x = 6; 编译器的一些做法 以一下代码为例，如果有一个变量b是a的引用，那么有sizeof(a) == sizeof(b)而且&amp;a == &amp;b。 上面也说了引用是个指针，在32位系统中sizeof指针应该是4个byte。但是因为b是a的引用，它代表了a，所以代码中sizeof(b)是16byte。而且a和b取地址得到的值也是一样的，虽然我们知道这个在内存中肯定是不一样的。只不过编译器做了这些的处理。 1234typedef struct A {int a, b, c, d};A a;A&amp; b = a; reference的常用方式 主要用于参数的修饰，很少用来声明变量。 参考以下的代码，在使用上引用传递在写法上和值传递是一样的，当然本质不同。但是从代码的优雅性上引用会比指针的参数形式好。 1234567891011void Func1 (Cls a)void Func2 (Cls&amp; a)void Func3 (Cls* a)...Cls obj;Func1(obj);Func2(obj);Func3(&amp;obj); 需要注意以下两个函数不能同时定义，因为在调用上会出现歧义。但是const修饰符可以实现重载。 123456789101112void Func (Cls a)void Func (Cls&amp; a)......Cls obj;Func(obj);......void Func (Cls a) constvoid Func (Cls&amp; a)","link":"/2018/01/07/2018-1-7-侯捷C-学习笔记：Reference/"},{"title":"侯捷C++学习笔记：Object Model","text":"composition &amp; delegate &amp; inherit 的构造和析构顺序 s 如果有以下代码： 12345678910111213141516171819202122232425262728class A{public： A(); ~A(); Foo();}class B{public： B(); ~B();}class C:A{public： C(); ~C();private: B* b;}main(){ C c;} 在前面面向对象中讲过，B和C组成了composition &amp; delegate，而A和C是继承关系。 那么在内存使用的顺序上会先调用A的构造函数，然后调用B的构造函数。最后调用C的构造函数。 在析构时的顺序是：先调用C的析构，在调用B的，最后调用A的。 其顺序可以从代码层面这样的解释 12345678C::C() ：A(), B() { // c在构造函数中要做的事情}C::~C(){ // c的析构 ~B(); ~C();} vptr &amp; vtbl 在C++中函数分为虚函数和非虚函数，对于非虚函数来说调用的时候编译器会编译为call(method address)的形式，也就是说函数的地址是已知的，即使是继承下来的函数，等于也是调用了父类的函数的地址。这个被称为静态绑定。 但是对于虚函数，因为有override的情况，所以C++中采用了虚机制，也可以说是动态绑定。 虚机制的基础是虚指针和虚表。虚指针是对象中的一个指向虚表的指针，虚表是一个对象中所有的虚函数地址表。 与C#方法列表进行比对： C#中方法列表包含了所有函数的地址，而C++的虚表中只是虚函数的。因为不知道子对象是否会override父类虚函数，所以这个虚表里面的函数可能指向了父类的虚函数，也可能指向了子类的虚函数，还有可能是子类override的虚函数。 什么时候C++会使用动态绑定呢？ 调用方法的对象是一个指针 对象使用时是up cast，也就是协变。 调用的是虚函数 本质：从下面的代码看*(p-&gt;vptr)是虚指针指向的虚表，虚表中其实是函数地址的数组，调用某个函数就是去数组的值，然后传递参数。 1( *(p-&gt;vptr) [n] )(...) PS：对于栈上的对象的方法调用，就不考虑虚机制。下面例子中B继承自A，AB中均有虚函数vFunc的情况下，结果是调用了A的虚函数，因为a不是指针。如果a是指针，那么走虚机制，应该执行的是B的vFunc。 12345B b;A a = (A)b;a.vFunc();","link":"/2018/01/09/2018-1-9-侯捷C-学习笔记：Object-Model/"},{"title":"使用整体性学习方法来提高学习效率","text":"前言 这篇文章可以说是一篇读书笔记，内容来自《如何高效学习：1年完成MIT4年33门课程的整体性学习法》这本书。 实际上看到书名的时候我的第一反应这是本讲费曼技巧的书，因为在很多年前我看到过一篇文章，标题和这个非常类似，直到我重新翻出来后发现文中所讲的那个人正是这本书的作者。 书的内容 在这里我不打算过多的写书中的内容，只是简单的把一些核心的内容列出来。实际上如果没有时间看书，我觉得看上面链接中的那篇文章是一样的。因为这本书的观点比较简单，大部分内容是来证明这些观点，并且列出了一些如何实践的方法。 结构、模型和高速公路 这本书虽然叫做如何高效学习，但实际上主要讲的是整体性学习方法。作者一上来先讲了三个主要的观点：结构、模型和高速公路。 结构：理解是结构高度发达完善的结果，结构是学习新知识时与其它知识建立联系。 模型： 简化的结构、结构的快照 模型的目的是压缩信息 核心概念联系在一起创建模型 模型是逐渐调整和更新的 高速公路：结构之间的联系 实际上这三点是整体性学习的核心内容或者说是最终形态。在我的理解中所谓的整体性学习更像是用类比的方式来快速对新知识进行学习，而在类比的过程中对于已有的知识需要一个结构或者模型，在这个基础上通过联想、类比等方法来进行学习。不同的知识之间是有相似性或者本身就是有联系的，这就是高速公路。 以学习编程语言为例，我们知道目前的编程语言会分成不同的范式，比如有面向对象的、面向过程的、函数式的、命令式的等等。现代的编程语言往往包含了多个范式，以C#为例它是面向对象的，也是命令式和函数式都有的。在学会了C#之后，对于java这样的编程的语言在学习上会很快，因为他们几乎在编程范式是一样的，在语法上的差异和API的时候在使用的过程中再慢慢熟悉即可。但是在赋值、条件判断、循环、多线程、文件操作、lambda等等上都非常的接近，这样就可以通过类比的当时来快速的学习。 对于lua、python或者JavaScript这样的脚本语言来说，其在赋值、条件判断、循环这些基本操作上也是一样的，再加上函数式编程的范式使得学习起来也会有一种熟悉的感觉。这也是为啥工作了几年的人在学习一门新的编程语言时会比较快，因为会有一种熟悉感、进而进行类比的学习。快速掌握共同点、重点学习不同点和API就可以很快的掌握。 五个信息类型 书中列出了五种信息类型，也是知识类型。分别是： 随意信息 观点信息 过程信息 具体信息 抽象信息 其中随意信息是最难以记忆的，因为它们往往是一些事实，比如历史中的事件的时间，这些东西往往就是枯燥的记忆内容，没有什么很好的类比方式。 学习的顺序 文中还列出了一个学习的顺序，实际上就是一种知识的学习过程： 获取：快速阅读和笔记法 理解：使用内在化、类比、比喻等技巧。所谓内在化更像是观想法，也就是把知识具现化。 拓展：同上 纠错 应用 这个没什么特别的地方，基本上就是一个获取知识的过程。实际上，这本书中很多的内容对于天朝读了十几年书的人来说都是没什么新意。 书中用了很大的篇幅来描述着5个过程，比如获取就介绍了快速阅读和笔记法。在这里快速阅读推荐指读法，也就是用手指的移动来带动阅读，这样可以让人的注意力集中在手指所在的地方。而笔记法，推荐使用康奈尔笔记法或者与其接近的黄金三分法来做笔记。 对于理解和拓展，就是内在化、图表法等。 对于随意信息的记忆推荐联想法、信息压缩技术。 真正的干货 - 费曼技巧 费曼技巧的过程： 选择要学习的概念 设想你是老师，正在试图教会一名新生这个知识点 当你感到疑惑时，回过头来，重新阅读参考材料、听讲座或找老师解答，直到你觉得搞懂了为止，然后把解释记到纸上。 总结来说就是小学老师告诉我们的，如果你能给你的同学讲明白一个知识点你就是真的懂了这个知识点。 我所总结出来的学习方法 在学习一个新的知识点的时候尽可能的联系已经学过的知识，通过知识的连接和类比来快速掌握知识。 实际上费曼技巧是很实用而且也比较容易实施的方法，费曼技巧的根本理论在于找出自己没有真正掌握的知识，从而查漏补缺。 使用思维导图来做联想、类比和内在化。书中很多方法都提到了联想、内在化、图表法等，在我看来都可以总结为思维导图。思维导图的制作本身就是一个查漏补缺和思维拓展的过程。 使用方格笔记和黄金三分法，这个技巧也是有人专门写过书的，个人认为还是很有用的。 最后这本书的笔记可以看这里","link":"/2018/02/18/2018-2-18-使用整体性学习方法来提高学习效率/"},{"title":"计算机组成原理：6、高速缓冲存储器","text":"概述为何使用Cache CPU速度太快了 解决CPU空等问题，但是需要保证的是大多数的数据和指令都在cache中。 程序访问局部性原理 时间局部性：当前正在使用的指令和数据，在不久的将来还会被使用。那么这些数据和指令需要放到cache。 空间局部性：当前正在使用的指令或者数据的相邻的指令或者数据在不久的将来会被使用，那么把当前使用的和相邻的数据和指令放到cache。 Cache工作原理主存和缓存的编址 图中主存和cache中块的大小一样，主存分成M个块、cache分成C个，显然C远小于M。 标记：主存块和cache块之间的对应关系，如果一个主存块被调入cache，那么主存块号写入到标记中。当CPU想要访问主存时，根据主存块号先去cache中与标记对比。如果找到，那么说明想要在内存中获取的数据已经在cache中了。 注意：cache-主存这个结构中是按块进行存储和传输的。块的大小和块内地址（本质是偏移量）是完全相同的。在有标记的情况下cache是不需要特别编址的。 命中与未命中 定义：CPU使用主存块时，如果块已经调入缓存则命中；如果没有则是未命中。如果命中那么主存中某些块与缓冲块建立了对于关系（标记）。 Cache的命中率 CPU欲访问的信息在Cache中的比率 简单来说和cache的容量和块长有关 一般每块取4-8个字，块长取一个周期内从主存调出的信息长，与前面的低位交叉相关。如果是4体交叉，块长就是4个存储字长。 Cache-主存系统的效率 Cache的基本机构 上图的流程中其实包含了cache读取的流程。 最下面主存和CPU之间是有数据总线的，当cache未命中时主存先把数据送入CPU，同时与cache进行数据交换。 地址映射：给出一个规则，主存当中的块如果要放入cache，它可以放入哪一个或哪几个块中。 地址变换：主存块号或地址转换成cache块号或地址。 替换结构：通过替换算法来决定哪些块从cache退出 注意：图中可装进的判断不是以整个cache为基础的，而是以地址映射的结果为基础。e.g: 未命中发生，经过映射计算后主存的块要进入add1，此时如果add1已经有数据了，就要替换；但是此时cache可能并不满，而只是add1有数据。而且这个还要和具体的映射方式有关，见下面内容。 Cache的读写操作读操作 参考上图，因为读操作的特点是不会改变主存和cache的内容，所以相对比较简单。 写操作 是否实时同步cache和主存就是写操作要关注点了。有两个方法： 写直达法（Write-through）： 写操作时数据既写入cache也写入主存 写操作时间就是访问主存时间 cache退出块时不需要对主存进行写操作，更新策略比较简单。 写回法（Write-back） 写操作只把数据写入cache而不写入主存 当cache数据被替换出去时才学会主存 比较： 显然写操作从逻辑上简单，但是操作步骤太多。尤其是做循环加法这样的操作时，我们只关注结果，中间数值没必要写入主存。这点上写回法就好很多，它只写最后的结果。 但是写回法在多处理器时就会出现数据一致性问题，并发计算时主存块在多个CPU cache中都有副本，很难保证同步。 Cache的改进 增加cache的级数： 离CPU比较近或者离CPU中的core比较近的cache直接做入到CPU内部（片载cache），CPU内部接着做多级。现代多核CPU每个core都有自己的cache，core之间还有共享的cache，所以至少都有三级的cache。 主板上做大容量cache，片外cache。 统一缓存和分立缓存：指令和数据分开放（分立缓存） Cache-主存的地址映射直接映射 对主存分区，每个区的第0块就放到cache的第0块。从图中可以看到cache的0块可能是任何一个区的第0块。 主存区号就是cache的标记，因为只要区号和标记一致，那么主存区中的块和cache的块就能一一对应，同样字块内地址也是一一对应的。 弊端：对于cache的使用有浪费，比如一个区只有一个块被用到了，但是如果出现代码的调转等操作导致需要加载新的cache，只能整块的替换。 全相联映射 主存中任何一个块可以放入cache中任何一个块。 弊端：因为是随便放的，所以CPU使用数据时要把主存地址和cache标记一一对比，导致效率低，线路也会比较复杂。同时cache标记记录的是区号+块号，位数比较多，比较器长度比较长。 组相联映射 cache分成多少组，主存储器中每个区就包含了多少块。 主存在往cache放块的时候，只要计算出这个块是该区的第i个，那么就会放入到cache中第i组中。 主存的块只能放到指定的组（体现了直接相连），但是这个主存块可以在组的任何位置（体现了全相连）。 总结 直接映射：某一主存块只能固定映射到某一缓冲块，速度快但是不灵活。 全相联映射：某一主存块能映射到任一缓冲块，速度慢但cache利用率高。 组相联：某一主存块能映射到某一缓存组中的任一缓冲块中。实际上如果每组都只有一块就等于是全相连，而如果只有一组那就是直接相联。优点就是兼顾速度与利用率。 不同的相联模式在多层cache中分别使用：靠近CPU的cache要求高速度，可以用直接映射或者路数比较少的组相联映射；中间层次可以组相联（比如：两路组相联、四路组相联等）；越远的可以用全相连，因为远的对速度要求低，对利用率要求高。 替换算法 先进先出（FIFO）算法：不能很好的体现程序的局部访问原理 近期最少使用（LRU）算法：希望替换cache块中CPU不再用，或者距离下次CPU读写这个块时间最长的块。 一点感悟： 学到现在从组成原理的设计上学到一个很好的思路，在解决一个问题的时候如果有明显的两个极端的方案，那么可以在局部采用一个方案，而在整体采用另外一个方案。这个就能很好的融合两者的优点，而尽量较少弊端带来的影响。","link":"/2018/10/03/2018-10-3-计算机组成原理：6、高速缓冲存储器/"},{"title":"七周七并发模型：函数式编程","text":"概念 命令式编程的代码由一系列改变全局状态的语句构成，而函数式编程则是将计算过程抽象成表达式求值。 这些表达式由纯数学函数构成，而这些数学函数是第一类对象（我们可以像操作数值一样操作第一类对象）并且没有副作用。由于没有副作用，函数式编程可以更容易做到线程安全，因此特别适合于并发编程。 为什么在并发和并行问题时会用到函数式编程 有关锁的一些规则，都是针对于线程之间共享的可变的数据——换个说法就是共享可变状态。而对于不变的数据，多线程不使用锁就可以安全地进行访问。 这就是为什么在解决并发和并行问题时函数式编程会如此引人注目——它没有可变状态，所以不会遇到由共享可变状态带来的种种问题。 纯粹的函数式语言中，函数都具有引用透明性——在任何调用函数的地方，都可以用函数运行的结果来替换函数的调用，而不会对程序产生副作用。这个特性也使得可以任意安排多个计算过程的求值顺序，包括让它们并行。 所有函数（至少是理论上）都可以同时执行。这种执行方式被称为数据流式编程（dataflow programming）。 PS：其实本书在第三章函数式编程部分的前两天中的内容，在我看来更多的是利用语言或者运行时本书的并发能力。后续会专门写个文章总结下C#中对应的并发功能。 写在2018.2.8的第一版总结 函数式编程确实是个大话题，在七周七并发模式看到第三章的时候我卡到了函数式编程这里。然后看完了《函数式编程思维》这本书，《C#函数式程序设计》还在路上，我想这是一次很不错的机会，让我好好的学习下。 参考从C#的角度看看 Map、Reduce、Filter分别对应了C# linq中的三个函数 123Map = Select | Enumerable.Range(1, 10).Select(x =&gt; x + 2);Reduce = Aggregate | Enumerable.Range(1, 10).Aggregate(0, (acc, x) =&gt; acc + x);Filter = Where | Enumerable.Range(1, 10).Where(x =&gt; x % 2 == 0); Map从下面函数式编程部分的含义看就是接收一个函数，作用于范畴中每一个值，使得范畴从A变成B。 Filter就是过滤，在我理解里面其实也就是一个传递给map的函数，这里的map是函子中的map。 Reduce，正如下图说的，它是个折叠的作用。要我说就是sum的过程。只不过也许并不是真的对数值进行累加，而是可以做其它的处理。总之细细体会下面图片中的文字吧。 PS:折叠这个词用的好。 来自知乎的一个回答 结论：函数式编程会把数据的结构外显，而命令式则把执行过程外显。或者这样说：你在读函数式代码时，经常会想不清楚执行过程；而你在读命令式代码时，会经常搞不清楚当前对象有哪些属性。 函数式编程思维 函数式编程原文 函数式编程入门教程 范畴 彼此之间存在某种关系的概念、事物、对象等等，都构成”范畴”。随便什么东西，只要能找出它们之间的关系，就能定义一个”范畴”。 范畴的数学模型： 所有成员是一个集合 变形关系是函数 容器 可以把”范畴”想象成是一个容器，里面包含两样东西。 值（value） 值的变形关系，也就是函数。 范畴论与函数式编程的关系 范畴论使用函数，表达范畴之间的关系。 本质上，函数式编程只是范畴论的运算方法，跟数理逻辑、微积分、行列式是同一类东西，都是数学方法，只是碰巧它能用来写程序。 为什么函数式编程要求函数必须是纯的，不能有副作用？因为它是一种数学运算，原始目的就是求值，不做其他事情，否则就无法满足函数运算法则了。 总之，在函数式编程中，函数就是一个管道（pipe）。这头进去一个值，那头就会出来一个新的值，没有其他作用。 函子 函子是函数式编程里面最重要的数据类型，也是基本的运算单位和功能单位。 ++它首先是一种范畴，也就是说，是一个容器，包含了值和变形关系++。比较特殊的是，它的变形关系可以依次作用于每一个值，将当前容器变形成另一个容器。 一般约定，函子的标志就是容器具有map方法。该方法将容器里面的每一个值，映射到另一个容器。 函数式编程里面的运算，都是通过函子完成，即运算不直接针对值，而是针对这个值的容器—-函子。函子本身具有对外接口（map方法），各种函数就是运算符，通过接口接入容器，引发容器里面的值的变形。 PS:实际上函子通过map方法接收函数来实现转换。而所有的计算本质还是这个函数对函子中的值的计算 常见的函子of new一个函子 Maybe Maybe 函子就是为了解决内部值为null而设计的。简单说，它的map方法里面设置了空值检查。 Either 条件运算if…else是最常见的运算之一，函数式编程里面，使用 Either 函子表达。 Either 函子内部有两个值：左值（Left）和右值（Right）。右值是正常情况下使用的值，左值是右值不存在时使用的默认值。 ap 函子B内部的函数，可以使用函子A内部的值进行运算。这时就需要用到 ap 函子。 ap 是 applicative（应用）的缩写。凡是部署了ap方法的函子，就是 ap 函子。 ap是为了解决一个函子使用另一个函子的值的问题。 Monad Monad 函子的作用是，总是返回一个单层的函子。 它有一个flatMap方法，与map方法作用相同，唯一的区别是如果生成了一个嵌套函子，它会取出后者内部的值，保证返回的永远是一个单层的容器，不会出现嵌套的情况。 Monad 函子的重要应用，就是实现 I/O （输入输出）操作。 举例说明： 12345678910111213141516171819202122232425262728class Monad extends Functor { join() { return this.val; } flatMap(f) { return this.map(f).join(); }}// 具体事例var fs = require(&apos;fs&apos;);var readFile = function(filename) { return new IO(function() { return fs.readFileSync(filename, &apos;utf-8&apos;); });};var print = function(x) { return new IO(function() { console.log(x); return x; });}readFile(&apos;./user.txt&apos;).flatMap(print) 上面第一段代码中如果f函数返回一个函子，map本身也是返回函子。这样就的造成了this.map(f)是函子的嵌套。 从事例的角度看，readFile('./user.txt')本身是返回了一个函子IO，其中的值为函数function() { return fs.readFileSync(filename, 'utf-8');}（注意：函子的值可以是函数，而且因为这里的new实际就是上面的of，所以里面的参数应该是值），它其实是从文件中读取到的数据。而.flatMap(print)根据上面的描述它会取出后者内部的值，保证返回的永远是一个单层的容器，不会出现嵌套的情况。。它取出的就是第一个IO函子中的值（函数），然后在将这个值作为参数传递到print函数中。只有就形成了函数链。 PS：以上只是我的理解，这篇文章的评论区有很多质疑，但是因为我确实对这个不了解，所以就按照原文的理解来解释了。","link":"/2018/02/08/2018-2-8-七周七并发模型：函数式编程/"},{"title":"七周七并发模式：Actor","text":"什么是Actor 在本书提到的观点中，认为Actor是一个线程或者进程。在这个线程或者进程中执行了一段代码（函数)，这个代码可以包含状态（数据）也可以不包含。 所谓Actor模型是Sequential Processes和Functions transforming data values两者的结合，可以理解为是综合了过程式计算和函数式计算的一个计算模型。 一个Actor会把接收到的消息映射为三个部分，传给其他Actor的消息，一个新的行为（用来处理下一个消息），和创造一些新的Actors。 为什么会出现Actor 在本书的第二章谈到了线程和锁，其中提到了这个并发模式存在的一些问题，比如竞争共享资源所导致的阻塞、多重锁导致的死锁等问题。 Actor正是为了解决这些问题而产生的。从定义看actor就是多线程，只不过它避免了对于共享资源的并发调用。一个actor只使用自己的资源，而不是直接使用共享资源，它作用单一，顺序执行。不同的Actor之间使用message来传递数据。 PS：这里实际上并不存在真的不使用锁。只要存在多个actor共同访问一个数据对象就存在锁的问题，只不过可能无需开发者自己去写相关的代码。因此书中在提到actor缺点时也提到了可能出现死锁的问题。 PS2：在书中最后使用Actor来统计wiki的例子里，实际上是将wiki的页面进行拆分，然后不同的page用不同的Actor开统计。 消息和信箱 因为actor模型没有提供直接回复消息的机制，所以将发送进程的标识符包含在消息中。通过这个机制，消息的接收者可以回复消息。 异步地发送消息是用actor模型编程的重要特性之一。消息并不是直接发送到一个actor，而是发送到一个信箱（mailbox）。 每个Actor都有一个信箱 分布式 与其说Actor是为了并发，不如说Actor是为了分布式。 书中使用Elixir语言进行了demo的编写。在不同的设备或者操作系统中（这里可以是一个设备上有多个不同的虚拟机，也就是逻辑意义上的一个主机），不同的Actor可以进行通信，可以协作来处理一些数据。整个过程是异步的，每个Actor因为都看上去是无状态的，或者说即使有状态也是内部的。所以每个Actor的运行并不会影响其它Actor。 Actor的实现 这个是我比较郁闷的地方，因为书中使用了Elixir这个我完全不熟悉的语言，因此我对于代码也是看个大概，具体某些语法和函数为什么这么写也是一知半解。 但是从demo code来看，也是创建纤程（这个概念个人认为和golang里面的应该是一样的）来实现actor，而一个actor本质就是一个module，里面包含了一些函数用于处理逻辑，收发消息。 对于Actor可以使用缓存机制来统一进行管理。这样的好处还有可以控制错误的处理。 Actor的错误处理 书中对于Actor的错误处理有这样一个观点：任其崩溃。 这个观点得益于Actor的独立性，在一个Actor出现异常后，以为它对于某些消息的处理是失败的，因此消息队列或者信箱可以将没有处理的消息交给其它的Actor来处理。 出现异常的Actor什么我们可以不做任何的处理。 不过如果出现Actor一启动就崩溃了，那么也不能无限制的创建新的Actor。因此书中提到了Actor创建频率的问题，过高的时候就要考虑错误的问题了。 对于Actor的错误处理建议的做法是创建一个错误处理内核，这就有一个要求了：那么该系统正确运行的前提是其错误处理内核必须正确运行。 如何保证错误处理内核正确运行呢？这需要内核是顶层的管理者，书中是使用actor的缓存来实现的。 同时在错误处理时还要保证消息的必达性： 没有异常发生，消息一定能被送达并被处理 如果某个环节出现异常，异常一定会通知到使用者（假设使用者已经连接到或正在管理发生异常的进程） Actor的优势和缺点 从前面的讲述来看，其优点是： 消息的传输和封装性很好 容错能力比较好 天然支持分布式。 而缺点是： 同样有死锁问题 信箱溢出（这个可能是指的actor如果处理不够及时，mailbox可能会数据量过大) actor本身没有直接提供并发，需要通过并发技术来构造并发方案。 由于多个actor并不共享状态，仅通过消息传递来进行交流，所以不太适合实施细粒度的并行。 吐槽 这本书是好书，不过其使用的编程语言确实比较丰富，导致我看代码时很痛苦。 像是OTP部分完全是依赖于某个编程语言来写的，对于其真正的机制我觉得描述的不够清楚。 参考 为什么我觉得 Actor很难用？ 如果理解并行计算中的参与者模式（Actor Model）？ PS：在这里说下C#的进程间通信实现，可以通过pipe来实现。可以参考：https://gist.github.com/klkucan/b76c85c77fdfcde51aa4eeb1c6f7cd0b","link":"/2018/03/15/2018-3-15-七周七并发模型：Actor/"},{"title":"Unity ECS：概述","text":"前言 看来unity已经认识到现在编写代码的一些问题了：OO的模型、mono所编译的糟糕的机器码、GC和单线程。emmm ECS的推出就是为了解决上面的问题，同时使用ECS是为了能够利用C# Job System和Burst compiler。job system是支持多线程的（( Ĭ ^ Ĭ )） ComponentSystem 在后面的文章中会说到ECS中的Component，这里简单说下，新的component模型只包含了数据，而ComponentSystem包含了行为。 一个ComponentSystem负责在每帧中对物体进行操作，这些物体必须匹配ComponentSystem所定义的一组component。有点类似后面讲到的的EntityArchetype。看下代码的例子： 12345678910111213141516171819202122232425262728293031323334class Rotator : MonoBehaviour{ // The data - editable in the inspector public float Speed;}class RotatorSystem : ComponentSystem{ struct Group { // Define what components are required for this // ComponentSystem to handle them. Transform Transform; Rotator Rotator; } override protected OnUpdate() { // We can immediately see a first optimization. // We know delta time is the same between all rotators, // so we can simply keep it in a local variable // to get better performance. float deltaTime = Time.deltaTime; // ComponentSystem.GetEntities&lt;Group&gt; // lets us efficiently iterate over all GameObjects // that have both a Transform &amp; Rotator component // (as defined above in Group struct). foreach (var e in GetEntities&lt;Group&gt;()) { e.Transform.rotation *= Quaternion.AxisAngle(e.Rotator.Speed * deltaTime, Vector3.up); } }} Rotator是现在系统中的一个MonoBehaviour，而RotatorSystem是一个ComponentSystem。后者包含了一个Group用于匹配GameObject，而OnUpdate方法则是处理行为的函数。 如何在现有的系统中使用ComponentSystem 目前是需要在每个GameObject上挂一个GameObjectEntity脚本，它在OnEnable方法中会创建一个entity，挂上GameObject上的所有组件。然后就能被ComponentSystem使用了。 这意味着你可以将所有的行为处理从MonoBehaviour.Updata中转移到 ComponentSystem.OnUpdate中，数据仍旧可以保持在MonoBehaviour中。 这样做的优势 数据（MonoBehaviour）与行为（ComponentSystem）的分离 一些对象上的系统操作是批量的（应该是基于Job System），便于优化代码。比如上面代码中的deltaTime的使用。 可以继续使用现存的inspector、editor工具等。 劣势 实例化时间没有改善 加载的时间没有改善 数据时随机访问的，非线性。线性数据访问的问题下面会说到。 非多核的 非SIMD 总结来说这样的混合方案性能提升有限 Pure ECS ECS不支持托管类型，支持struct和NativeContainer类型。所以只有IComponentData可以被C# Job安全的访问。 EntityManager（后面会提到）保证了线性的内存布局 ，这是性能提升很重要的部分。通过job和IComponentData可以做到。 目前想将ComponentData添加到GameObject上需要使用ComponentDataWrapper 12345678910// The rotation speed component simply stores the Speed value[Serializable]public struct RotationSpeed : IComponentData{ public float Value;}// This wrapper component is currently necessary to add ComponentData to GameObjects.// In the future we want to make this wrapper component automatic.public class RotationSpeedComponent : ComponentDataWrapper&lt;RotationSpeed&gt; { } 1234567891011121314151617181920212223242526272829303132333435// Using IJobProcessComponentData to iterate over all entities matching the required component types.// Processing of entities happens in parallel. The main thread only schedules jobs.public class RotationSpeedSystem : JobComponentSystem{ // IJobProcessComponentData is a simple way of iterating over all entities given the set of required compoenent types. // It is also more efficient than IJobParallelFor and more convenient. [ComputeJobOptimization] struct RotationSpeedRotation : IJobProcessComponentData&lt;Rotation, RotationSpeed&gt; { public float dt; public void Execute(ref Rotation rotation, [ReadOnly]ref RotationSpeed speed) { rotation.Value = math.mul(math.normalize(rotation.Value), math.axisAngle(math.up(), speed.Value * dt)); } } // We derive from JobComponentSystem, as a result the system proviides us // the required dependencies for our jobs automatically. // // IJobProcessComponentData declares that it will read RotationSpeed and write to Rotation. // // Because it is declared the JobComponentSystem can give us a Job dependency, which contains all previously scheduled // jobs that write to any Rotation or RotationSpeed. // We also have to return the dependency so that any job we schedule // will get registered against the types for the next System that might run. // This approach means: // * No waiting on main thread, just scheduling jobs with dependencies (Jobs only start when dependencies have completed) // * Dependencies are figured out automatically for us, so we can write modular multithreaded code protected override JobHandle OnUpdate(JobHandle inputDeps) { var job = new RotationSpeedRotation() { dt = Time.deltaTime }; return job.Schedule(this, 64, inputDeps); } } 这段代码和ComponentSystem的部分有类似的结构，但是它结合了JobSystem，做到了并发执行。而且里面还有依赖注入的部分，下一篇在将ECS功能的时候会详细来说。 总结 Unity ECS做到了数据与行为的分离，而且更加轻量级。 通过结合JobSystem实现了CPU多核的利用。 目前来看在已有系统结构上使用ECS有点累赘的感觉。","link":"/2018/03/22/2018-3-22-Unity-ECS：概述/"},{"title":"Unity ECS：C# Job System","text":"Job systemJob system解决了什么问题 unity是支持多线程的，虽然有些缺陷。但是我们在代码里面编写大量的线程，即使使用thread pool也无法避免上下文切换的问题。而Job System本质上还是线程(wrok thread)，只不过它的工作线程的数量和CPU逻辑上的核数量一致，这样就避免了上下文切换。 Job System如何工作 在这个系统中真正发挥作用的是job单元，它类似方法的调用，包含了参数和数据。job被填入Job Queue中，然后work thread负责调用它。 job system中有dependency（依赖）的概念，如果job A依赖于job B，那么系统会保证B在A执行前完成。 job system不是现存的任何C#线程模型中的一种。 它被集成在引擎内部，这意味着我们开发者所编写的代码会让unity引擎共享work thread，这样才能避免对于CPU的竟态使用。 PS: 我很怀疑是否代码写的很糟糕的情况下，会影响引擎本身的效率。 Job System如何避免竟态 我觉得文档想描述的很大程度上是数据原子性的问题 job system会检查所有潜在的竟态。 让所有的job操作同一份数据拷贝 job只能访问blittable data(这种数据在托管和非托管中具有相同的内存结构)，而不是managed types。 鉴于上面提到的数据拷贝的就行，为了解决现实世界复杂的问题，提供了NativeContainers： 类型包括：NativeArray, NativeList, NativeHashMap, and NativeQueue. 这些类型能够被unity追踪，谁在读写它们。比如两个job同时写入时需要使用Schedule来安排执行顺序，安全系统会抛出一个明确的异常来说明这些。 多个job同时读取一个数据时是并发的 读写的限制同样适用于main thread 一些container有特殊的规则，以便适应来自ParallelFor jobs的安全、明确的写入访问。比如NativeHashMap.Concurrent允许使用IJobParallelFor并发的添加item。 调度job job system依赖blittable data和NativeContainer 实现步骤： 定一个实现了IJob接口的struct 创建struct对象，填充数据，调用Schedule方法。 调用方法后得到一个job handle对象。它可以做为其它job的依赖对象；也可以等待它完成工作。如果说需要在主线程访问传入job的NativeContainer，那就等待这个handle完成。这部分具体看代码比较好理解。 需要注意的是在主线程想要访问NativeContainers数据之前，需要让所有的 job依赖都完成，此时只用JobHandle.IsDone来判断是不够的，需要手动调用 JobHandle.Complete方法。Complete方法还会清空jobs debugger中的状态。 如果每一帧都调用一个新的job，这个job还依赖于上一帧的job的话，会出现内存泄漏。 从下面的代码可以看出，一个job就是一个实现了IJob的struct。 定义struct： 1234567891011121314151617181920// Job adding two floating point values togetherpublic struct MyJob : IJob{ public float a; public float b; NativeArray&lt;float&gt; result; public void Execute() { result[0] = a + b; }}public struct AddOneJob : IJob{ public NativeArray&lt;float&gt; result; public void Execute() { result[0] = result[0] + 1; }} 创建单个job实例，进行调用： 123456789101112131415// Create a native array of a single float to store the result in. This example will wait for the job to complete, which means we can use Allocator.TempNativeArray&lt;float&gt; result = new NativeArray&lt;float&gt;(1, Allocator.Temp);// Setup the job dataMyJob jobData = new MyJob();jobData.a = 10;jobData.b = 10;jobData.result = result;// Schedule the jobJobHandle handle = jobData.Schedule();// Wait for the job to completehandle.Complete();// All copies of the NativeArray point to the same memory, we can access the result in &quot;our&quot; copy of the NativeArrayfloat aPlusB = result[0];// Free the memory allocated by the result arrayresult.Dispose(); 使用schedule调用多个job 1234567891011121314151617NativeArray&lt;float&gt; result = new NativeArray&lt;float&gt;(1, Allocator.Temp);// Setup the job dataMyJob jobData = new MyJob();jobData.a = 10;jobData.b = 10;jobData.result = result;// Schedule the jobJobHandle firstHandle = jobData.Schedule();AddOneJob incJobData = new AddOneJob();incJobData.result = result;JobHandle handle = incJobData.Schedule(firstHandle);// Wait for the job to completehandle.Complete();// All copies of the NativeArray point to the same memory, we can access the result in &quot;our&quot; copy of the NativeArrayfloat aPlusB = result[0];// Free the memory allocated by the result arrayresult.Dispose(); ParallelFor jobs ParallelForJob适用于对于多个物体的并发操作，比如集合中的item。 并不是每个item对应一个job，而是每个CPU CORE对应一个job。这个也是上文说的为了保证减少上下文切换。 在使用ParallelForJob时需要传递两个参数： 数组的长度，这个数组应该是你要用来迭代的数组。 PS：实际上这部分文档上写的很奇怪，通过长度来区分数组？ 一次批处理的个数，这个决定了job的个数。建议一开始使用的一个job然后慢慢的增加。直到性能提升的不明显了。 PS：其实在并行问题上，线程越多未必能够效率越高。以为还存在一个锁的问题。 12345678910111213// Job adding two floating point values togetherpublic struct MyParallelJob : IJobParallelFor{ [ReadOnly] public NativeArray&lt;float&gt; a; [Readonly] public NativeArray&lt;float&gt; b; public NativeArray&lt;float&gt; result; public void Execute(int i) { result[i] = a[i] + b[i]; }} 12345678var jobData = new MyParallelJob();jobData.a = 10; jobData.b = 10;jobData.result = result;// Schedule the job with one Execute per index in the results array and only 1 item per processing batchJobHandle handle = jobData.Schedule(result.Length, 1);// Wait for the job to completehandle.Complete(); Job System还存在的问题 无法访问static数据，这个功能后续应该会有。 参考 Blittable and Non-Blittable Types","link":"/2018/03/23/2018-3-23-Unity-ECS：C-Job-System/"},{"title":"Unity ECS：基本组件和功能","text":"ECS的组成Entity： 近似一个轻量级的GameObject对象。 内部没有什么东西，这个和GameObject还不一样，毕竟在GameObject的继承链中具有很多成员和函数。 可以添加和移除组件 具有一个ID，这个是唯一稳定的。这个ID是entity在被保存时的唯一引用。 IComponentData和ISharedComponentData 前文说到过，ECS中的Component是一个结构体，里面只有数据。 这个结构体可以继承IComponentData或ISharedComponentData，从源码看这两个接口是空的。 IComponentData可以理解为不同entity之间不同的数据，而ISharedComponentData代表了相同的数据。其实从后者的名称上也可以看到一些蛛丝马迹。 EntityArchetype 其实看到archetype（原型）这个词就大致明白这个类的作用了。 EntityArchetype是一个具有唯一性的ComponentType数组，它可以在创建entity时被作为参数使用，一个entity具有什么能力，完全在于它上面挂了什么Component，而多个component组成了一个能力组，这个就是EntityArchetype了。 1234567891011// Using typeof to create an EntityArchetype from a set of componentsEntityArchetype archetype = EntityManager.CreateArchetype(typeof(MyComponentData), typeof(MySharedComponent));// Same API but slightly more efficientEntityArchetype archetype = EntityManager.CreateArchetype(ComponentType.Create&lt;MyComponentData&gt;(), ComponentType.Create&lt;MySharedComponent&gt;());// Create an Entity from an EntityArchetypevar entity = EntityManager.CreateEntity(archetype);// Implicitly create an EntityArchetype for conveniencevar entity = EntityManager.CreateEntity(typeof(MyComponentData), typeof(MySharedComponent)); EntityManager 一个管理所有EntityData、Archetype、SharedComponentData 和ComponentGroup的类。与ComponentSystems是同等地位的，看来unity ECS确实是一套新的系统。 从下面的代码中可以看出，实际上所有的Entity的创建、添加组件、查询live状态等操作的API都在这个类里面。应该是核心类。 1234567891011121314151617181920212223242526// Create an Entity with no components on itvar entity = EntityManager.CreateEntity();// Adding a component at runtimeEntityManager.AddComponent(entity, new MyComponentData());// Get the ComponentDataMyComponentData myData = EntityManager.GetComponentData&lt;MyComponentData&gt;(entity);// Set the ComponentDataEntityManager.SetComponentData(entity, myData);// Removing a component at runtimeEntityManager.RemoveComponent&lt;MyComponentData&gt;(entity);// Does the Entity exist and does it have the component?bool has = EntityManager.HasComponent&lt;MyComponentData&gt;(entity);// Is the Entity still alive?bool has = EntityManager.Exists(entity);// Instantiate the Entityvar instance = EntityManager.Instantiate(entity);// Destroy the created instanceEntityManager.DestroyEntity(instance); 123456789101112// EntityManager also provides batch APIs// to create and destroy many Entities in one call. // They are significantly faster // and should be used where ever possible// for performance reasons.// Instantiate 500 Entities and write the resulting Entity IDs to the instances arrayvar instances = new NativeArray&lt;Entity&gt;(500, Allocator.Temp);EntityManager.Instantiate(entity, instances);// Destroy all 500 entitiesEntityManager.DestroyEntity(instances); 对entity的一个小总结 EntityManager在生成一个entity时实际使用的是EntityDataManager类中的方法，而EntityDataManager中Entity 当一个entity添加或者移除一个component时，实际上改变了其archetype的结构，此时会创建（优先从已有的archetype集合中查询）一个新的archetype来赋值给entity。参考EntityManager源码中相关的代码。 Chunk chunk是所有ComponentData存储的方式，或者说在内存中的排列方式。 chunk连接着（或者说对应着）一个EntityArchetype。所有使用同一个EntityArchetype的entity都具有相同的内存布局，在内存中这些entity上的components的布局也比较奇特（原谅我用这个词）。它们（components）在存储时按照类型紧密排列的，。同一类型的component实例在内存中被连续的放在一起，后面是另一个类型的所有component实例。 从内存角度看看archetype和chunk 从函数GetOrCreateArchetype可以看到每当新创建一个archetype时本质还是mallco一块内存，但是比较复杂的是一个archetype还包含了很多其它的数据，比如所有ISharedComponentData的类型。 但是正如上面提到的，chunk对于着一个archetype，其实chunk不过是一个内存地址。ChunkAllocator中的m_LastChunk维护这一个chunk的链表。 JobComponentSystem 上一篇最后的代码中提到了JobComponentSystem，它主要是用于自动管理job的依赖。一个例子就是在多个job在操作同一个ComponentData时，如果前面几个是在并行的read数据，突然出现一个write数据的job，此时就要等已经执行的read全部结束后暂停其它的job，让write job完成后在执行其它的。这个东西本质上与.NET的Parallel API是一样的，而大多数并行操作都会采用这样的方式，比如一个典型的例子就是SQLit的操作。 同时系统内部还使用Injection和ComponentGroup在管理依赖。","link":"/2018/03/27/2018-3-27-Unity-ECS：基本组件和功能/"},{"title":"七周七并发模式：通信顺序进程（CSP）","text":"概念CSP 与actor模型类似，通信顺序进程（Communicating Sequential Processe，CSP）模型也是由独立的、并发执行的实体所组成，实体之间也是通过发送消息进行通信。但两种模型的重要差别是：CSP模型不关注发送消息的实体，而是关注发送消息时使用的channel（通道）。channel是第一类对象，它不像进程那样与信箱是紧耦合的，而是可以单独创建和读写，并在进程之间传递。 从这段话可以看出CSP本质上也是独立运行的执行单元，但是它没有mailbox，那么它执行的数据来自哪里呢？来自于channel。 Channel 一个channel就是一个线程安全的队列，任何任务只要持有channel的引用，就可以向一端添加消息，也可以从另一端删除消息。在actor模型中，消息是从指定的一个actor发往指定的另一个actor的；与之不同，使用channel发送消息时发送者并不知道谁是接收者，反之亦然。 也就是说CSP更像是在不同的actor之间共享mailbox，但是这里mailbox编程了channel。 默认情况下，channel是同步的（或称无缓存的）——一个任务向channel写入消息的操作会一直阻塞，直到另一个任务从channel中读出消息。 emmm，阻塞了一个写入的线程。这样有些浪费线程，因此有了带缓存区的channel。当channel的缓存区有足够空间时，向其中写入消息的操作会立刻完成，不会阻塞。 对于有缓存的channel，一次性写入超过缓存区大小的数据时策略也是不同的，可以是只保留前面写入的（dropping），也可以是保留后面写入的(slide)，甚至是直接阻塞式的（blocking），这个一般都有语言级别的策略支持。 PS：是否支持可扩展的buffer这个问题书中提到是不支持，不过可能也只是这个语言不支持。因为我还没有看过其它的编程语言中是如何处理buffer的。 channel也可以被关闭，此时read/write的处理不同的语言可能会有不同的处理方式。 go块 在说这个概念之前需要先看看在它之前的线程操作过程中遇到的问题，只有弄清楚了存在什么问题，我们才能理解为何会有go块，而它又是干什么的。 线程启动和运行时都有一定开销，这正是现在的程序都避免直接创建线程、转而使用线程池的原因。然而线程池并不总是适用。尤其是当程序阻塞时，使用线程池可能会造成麻烦。 线程池技术是处理CPU密集型任务的利器——任务进行时会占用某个线程，任务结束后将线程返还给线程池，使线程可以被复用。但涉及线程通信时使用线程池是否仍然合适呢？如果线程被阻塞，那么它将无限期被占用，这就削弱了使用线程池技术的优势。 这种问题是有一些解决方案的，但它们通常会对代码风格加以限制，使之变成事件驱动的形式。虽然这些方案都能解决问题，但它们破坏了控制流的自然的表达形式，让代码变得难以阅读和理解。更糟糕的是，这些方案还会大量使用全局状态，因为事件处理器需要保存一些数据，以便之后的事件处理器使用。 从上面的摘抄中已经可以看出来多线程、线程池其实是各种局限，而加入了事件驱动后也是有问题的。在这样的情况下，一个能够支持事件驱动，又可以保证代码在编写和阅读时看上去是顺序执行（这样比较符合人的阅读习惯和理解），同时还把状态数据封装起来的东西，emmm，此时我第一个反应就是unity中的Coroutine，而unity的coroutine本质是个状态机。这样一路的推导下来，我们也就明白了go块的本质就是一个状态机。而它的诞生也是为了解决上面说提到的种种问题。 本书中对于go块的使用demo使用了Clojure这个语言，我觉得没必要细说具体实现，因为每个语言也不同。不过go块中需要强调一点，它是非阻塞的。当然如果是阻塞的并不是不能工作，但是又回到了线程大量使用而又阻塞的问题了。 在书中提到go块的成本很低，这与线程不同，因为目前我所知道的语言中go块这样的概念都是基于协程的。golang中甚至没有线程的概念。而C#中task也是协程的。 使用CSP 实际上本章第二节的例子基本都是利用channel的同步性。比如超时处理就可以让一个定时器过一定时间后写入channel，在这之前另一个方法用来读取channel。 还有一些异步操作也是利用了channel的同步性，在以前可能异步操作需要使用回调，但是这样的话不同函数就成了互相调用的情况，但是使用CSP可以让函数基于channel来执行。比如：A函数读取一个channel的数据，在channel被写入数据前，调用A的线程阻塞；在IO操作完成后将结果写入channel，这样A函数就可以读取IO的结果了，而且两个函数不需要知道对方的存在，完全依赖channel来通信。 总结 首先与Actor比，CSP更加灵活。Actor负责通信的媒介（mailbox）与执行单元是紧耦合的，而CSP中channel可以被独立的创建、读写数据。从耦合性上将CSP更好。 然后CSP的go块使得异步编程更加高效，比起写很长的回调式的代码，CSP的代码更简洁。 至于书中提到的CSP的缺点：分布式和容错性支持的不够好，这个我个人觉得因语言而异，因为很少做相关的开发不好发表意见。 参考 Golang的CSP很酷？其实.NET也可以轻松完成 CSP与并发编程","link":"/2018/04/02/2018-4-2-七周七并发模型：通信顺序进程/"},{"title":"游戏设计模式读书笔记：状态模式","text":"解决了什么问题 在游戏开发中状态是一种常见的用于描述游戏对象的方法，在状态比较简单的情况下可能通过多个标志位变量就可以组合出不同的状态。例如书中举得英雄行走、跳跃、蹲下等操作。但是一旦当对象的状态可是变得比较多，而且需要通过比较多的变量才能描述清楚时，只使用标志位变量的弊端就出现了：那就是过多的变量在代码编写时需要的条件语句会很多，而且变量的组合也不利于管理。 使用switch管理状态 首先需要将状态从变量组合变为一个明确的字段，此时我们可以使用enum来实现这个。 在switch中对于每个枚举状态开设分支。这样从一定程度上解决了大量变量带来的编程的复杂度。而且从逻辑上清晰的划分了状态。 但是这个仍旧存在问题，用书中的例子来说，当你需要在某个状态中进行一个计时操作时。就需要在switch代码块和update代码块中修改功能，这说明功能没有能很好的封装，你需要修改两处才能实现功能的修改。如果我们在修改功能的时候只修改一个地方就能够避免一些麻烦，比如一次修改就要同时修改多处，万一遗漏了一个就可能造成bug。 状态模式 允许一个对象在其内部状态发生变化时改变自己的行为，该对象看起来好像修改了它的类型。 这句话有点让人难以理解，实际上状态模式是这么干的： 定义状态接口 让每个状态成为一个类并实现接口 对象持有状态对象的引用，从而使得从外部看（实际就是获取对象的某些属性或者调用函数）这个对象具有不同的状态。 对于一个状态的接口一般都包含如下的函数：Enter、Update、Exit。除此之外也可以根据实际情况设计一些函数，比如设计一个Init函数，它是在状态对象实例化时进行初始化用的。 静态状态：如果一个状态它只有函数没有字段，也就是说它是对象无关的，那么完全可以使用静态类来定义状态，这样做可以节省内存，管理起来也比较简单。 有限状态机（FSM） FSM我个人认为其作用在于专职的管理状态，比如状态的创建、切换、销毁等。 对象持有的不在是一个具体的状态对象，而是一个FSM对象。而状态的切换也需要在FSM中实现，FSM中有一个所有状态的集合，同时保存当前的状态的引用。 在切换状态时先要执行当前状态的Exit函数，然后执行下一个状态的Enter。 在unity中对于不同的FSM一般使用一个专门的管理类来管理所有的FSM。 并发状态机 并发状态机和下面谈到的另外两个其实都是在上面所说的基础上的扩展，用于不同的场景。 顾名思义，并发状态机实际上就是对象同时拥有两种不同的状态。以书中的例子来说，就是英雄角色具有一个状态机，而英雄手中的武器也具有一个状态机。 两个不同的状态机之间可能会有交互，为了完成这个，你也许会在状态的代码中做一些粗糙的if测试其他状态来协同，这不是最优雅的解决方案，但这可以搞定工作。 分层状态机 当不同状态具有某个共同点时使用。 举个例子，我们的英雄也许有站立、行走、奔跑和滑铲状态。在这些状态中，按B跳，按下蹲。如果使用简单的状态机实现，我们在每个状态中的都重复了代码。如果我们能够实现一次，在多个状态间重用就好了。 状态可以有父状态（这让它变为子状态）。当一个事件进来，如果子状态没有处理，它就会交给链上的父状态。 换言之，它像重载的继承方法那样运作。事实上，如果我们使用状态模式实现FSM，我们可以使用继承来实现层次。 定义一个基类作为父状态： 123456789101112131415class OnGroundState : public HeroineState{public: virtual void handleInput(Heroine&amp; heroine, Input input) { if (input == PRESS_B) { // 跳跃…… } else if (input == PRESS_DOWN) { // 俯卧…… } }}; 12345678910111213141516class DuckingState : public OnGroundState{public: virtual void handleInput(Heroine&amp; heroine, Input input) { if (input == RELEASE_DOWN) { // 站起…… } else { // 没有处理输入，返回上一层 OnGroundState::handleInput(heroine, input); } }}; 除了使用继承外，还可以显式的使用状态栈而不是单一状态来表示当前状态的父状态链。栈顶的状态是当前状态，在他下面是它的直接父状态，然后是那个父状态的父状态，以此类推。 当你需要状态的特定行为，你从栈的顶端开始，然后向下寻找，直到某一个状态处理了它。（如果到底也没找到，就无视它。） 下推自动机 下推状态机解决的问题是有限状态机没有任何历史的概念。你记得正在什么状态中，但是不记得曾在什么状态。 没有简单的办法重回上一状态。 有限状态机有一个指向状态的指针，下推自动机有一栈指针。 在FSM中，新状态代替了之前的那个状态。 下推自动机不仅能完成那个，还能给你两个额外操作： 你可以将新状态压入栈中。“当前的”状态总是在栈顶，所以你能转到新状态。 但它让之前的状态待在栈中而不是销毁它。 你可以弹出最上面的状态。这个状态会被销毁，它下面的状态成为新状态。 总结 状态模式在游戏开发中使用的最为广泛的就是FSM，它有效的将游戏对象的不同状态进行了封装，从而使得对象的操作更加简单。 对于单个的游戏对象不同的状态中可能会有更多的操作，比如对象在行走状态下需要控制移动的方向、速度、对于碰撞体的处理等。这个就需要在状态机中进行功能编写了。 对于FSM的实现推荐看下GameFramework中的FSM部分。","link":"/2018/04/21/2018-4-21-游戏设计模式读书笔记：状态模式/"},{"title":"Unity人工智能游戏开发笔记","text":"前言 本着学习一下游戏AI开发的目的看了书，总体来说本书涉及的技术比较浅显，但是胜在面面俱到，很适合没有做过AI开发的同学。 但是本书关于模糊逻辑部分非常坑，令人发指。 概要内容FSM 有限状态机算是最简单的一种AI的实现，它的核心是状态，逻辑运算的结果表现为状态的变化。主要包含三个要点： 转换：状态间的关系 规则：触发某一状态转换 事件：触发规则检查 关于FSM我之前有写过，包括网上也有很多教程。 感知系统 重要概念： Entity：包含玩家主体对象和环境对象 Aspect：标记卡。这个用于让AI判断检测到的物体是不是搜索的目标。 Sense Sense：字面翻译过来就是个感知，它包含了视觉、听觉、触觉、嗅觉和超自然的感知（忽悠人的^_^）。 实现：以下罗列出unity引擎中的实现 视觉：通常用于表达AI是否看到，unity用可以使用多条射线来制作。在视觉中也有FOV的概念，这个在制作射线的时候可以作为因素考虑进去。 听觉、触觉、嗅觉：球体实现。触觉用碰撞体其实是比较好理解，听觉和嗅觉有点抽象，但是本质还是不同的碰撞体检测不同的layer。 超自然的感知：直接通过获取系统数据来实现感知，作弊的行为。 寻路 寻路是游戏中很重要的AI行为，书中提到了A star，也用到了unity的NavMesh组件，在这里就不具体说了。 集群行为 三个基本的概念： 分离性：个体之间保持固定距离 排列的整齐性：整体间相同的方向和速度 内聚性：个体与集群中心位置进保持最小距离 书中实现了多个不同的算法，也利用unity引擎的一些内置功能俩实现。 行为树 行为树体现为任务节点。在行为树中有很多功能不同的节点，有完成基础任务的叶子节点，也有用于逻辑的复合节点和修饰节点。 节点的状态一般分为三种：成功、失败、运行状态（等待） 复合节点 序列（Sequence）：逐个执行node，当出现失败时返回失败；否则一直执行完。node之间是and关系。 选择器（Selector）：只要一个node成功就返回成功，如果运行完了都没有成功的则为false。node之间是or关系。 注意，节点之间的and、or的关系是可以自己控制的。 修饰节点 定义： 修饰节点只包含一个子节点，接受子节点返回的状态。 可以自由组合使用 根据自身的参数估算子节点结果，可以根据设置重新得到一个子节点结果（反相器）或者设置子节点频率（重复器、限制器）。 反相器：NOT标识符，接受与其子节点返回状态相反的结果。 重复器：重复估算子节点特定的次数，直至满足修饰节点定义的条件。 限制器：限制子节点估算次数。 模糊逻辑 在以往的二元逻辑中，基本只有true和false。但是在模糊逻辑中，数值是[0,1]，在这个区间内的值代表着一种模糊的状态。 三个步骤 模糊化：根据隶属度函数从具体的输入得到对模糊集隶属度的过程。 推理方法：从模糊规则和输入对相关模糊集的隶属度得到模糊结论的方法。 去模糊化：将模糊结论转化为具体的、精确的输出的过程。 这部分的内容请移步游戏开发中的人工智能（十）：模糊逻辑 。 本书模糊逻辑部分根本就是不完整的，内容质量非常的差。","link":"/2018/08/29/2018-8-29-Unity人工智能游戏开发读书笔记/"},{"title":"开发ECS style项目的思考","text":"概述 这篇文章是近期在学习Entitas时对于ECS的进一步思考 其中会包含在使用ECS时需要注意的一些重要原则 这些原则在使用Entitas时如何实现 这篇文章不会讲Entitas的具体代码和功能，这需要每个使用者自己去看源码和demo。 ECS的使用原则数据驱动一切 ECS的目的就是将数据与行为进行解耦，而ECS中行为（System）的执行是依赖于数据（Component）的。 这个依赖应该分为两个方向来看，第一是变化的数据，它造成了事件的发生；第二是非变化的数据，它提供了Update中逻辑执行的数据。 外部的输入（Input、Net、Bluetooth）改变的是数据，这些数据经过System的处理（非必须）后可能被用来驱动View层，或者用来改变其它的数据，从而产生新一轮的System处理数据。 ECS只包含数据与逻辑 ECS是一种开发模式、是一种思维方式，它的实现是不依赖与具体语言、引擎或特定环境的。ECS系统中应该只包含entity、component、system，以及其它辅助的类。 这样的认知就要求我们在使用时要将ECS的数据、逻辑与具体实现分离开，请细细品味 I am abstracting the logic from the implentation, the what from the how. ECS与外部实现解耦 ECS与外部实现交互时遵从面向接口编程的原则：从函数调用层面讲不要在ECS系统中直接调用外部对象的函数，因为这必然要求component持有一个具体的对象，导致ECS引用了外部的类定义。此时ECS应该是持有一个接口的实现对象。 从数据层面讲，ECS中的类型不依赖于任何第三方的定义。比如表示位置的Vector3，它应该是ECS内部定义的，而不应该依赖于外部定义的类型（比如Unity中的Vector3）。 尽量避免component持有对象的引用，哪怕是基于接口的。使用事件机制可以做到更好的解耦。 在事件机制的基础上，应该尽量做到上层功能依赖底层功能，反之则不行。也就是说外部实现可以使用ECS的方法、修改component的数据。但是ECS内部可以做到不知道有外部对象这回事，因为在完全使用事件系统的情况下，ECS调用外部函数都可以通过触发事件的方式来调用。 忘却OOP 这点对于大家来说比较难，MonoBehaviour自身也是OOP的。但是从和大家的讨论结果来看，忘却继承、多态有助于更好的写出ECS style的代码。 如何使用Entitas它山之石可以攻玉 下图是一位国外开发者对于使用Entitas，或者说是使用ECS的经验总结。里面用了非常多的代码例子来讲述如何解耦ECS与具体的实现，建议所有使用Entitas的人都看一下，链接在最后。 在这幅图中ECS通过interface与View和Service交互，具体的实现可以是unity或者是其它的引擎。 里面的箭头也很好定义了一个workflow，service层改变了ECS中component的数据，引发system的处理，最终引发VIEW层的变化。 Entitas中的System 说到System就要提一下Entitas中两种处理数据变化的方式，一种是响应式的，一种是轮询式的。 响应式处理需要使用继承自ReactiveSystem的system，虽然在底层它还是会去轮询，但是在使用层面上它只是处理发生了变化的component。 而轮询式的则要求system继承自IExecuteSystem，它会在每帧去调用一次Execute方法。 对于不同功能的component应该合理的去选择它对应的system，从之前讨论的结果看，绝大多数component都应该是对应的ReactiveSystem。因为响应式会比较高效，只有当系统中entity上的component发生了Add/Remove操作，或者component中的数据发生了变化后才会执行相关的操作。 一些使用ECS实现的功能 下面会对一些常见的功能如何使用ECS实现来进行讨论，目前为止这些实现只存在于讨论的层面，当然这些实现是基于Entitas的。 FSM FSM的核心是状态（state）和状态变化所引发的函数调用。 以点击跳跃按钮触发玩家播放跳跃动画为例： ECS中添加一个PlayerAnimatorStateEntity，添加PlayerAnimatorStateComponent，里面的变量是一个string类型的state，利用它的改变来驱动玩家身上动画状态机的切换。 在PlayerGameObject创建时需要监听state改变的事件。 View层识别到一个按钮的点击（Unity自己的事件机制），ECS中产生一个PlayerJumpEntity，它上面add了一个PlayerJumpComponent。组件中无需任何数据，因为当ECS中出现这个组件时就已经代表jump按钮被按下了。 在这里需要注意，如果点击按钮只是改变动画，那么VIEW里面按钮点击可以直接改PlayerAnimatorStateComponent中state变量的值。 PlayerJumpSystem是一个ReactiveSystem，它在执行Execute函数时改变state的值引发事件，从而使得PlayerGameObject可以改变animator的状态。 伤害技能系统 未完待续 引用How I build games with Entitas (FNGGames)","link":"/2018/07/20/2018-7-20-开发ECS-style项目的思考/"},{"title":"计算机组成原理：1、组成原理到底研究的什么","text":"这是对哈尔滨工业大学网络课程《计算机组成原理》的笔记 计算机系统层次从程序的角度看分为下面5层： 高级语言层：Java、C、C++、C#等，需要编程成机器语言 汇编层：也需要编译成机器语言，符号语言和机器语言的指令基本是一一对应的。 操作系统：提供机器语言与编程语言的 机器语言：就是计算机所提供的语言了，根据地址从存储器读取-&gt;送往控制器译码-&gt;计算器。操作有顺序要求，并非全部是并发。 微指令系统：机器指令的细化，在某个时间点上可以执行的操作放到一个微指令当中，执行上有先后顺序的放到不同的微指令中。 从下往上看这个层级： 多个微指令构成一个微程序，微指令是由硬件直接执行的。 一个微程序对应一个机器指令，用微指令解释机器指令。 用机器指令解释操作系统 ————软硬件分割线————— 用汇编程序翻译成机器语言程序 用编译程序翻译成汇编语言程序 实际上OS除了管理硬件、软件外。从编程的角度看OS提供了编程语言与机器语言的接口。 对于在机器上编写程序的人来说，计算机组成在设计上就要提供一套微指令集给程序员，并且要定义哪些指令可以操作什么类型的数据（数据表示）。实际上在机器指令集设计的时候对于不同数据类型的相同操作可能会有不同的指令（e.g 整数和浮点数的加法运算） 计算机组成原理所研究是就是硬件部分的设计，需要实现计算机体系结构所体现的属性。比如：当程序员询问有没有乘法指令？这个指令能对什么类型的数据操作？长度限制是多少？那种做计算机组成设计的人就要负责具体指令的实现。（从纯软件编程的角度说，计算机组成可以理解为一个lib，在设计的时候要确定有什么接口，接口的实现要怎么做，里面有哪些定义的数据，这些数据哪些接口理由操作、怎么操作等问题）","link":"/2018/09/19/2018-9-19-计算机组成原理：1、组成原理到底研究的什么/"},{"title":"计算机组成原理：4、存储器概述","text":"分类 按照介质 按照存取方式 存取时间与物理地址无关（随机访问） 随机存储器（RAM）: 在程序执行过程中可以读写 制度存储器（ROM）：在程序执行过程中只能读 存取时间与物理地址有关（串行访问） 顺序存取存储器：磁带 直接存取存储器：磁盘 按照作用 主存储器 RAM 静态RAM（cache） 动态RAM（内存芯片） ROM（只读，但是不同的）（BIOS ROM） MROM：Mask Read-Only Memory，中文全称“掩模式只读存储器”。掩模式只读存储器的内容是由半导体制造厂按用户提出的要求在芯片的生产过程中直接写入的，写入之后任何人都无法改变其内容。 PROM：可编程ROM EPROM：可擦除可编程ROM，是一种断电后仍能保留数据的计算机储存芯片。一旦编程完成后，EPROM只能用强紫外线照射来擦除。 EEPROM：EEPROM（带电可擦写可编程读写存储器）是用户可更改的只读存储器（ROM），其可通过高于普通电压的作用来擦除和重编程（重写）。不像EPROM芯片，EEPROM不需从计算机中取出即可修改。 Flash Memory → SSD 高速缓存存储器（Cache） 辅助存储器 存储器层次 寄存器并非只存在于CPU，IO端口中也有。 对于指令能够操作的寄存器叫体系结构寄存器，对应的指令无法操作的register就是非体系结构寄存器。 早期CPU中是没有cache的，随着发展一部分cache进入到了CPU。cache的作用是做CPU与主存的中间层，因为cache的访问速度更快，可以更CPU更好的配合。 缓存-主存层次与主存-辅存层次 缓存-主存是为了速度，由硬件连接 主存和辅存是为了容量，有软硬件连接 主存和辅存构成虚拟存储器，在程序使用时识别的是虚拟地址（逻辑地址），所以我们写程序的时候往往看到的初始内存地址为0。当程序被装入内存或指令要执行的时候，由特定的机构把逻辑地址转化为内存中的物理地址。 缓存和主存使用的地址是主存的实地址（物理地址） 缓存按内容查找 缓存中保存的指令中的地址码保存的是主存的地址，把这个主存地址转化成缓存中的块号和块内偏移地址。 参考 https://baike.baidu.com/item/MROM https://baike.baidu.com/item/EEPROM https://baike.baidu.com/item/EPROM","link":"/2018/09/21/2018-9-21-计算机组成原理：4、存储器概述/"},{"title":"Unity ECS：C# Job System文档总结","text":"背景、初衷、目标 出现的背景、初衷就是：天下苦无多线程久已 当然这个说法要进一步的约束，首先unity中可以编写多线程代码，但是最大的问题是多线程中无法使用unity API，当然也无法修改component中的数据了。 目前来看似乎这个技术就是为了能够让开发者使用multithread来操作unity API和component 数据。 优势和劣势 多线程就是优势 可操作的数据类型限制比较大，目前只能是blittable data type 这个多线程是和unity引擎共享work thread，所以变相的侵占了引擎层的性能。 组成部分和关键点组成 job system job system管理一组worker thread，通常每个逻辑上的CPU的核（core）可以跑一个worker。这是为了避免上下文切换带来的性能问题。 job system会把一些job放入一个队列，然后worker thread从队列中取出job进行执行。 job：最小工作单元，接受参数和操作作为数据。job是可以自足的，也可以依赖其他的job。 NativeContainer： 一个托管的值类型，对native memory提供安全的C#的包装器。 包含一个指向非托管内存地址的指针 job system中NativeContainer允许job和主线程共享数据，而不是copy的数据。 关键点保障执行顺序和数据竟态 job system管理job之间的依赖，保证执行的正确。 job system通过深拷贝（memcpy）数据来解决竟态问题，带来的问题就是只能访问blittable data type。 job system在托管和native之间传递copy的data，调度job时使用memcpy将数据放到native memory，然后在job执行时给托管代码这边访问数据的能力。 NativeContainer safety system的缺点是因为采用了copy数据的方式，所以数据结果在job之间是独立的。可以想象对于有执行顺序依赖的job，这样的结果是错误的。NativeContainer就是以为了解决这个问题。 NativeContainer包含的数据结果： NativeList - a resizable NativeArray. NativeHashMap - key and value pairs. NativeMultiHashMap - multiple values per key. NativeQueue - a first in, first out (FIFO) queue. Allocator：分配器，不同的分配器区别主要在对于NativeContainer对象lifetime的影响。 Allocator.Temp：NativeContainer的lifespan只在一帧内，不能将这样的NativeContainer传递给job。而且要在某个使用了它的函数结束前调研Dispose方法来销毁NativeContainer。内存分配的速度很快（怀疑是在一个已经分配好的shared memory中）。 Allocator.TempJob：中速，lifespan 4帧，线程安全。多数比较小的job都使用这个。如果4帧后没有销毁，会有一个来自native code的警告输出。 Allocator.Persistent：最慢，NativeContainer长存。本身是malloc的包装器。 NativeContainer中的safety system 注意：所有NativeContainer中的安全监测只在Editor和Play Mode有效。也就是真机无需。 DisposeSentinel：发现内存泄漏，然后给出error。 AtomicSafetyHandle：转移NativeContainer的控制权。这个有效需要使用宏：ENABLE_UNITY_COLLECTIONS_CHECKS 不管是主线程还是job对于NativeContainer的访问仍旧是同一时间只允许一个写操作，但是支持并发读操作。 如果NativeContainer被设计为只读的可以使用[ReadOnly] 注意：job中访问静态数据绕过了所有的保护系统，可能引起unitycrash。 创建job 创建一个inherit IJob的struct 添加成员变量，只能是NativeContainer或者blittable types 创建Execute函数，job运行时Execute函数在CPU core中会执行一次。 注意：job中操作的数据除了NativeContainer的外都是一份拷贝。job中访问主线程中数据的唯一方式就是用操作NativeContainer类型的数据。（调用job的代码中很好的体现了这个） 代码参考原文文档 使用job 直接调用job的Schedule方法 调用Schedule方法将job放到一个队列中，一旦放入就不能中断。 Schedule方法只能在主线程调用。 注意源码最后释放了NativeArray类型的result，因为它的分配器是TempJob。 代码参考原文文档 JobHandle和依赖 JobHandle是Schedule函数的返回值 在job存在依赖时利用它来设置依赖 多依赖时使用CombineDependencies 当在主线程需要等待job完成，可以使用Complete方法。 ParallelFor jobs 利用多和并发执行job 可以通过这种参数决定在native层有多少个batch 参数中的lenght应该是作为输出结果的NativeContainer的lenght，它告诉job system有多少execute函数要执行。 innerloopBatchCount从字面看应该是batch中有多少个job，从下面代码的注释看也是这个意思。// Schedule the job with one Execute per index in the results array and only 1 item per processing batchJobHandle handle = jobData.Schedule(result.Length, 1); 底层原理和关键实现 底层实现全部被封装到了DLL中，SHIT! 对比 对比C#中的Thread类 Thread使用的是从系统申请来的现场，而job system是与引擎共享的线程，在没有源码的情况下姑且认为是有不同的。 对于可操作对象的不同，Thread只能操作非引擎的对象，而job system是操作的引擎对象，虽然是受限的。 从管理上也不一样，Thread需要自己控制执行的顺序但是job system的顺序是通过设置后引擎来管理的。 对比协程 单线程与多线程的差异 但是协程是可以控制所有的unityengine对象的，例如物理、动画等。这些job system还做不到，只能依赖MonoBehaviour。 因此在大规模计算的数据是NativeContainer或者blittable types的时候在性能上肯定是碾压协程的。 原文C# Job System","link":"/2018/09/26/2018-9-26-Unity-ECS：C-Job-System文档总结/"},{"title":"iOS学习笔记-02集合","text":"2.集合 集合分为可变与不可变。 泛型，写法NSMutableArray&lt;NSNumber*&gt;* mutablearr = [NSMutableArray array];和NSMutableDictionary&lt;NSString*, NSNumber*&gt;* dic = [[NSMutableDictionary alloc] init];,目前会有warning提示如果类型不对。多参数泛型如下，第二行为Xcode的提示性代码。 12NSMutableDictionary&lt;NSString*, NSNumber*&gt;* dic = [[NSMutableDictionary alloc] init];[dic addEntriesFromDictionary:&lt;#(nonnull NSDictionary&lt;NSString *,NSNumber *&gt; *)#&gt;] 目前来看类型只能是Objective-C object或者block。 NSArray 原文 NSArray特点: 一旦创建成功,内容不可改变，只能存放OC对象。 1234567891011121314151617//1)创建一个空数组 NSArray *arr1 = [NSArray array]; //2)创建数组,只有一个元素 NSArray *arr2 = [NSArray arrayWithObject:@&quot;1&quot;]; //3)创建数组,有多个元素 // nil 表示数组赋值结束 // 常见写法 NSArray *arr3 = [NSArray arrayWithObjects:@&quot;one&quot;,@&quot;two&quot;,@1, nil]; NSLog(@&quot;arr3 = %@&quot;,arr3); //4)调用对象方法,创建数组 //nil Nil NULL NSNULL NSArray *arr4 = [[NSArray alloc] initWithObjects:@&quot;three&quot;,[NSNull null],@&quot;four&quot;, nil]; NSLog(@&quot;arr4 = %@&quot;,arr4); //5)用一个数组可以创建另外一个数组，修改一个数组中的数据不影响另一个数组。 NSArray *arr5 = [NSArray arrayWithArray:arr3]; 常用方法: 1234567891011121314151617181920212223NSArray* arr3 = [NSArray arrayWithObjects:@&quot;one&quot;, @&quot;two&quot;, @1, @&quot;three&quot;, nil];NSLog(@&quot;arr3 = %@&quot;, arr3);//1)获取数组的长度 count获取数组的元素的个数NSLog(@&quot;%ld&quot;, arr3.count);//2)根据下标,获取下标对应的对象NSLog(@&quot;%@&quot;, [arr3 objectAtIndex:3]);//3)返回元素的下标NSUInteger loc = [arr3 indexOfObject:@&quot;three&quot;];NSLog(@&quot;%ld&quot;, loc);//4)数组中是否包含了某个元素if ([arr3 containsObject:@&quot;four&quot;]) { NSLog(@&quot;包含此元素&quot;);}else { NSLog(@&quot;不包含&quot;);}NSLog(@&quot;arr5 = %@&quot;, arr5); 简化形式 123456789101112//用简化的方式,来定义和访问数组元素//1)用简化的方式,定义数组//格式: @[ 数组元素 ]NSArray* arr = @[ @&quot;1&quot;, @&quot;one&quot;, @&quot;3&quot;, @4, @&quot;ONE&quot; ];NSLog(@&quot;arr = %@&quot;, arr);NSString* str = [arr objectAtIndex:2];NSLog(@&quot;%@&quot;, str);//2)用简化的方式访问数组元素str = arr[1]; //C语言形式的数组元素访问NSLog(@&quot;%@&quot;, str); 遍历 123456789101112131415161718192021222324252627282930313233343536373839404142 //定义一个数组 NSArray* arr = @[ @&quot;one&quot;, @&quot;two&quot;, @&quot;three&quot;, @&quot;four&quot; ]; //对数组进行遍历 //1) 普通的方式,通过下标访问 for (int i = 0; i &lt; arr.count; i++) { NSLog(@&quot;-&gt; %@&quot;, arr[i]); } //2) 快速枚举法 for循环的增强形式 for (NSString* str in arr) { NSLog(@&quot;---&gt; %@&quot;, str); } //3) 使用block的方式,进行访问 // 数组元素 元素下标 是否停止 //stop:YES 会停止, stop:NO 不会停止 [arr enumerateObjectsUsingBlock:^(id obj, NSUInteger idx, BOOL* stop) { if (idx == 2) { *stop = YES; //停止 // break; } else { NSLog(@&quot;idx = %ld,obj = %@&quot;, idx, obj); } }]; //补充：OC1.0中的方法 id obj2; NSEnumerator* enumerator = [arr objectEnumerator]; while ((obj2 = [enumerator nextObject]) != nil) { NSLog(@&quot;%@ &quot;, obj2); }``` 5. 读写文件: - 写入 NSArray* array = [NSArray arrayWithObjects:@”one”, @”zbz”, @”cgx”, @”sb”, @”cjk”, @”senni”, nil]; //把NSArray 中的内容,写入到文件中 //arr.plist 一种特殊的文件格式 BOOL isWrite = [array writeToFile:@”/Users/zhaoxiaohu/Desktop/arr.xml” atomically:YES]; if (isWrite) { NSLog(@&quot;写入成功&quot;); }12- 读取 //从文件中,读取一个数组信息 NSArray *readArr = [NSArray arrayWithContentsOfFile:@”/Users/zhaoxiaohu/Desktop/arr.xml”]; NSLog(@”readArr = %@”,readArr); 1234 6. NSArray与字符串: - 把数组拼接成为字符串 //定义一个数组 NSArray *arr = @[@1,@2,@3,@4]; //1)需求: 把数组中的元素用 “-“ 连接起来 // [数组 componentsJoinedByString @”分隔符”]; // 1-2-3-4 NSString *str = [arr componentsJoinedByString:@”-“]; NSLog(@”str = %@”,str); 12 - 把字符串拆分为数组 //2) 给一个字符串,分割成一个数组 // 400-800-12580 //取得 400 12580 800 NSString *str2 = @”400-800-12580”; NSArray *arr2 = [str2 componentsSeparatedByString:@”-“]; NSLog(@”%@”,[arr2 firstObject]); NSLog(@”%@”,[arr2 lastObject]); NSLog(@”%@”,arr2[1]); 12345678 - #### NSMutableArray - NSArray子类，内容可变，其余很多操作与NSArray一样。 ``` NSMutableArray&lt;NSNumber*&gt;* mutablearr = [NSMutableArray array]; [mutablearr addObject:[NSNumber numberWithInt:1]]; 虽然有arrayWithCapacity这个方法，但是内容是可以超出设定的值的。应该仅仅是申请内存的需要，毕竟可变长度对于内存操作上比较麻烦。 NSDictionary与NSMutableDictionary字典的核心在于key和value。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//创建字典 //1、使用类方法创建字典 // 字典初始化后，内部是无序的 NSDictionary* dict1 = [NSDictionary dictionaryWithObjectsAndKeys:@&quot;zhangsan&quot;, @&quot;zs&quot;, @&quot;lisi&quot;, @&quot;ls&quot;, nil]; //获取字典的长度 NSLog(@&quot;%ld&quot;, dict1.count); //根据key获取 value 只获取zs NSString* s = [dict1 objectForKey:@&quot;zs&quot;]; NSLog(@&quot;%@&quot;, s); //2、快速创建字典 @{key:value,key1:value1} // 在字典中，key值是不能够重复的，重复的时候不会报错 // 重复的只保留一个（第一次出现的那个） NSDictionary* dict2 = @{ @&quot;zs&quot; : @&quot;zhangsan&quot;, @&quot;ls&quot; : @&quot;lisi&quot;, @&quot;zs&quot; : @&quot;fengjie&quot; }; NSLog(@&quot;%@&quot;, dict2); //3、遍历 NSLog(@&quot;获取所有keys的遍历&quot;); NSArray* keys = [dict2 allKeys]; for (NSInteger i = 0; i &lt; keys.count; i++) { NSLog(@&quot;key = %@ value = %@&quot;, (NSString*)keys[i], [dict2 objectForKey:keys[i]]); } NSLog(@&quot;NSEnumerator遍历&quot;); id key; NSEnumerator* enumerator = [dict2 keyEnumerator]; while ((key = [enumerator nextObject]) != nil) { NSLog(@&quot;key = %@ value = %@&quot;, (NSString*)key, [dict2 objectForKey:key]); } NSLog(@&quot;快速遍历&quot;); for (id key in dict2) { NSLog(@&quot;key = %@ value = %@&quot;, (NSString*)key, dict2[key]); } NSLog(@&quot;block遍历&quot;); [dict2 enumerateKeysAndObjectsUsingBlock:^(id _Nonnull key, id _Nonnull obj, BOOL* _Nonnull stop) { NSLog(@&quot;key = %@ value = %@&quot;, key, obj); }]; //4、可变的字典 NSMutableDictionary* mDic = [NSMutableDictionary dictionaryWithDictionary:dict1]; //4.1 移除数据 [mDic setValue:nil forKey:@&quot;zs&quot;]; [mDic removeObjectForKey:@&quot;ls&quot;]; [mDic removeAllObjects]; // [mDic removeObjectForKey:&lt;#(nonnull id)#&gt;]; //4.2 添加数据 [mDic setObject:@&quot;wei&quot; forKey:@&quot;hua&quot;]; [mDic setValue:@&quot;xing&quot; forKey:@&quot;zhong&quot;]; //4.3 改变数据 [mDic setObject:@&quot;lisi2222&quot; forKey:@&quot;ls&quot;]; NSLog(@&quot;遍历NSMutableDictionary&quot;); [mDic enumerateKeysAndObjectsUsingBlock:^(id _Nonnull key, id _Nonnull obj, BOOL* _Nonnull stop) { NSLog(@&quot;key = %@ value = %@&quot;, key, obj); }]; 注意setValue:forKey:这个方法，既可以添加数据也可以移除数据（当value是nil时）。 123 /* Send -setObject:forKey: to the receiver, unless the value is nil, in which case send -removeObjectForKey:.*/- (void)setValue:(nullable ObjectType)value forKey:(NSString *)key; NSSet &amp; NSMutableSet 原文 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107在Foundation框架中，提供了NSSet类，它是一组单值对象的集合，且NSSet实例中元素是无序，同一个对象只能保存一个。 一.不可变集合NSSet 1.NSSet的初始化 创建一个集合 NSSet *set1 = [[NSSet alloc] initWithObjects:@&quot;one&quot;, @&quot;two&quot;, nil]; 通过数组的构建集合 NSArray *array = [NSArrayWithObjects:@&quot;1&quot;, @&quot;2&quot;, @&quot;3&quot;, nil]; NSSet *set2 = [[NSSet alloc] initWithArray:array]; 通过已有集合构建集合 NSSet *set3 = [[NSSet alloc] initWithSet:set2]; 2.NSSet常用方法 集合中对象的个数 int count = [set3 count]; 以数组的形式返回集合中所有的对象 NSArray *allObjects = [set3 allObjects]; 返回集合中的任意一个对象 id object = [set3 anyObject]; 判断两个集合的元素中有包含的对象，包含返回YES，否则为NO BOOL isContain = [set4 containsObject:@&quot;2&quot;]; 判断两个集合的元素是否有相等的对象，存在返回YES，否则为NO BOOL isIntersect = [set4 intersectsSet:set2]; 判断两个集合的元素是否完全匹配，匹配返回YES，否则为NO BOOL isEqual = [set4 isEqualToSet:set5]; 集合4是否是集合5的子集合，如果是返回YES，否则为NO BOOL isSubset = [set4 isSubsetOfSet:set5]; 创建一个新的集合2，集合2有两个对象 NSSet *set1 = [NSSet setWithObjects:@&quot;a&quot;,nil]; NSSet *set2 = [set1 setByAddingObject:@&quot;b&quot;]; 通过已有的两个集合，创建新的一个集合 NSSet *set7 = [NSSet setWithObjects:@&quot;a&quot;,nil]; NSSet *set8 = [NSSet setWithObjects:@&quot;z&quot;,nil]; NSSet *set9 = [set7 setByAddingObjectsFromSet:set8]; 通过已有的集合和数组对象，创建一个新的集合 NSArray *array = [NSArray arrayWithObjects:@&quot;a&quot;,@&quot;b&quot;,@&quot;c&quot;,nil]; NSSet *set10 = [NSSet setWithObjects:@&quot;z&quot;,nil]; NSSet *set11 = [set10 setByAddingObjectsFromArray:array]; 二、可变集合NSMutableSet 常用方法 创建一个空的集合 NSMutableSet *set1 = [NSMutableSet set]; NSMutableSet *set2 = [NSMutableSet setWithObjects:@&quot;1&quot;,@&quot;2&quot;,nil]； NSMutableSet *set3 = [NSMutableSet setWithObjects:@&quot;a&quot;,@&quot;2&quot;,nil]; 集合2减去集合3中的元素，集合2最后元素只有1个 [set2 minusSet:set3]; 集合2与集合3中元素的交集，集合2最后元素只有1个 [set2 intersectSet:set3]; 集合2与集合3中的元素的并集，集合2最后元素只有3个 [set2 unionSet:set3]; 将空集合1设置为集合3中的内容 [set1 setSet:set3]; 根据数组的内容删除集合中的对象 [set2 addObjectsFromArray:array]; [set2 removeObject:@&quot;1&quot;]; [set]2 removeAllObjects]; 关于遍历 从NSArray的遍历中就可以看出目前基本有四种遍历方法，分别是for、快速遍历，OC1.0的Enumerator方法和block遍历。 对于这四种遍历来说，block应该是通用性最好的。NSArray往往需要下标值，而dictionary需要key和value，NSSet只是需要内容。对于不同的需求来说，前三个方法没有通用性。block方法为不同的集合有不同的实现方法，enumerateObjectsUsingBlock和enumerateKeysAndObjectsUsingBlock，而且提供了类似enumerateKeysAndObjectsWithOptions这样的方法，可以选择是反序遍历或者并发遍历。 关于NSNumber在使用数组和字典时会发现其内容不能使用简单类型，比如int，float，bool类型等，此时就需要用到NSNumber了，通过转换保存数值到数组或者字典。当然也可以通过@1这样的形式来讲数值保存到数字或字典。 1234NSMutableArray* mutablearr = [NSMutableArray arrayWithArray:@[ @9, @8 ]];[mutablearr addObject:[NSNumber numberWithInt:1]];[mutablearr addObject:[NSNumber numberWithInt:2]];[mutablearr addObject:@1]; NSCache缓存应该选择的数据类型，dictionary和array在iOS中并不是很好的缓存选择，更好的选择应该是NSCache。原因如下： 1.对于键值是retain而不是copy，这个是很dictionary本质的区别。 2.线程安全，支持多线程操作。 3.自己实现了很多控制性的功能，比如对象的多少，最大存储量(但是limits are imprecise/not strict，逗比！！！)，在内存不足（didReceiveMemoryWarning）时可以自动的删除，并且按照优先删除最久未使用的对象。 参考 NSUserDefaults 原文 了解NSUserDefaults以及它可以直接存储的类型 NSUserDefaults是一个单例，在整个程序中只有一个实例对象，他可以用于数据的永久保存，而且简单实用，这是它可以让数据自由传递的一个前提，也是大家喜欢用它保存简单数据的一个主要原因。 使用 NSUserDefaults 存储自定义对象的最初，我们必须认识NSUserDefaults可以存储哪一些类型的数据，下面一一列出： NSUserDefaults支持的数据类型有：NSNumber（NSInteger、float、double），NSString，NSDate，NSArray，NSDictionary，BOOL. 如果想要将上述数据类型的数据永久保存到NSUserDefaults中去，只需要简单的操作(一个Value 一个Key ),例如，想要保存一个NSString的对象，代码实现为： 12345678910//将NSString 对象存储到 NSUserDefaults 中NSString *passWord = @&quot;1234567&quot;;NSUserDefaults *user = [NSUserDefaults standardUserDefaults];[user setObject:passWord forKey:@&quot;userPassWord&quot;];将数据取出也很简单，只需要取出key 对应的值就好了，代码如下：NSUserDefaults *user = [NSUserDefaults standardUserDefaults];NSString *passWord = [ user objectForKey:@&quot;userPassWord&quot;]; 注意：对相同的Key赋值约等于一次覆盖，要保证每一个Key的唯一性 &lt;font color=red&gt;值得注意的是：&lt;/font&gt; NSUserDefaults 存储的对象&lt;font color=red&gt;全是不可变的&lt;/font&gt; （这一点非常关键，弄错的话程序会出bug），例如，如果我想要存储一个 NSMutableArray 对象，我必须先创建一个不可变数组（NSArray）再将它存入NSUserDefaults中去，代码如下：12345NSMutableArray *mutableArray = [NSMutableArray arrayWithObjects:@&quot;123&quot;,@&quot;234&quot;, nil];NSArray * array = [NSArray arrayWithArray:mutableArray]; NSUserDefaults *user = [NSUserDefaults standardUserDefaults];[user setObject:array forKey:@&quot;记住存放的一定是不可变的&quot;]; 取出数据是一样的，想要用NSUserDefaults中的数据给可变数组赋值 先给出一个错误的写法：12345/*-------------------------错误的赋值方法-------------------*/NSUserDefaults *user = [NSUserDefaults standardUserDefaults];//这样写后，mutableArray 就变成了不可变数组了，如果你要在数组中添加或删除数据就会出现bugNSMutableArray *mutableArray = [user objectForKey:@&quot;记住存放的一定是不可变的&quot;]; 正确的写法：12345/*-------------------------正确的赋值方法-------------------*/NSUserDefaults *user = [NSUserDefaults standardUserDefaults];//可以用alloc 方法代替NSMutableArray *mutableArray = [NSMutableArray arrayWithArray:[user objectForKey:@&quot;记住存放的一定是不可变的&quot;]]; 使用 NSUserDefaults 存储自定义对象 1、将自定义类型转换为NSData类型 当数据重复而且多的时候（例如想存储全班同学的学号，姓名，性别（这个数据量可能太大了 ）），如果不用SQLite 存储 （多数据最好还是用这个），你可以选择使用归档，再将文件写入本地，但是这种方式和 NSUserDefaults 比起来麻烦多了（因为NSFileManage 本来就挺复杂） ，但是问题是，NSUserDefaults 本身不支持自定义对象的存储，不过它支持NSData的类型，下面举一个例子来介绍。 我们先建立一个叫Student 的类，这个类里有三个属性（学号，姓名，性别）,如图： ![](http://images2015.cnblogs.com/blog/23250/201610/23250-20161003181834145-1260516689.png) 我们要做的就是将Student类型变成NSData类型 ，那么就必须实现归档： 这里要实现 在.h 文件中申明 NSCoding 协议，再 在 .m 中实现 encodeWithCoder 方法 和 initWithCoder 方法就可以了 ： .h 中修改文件如图 ： ![](http://images2015.cnblogs.com/blog/23250/201610/23250-20161003181857239-402489604.jpg) .m中加入代码 ： ![](http://images2015.cnblogs.com/blog/23250/201610/23250-20161003181907192-668738465.png) 这样做就可以将自定义类型转变为NSData类型了 2、将自定义类型数据存入 NSUserDefaults 中 如果要存储全班同学的信息，我们可以建一个NSMutableArray 来存放全班同学的信息（里面存储的全是NSData对象）在需要存储的地方加入代码：12345678910111213//首先，要建立一个可变数组来存储 NSDate对象Student* student = [[Student alloc] ini];//下面进行的是对student对象的 name ， studentNumber ，sex 的赋值student.name = @&quot;lady-奕奕&quot;;student.studentNumber = @&quot;3100104006&quot;;student.sex = @&quot;女&quot;;//这是一个存放全班同学的数组NSMutableArray* dataArray = [NSMutableArray arrayWithCapacity:50];//将student类型变为NSData类型NSData* data = [NSKeyedArchiver archivedDataWithRootObject:student];//存放数据的数组将data加入进去[dataArray addObject:data]; 如果你只想存一个人的信息，你可以直接将NSData存入NSUserDefaults中 : 123NSData *data = [NSKeyedArchiver archivedDataWithRootObject:student]; NSUserDefaults *user = [NSUserDefaults standardUserDefaults];[user setObject:data forKey:@&quot;oneStudent&quot;]; 如果你想存储全班同学的信息，你还要用一个for循环将data 放入 dataArray中，这里具体的操作就不实现了，只给出存放的代码： 1234//记住要转换成不可变数组类型NSArray * array = [NSArray arrayWithArray:dataArray];NSUserDefaults *user = [NSUserDefaults standardUserDefaults];[user setObject:array forKey:@&quot;allStudent&quot;]; 从NSUserDefaults中取出数据在还原也很简单。例如还原一个学生的数据： 12345NSUserDefaults *user = [NSUserDefaults standardUserDefaults]; NSdData *data = [user objectForKey:@&quot;oneStudent&quot;]; Student *student = [NSKeyedUnarchiver unarchiveObjectWithData:data];","link":"/2016/09/16/02集合/"},{"title":"每天一点UWA：第十七周","text":"AssetBundle当一个Texture被一个material和sprite都引用的时候，将三者分别打包，出现texture内存重复问题。 原文较长，总结一下就是：如果一个贴图一方面被当成Sprite使用，另一方面被当成Texture使用(譬如RawImage或者Material)，就会断开引用产生多份。目前解决办法是保证用Sprite的Prefab及Material打包在一个AssetBundle。 这是一个重要的问题，而且这个问题也是看unity版本的。 使用AssetBundle.Unload(true)释放AnimationClip , 但发现AnimationClip在Profiler看到还存在，请问要怎样才释放干净呢？ 如果这个AnimaitonClip是从AssetBundle中加载过来的，那么当这个AssetBundle调用unload(true)时，该AnimationClip理论上是会被强行卸载的。如果Profiler中查看还有，那么只有两种情况： 仍然存在的AnimationClip是从其他地方加载来的，而不是来自于该卸载的AssetBundle； Unity引擎的Bug，这种概率不是没有，但很小。 在打包的时候，有一部分资源是没有设置AssetBundleName的，打包的时候会和依赖它们的资源打到同一个AssetBundle包里（Unity自动完成）。在资源加载的时候，无法主动获取到这些没有设置AssetBundleName的资源。GetAllAssetNames、LoadAllAssets这些接口的返回值中都没有这部分资源。 请问，在你们看来，这种情况是Unity的设计还是Bug？如果是如此设计的话，有什么特别的意义吗？ 提供一个简单的情景，如下：１）有A、B两个Prefab，其中A上挂个脚本引用了B２）打包的时候，设置A的AssetBundleName＝”prefab.unity3d”，B的AssetBundleName=None３）打包，只产生prefab.unity3d这一个AB包，其中包含了A、B两个资源４）加载代码使用AssetBundle.LoadAllAssets()，返回的数组里只有一个资源（A） 我们刚刚在Unity 5.5.2版本上进行了一个测试，得到与题主一样的结论。我们更加倾向于它是一种设计，而非Bug。 因为Prefab B是作为一种参数被引用在A的脚本中，所以在AssetBundle中，它将以GameObject B的形式存在，但是不会存在于AssetBundle的映射表中。 而对于题主的这种打包方式而言，AssetBundle的映射表中只会有一个，就是Prefab A。而AssetBundle.LoadAllAssets虽然会把GameObject A、B及其关联的资源全部加载，但其返回的Object[]内容应该就只有一个，也就是Prefab A。 所以，UWA推测，AssetBundle中在打包时是自己维护了一个map的，只有明确被设置ABName的资源才会被放入map中，也只有map中的资源才可以通过特定名称进行Load，而其关联的资源则会被打包到AssetBundle中的其他container中，是无法通过LoadAsset或LoadAllAssets API来获取到的。 PS：==这是一个需要注意的问题== AssetBundle包字体bitmap A的使用到AssetBundle包Altas B时B冗余 出现冗余是因为vip和betaCommon两个Prefab实际上并没有建立其依赖关系（虽然mainfest上注明了存在dependencies）。 问题解决方式，只需要将BetaCommon Material设置为一个“显式”的AssetBundleName，那么冗余问题就不会存在了。 PS:让bitmap A的material被显示打包。 FontUnity 5.5版本下的UGUI，我将字体设置为粗体，发现字体只是变宽不加粗，不像正常的粗体，如下图所示。另外，TestMesh Pro需要预渲染，不能用动态字体，只能用于特定范围，有像NGUI(效果还不错)那种对动态字体加粗的方法么？ 动态字体加粗显示的外观是和字体本身有关系的，如果字体中没有包含“粗体”的字形，那么Unity会通过拉伸来“模拟”加粗，因此得到的效果是有问题的。 而这个行为在UGUI和NGUI中是一样的。因此，如果要确保加粗显示正确，则需要使用包含了“粗体”字形的字体，甚至需要考虑是否将其include到发布包中（因为某些设备中的内置字体也有可能被精简过）。 TextureUGUI自动打包图集时，有时候同一个Tag会自己打出多个Group图集，导致DrawCall增加，有什么解决方法吗？这个分Group的原理是什么？ 产生Group的原因主要有两种： 纹理的格式不同 。举例来说，有这样四张纹理格式分别为：RGB24，ETC1，RGBA32和ETC2，那么设置一样的Tag后，对应的图集就会有四个Group。 纹理量太大。一个Group放不进，这个原因是容易理解的，就不解释了。 其中特别容易忽略的一点是，某些小纹理可能没有Alpha通道，导致了图集被分成两个Group，引起DrawCall的增高，这种情况下可以直接修改纹理，也可以强制设定为Aalpha通道的格式。 UI请问UGUI Image 在切换Sprite（网络图片） 的时候有卡顿，从Profiler中看到具体卡在SpriteMeshGenerator.TraceShape 这个方法上，如下图所示，有没有什么优化的方法呢？ 图中的==SpriteMeshGenerator.TraceShape/Decompose/Simplify==的函数，通常出现在加载或者创建（Sprite.Create）SpriteMeshType为==Tight类型==的Sprite时，==Tight类型的Sprite在加载或创建时，需要检测图片的alpha区域从而生成多边形==。计算量较大，建议将其改为FullRect模式。 工具Unity Profiler中如下函数的耗时异常高，请问是什么原因导致呢？这些函数分别是什么意思，有什么具体优化方法呢？ Profiler.FinalizeAndSendFrame: 这个是Unity Profiler在记录和传输性能数据的开销，研发团队可忽略，因为在release版本中，该项并不存在； WaitForJobGroup:是主线程在等待子线程完成的耗时开销，如果该项较高，那么说明该帧中某子线程的开销很大。就目前我们优化过的项目而言，绝大部分均为UGUI在子线程的开销所致。更多的参考资料建议研发团队参考UWA问答之前的记录：https://answer.uwa4d.com/question/search?q=waitingforjob Camera.Render:是Unity引擎的主要渲染函数，其中负责了绝大部分场景的渲染工作 Gfx.ProcessCommands包含哪些行为操作？ 该行为是在RenderThread中，导致该行为耗时的主要原因是DrawCall。 另外过程耗时统计还包括顶点、材质贴图以及Shader等从内存到GPU的IO时间。 即使是多线程渲染，图形API的调用也需要在同一个线程中。其一，是Android系统的EGLContext一般不是线程独共享的，也就是只有一个线程能向同一个EGLContext里面发送GL指令。其二，如果使用共享的EGLContext，多个线程都能提交图形API，渲染的结果很难保证正确性。比如：如何保证线程A绑定了VBO或者Texture之后，线程B提交DrawCall时一定是它需要的呢。综上所述，我们认为这些行为应该都在一个线程里面执行的。 模型和动画New出来的Mesh好像都是可读写的，在我填充完数据以后，有什么办法能把这个Mesh改为只读么？ 通过public void UploadMeshData(bool markNoLogerReadable);来设置。 请问我一个MeshRender的显示层级能不能夹在一个Canvas下的两个UI节点下？我通过设置MeshRender.sortingOrder数值在两个Image的Render的sortingOrder数值之间 ，是否能做到呢？ Image的sortingorder设置通常是无效的，因为UGUI会对DrawCall进行合并，调整其渲染顺序。因此，需要将Mesh前后的UI元素拆分到不同的Canvas中，从而直接设置Canvas的sortingorder。 物理在游戏里没有使用物理（Physics)相关功能时，怎么把物理相关的性能消耗降到最低？我们游戏里完全没用到物理相关的功能，只是因为需要做点击碰撞检测，所以GameObject上需要加上BoxCollider组件，但是Profile时会时不时看到Physics.Processing的消耗有点高，也不算非常高，但是理论上如果完全没用物理相关功能的话，总感觉这部分消耗是可以完全干掉的，对于Profiler中Physics模块中给的几个统计不太清楚是怎么计算的，目前使用的Unity版本是5.3.6f1版本。 就我们目前的分析来看，在Unity5.4版本之前，物理模块是会每帧都运行的。而在Unity5.4版本之后，如果没有使用任何物理相关的功能时（Rigidbody、CharacterController、Rogdoll、Cloth模拟等等），物理模块会被关闭。所以，就你的问题而言，物理模块的开销只能降低，而不能完全消除。 对于物理模块的开销，我们建议从宏观上进行了解，当你的项目完全没有使用物理模块时，那就需要从它的调用次数入手了。 Physics.Processing调用次数高：可以看到，很多时候，该函数的CPU耗时其实并不是物理开销过高，而是调用次数过多。这主要是因为Unity 5.x默认设置的Fixed Timestep为0.02，Maximum Allowed TimeStep为0.333。也就是说，物理模块每20ms更新一次，所以如果某一帧很卡（200ms），那么物理模块会被调用10次，这样耗时就直接上去了。而0.333表示如果该帧CPU开销超过333ms了，那么就不会再调用物理模块，所以上图中调用次数中最大是17次。 所以，如果想进一步降低物理模块的开销，在完全没有使用物理的情况下，可以将Fixed Timestep设置为0.05或0.1均可，降低它被调用的频率。同时，尽可能优化其他模块耗时，让每帧的总体耗时尽可能降低。 另外，需要注意的是，修改Fixed Timestep也会影响FixedUpdate的调用，在修改之前一定要检测项目中是否有使用FixedUpdate。 性能综合MonoBehaviour中包含了被加载出来的Prefab上的组件（通过Load接口加载出来的），而这部分组件只能在Prefab被销毁的时候才会释放。工程里还是选择只使用 OpenGL ES 2.0吗？iOS 是否该加上 Metal？ 目前都是用的Auto，主要有两个原因： Metal测试下来CPU Overhead会比GLES低很多 GLES3能够有tex2Dlod支持 兼容性上来说只有实在老的机器和模拟器会fallback到GLES2，可能效果上会略差一些不过我们测试下来都可以接受。 选ES3.0还有一个原因，就是发现AssetBundle打出来的资源会比选Auto小很多。 PS:如果游戏面对的是高端机玩家可以放弃ES2 切换UI场景使用AssetBundle加载慢，怎么优化界面进入速度，是应该预加载吗？ 界面加载慢主要的原因有，图集纹理的加载以及大量UI元素的实例化操作。 针对图集的加载，可以尝试合理的规划图集，尽量控制界面所引用的图集数量（即使用到了某个图集中的一个Sprite，也会加载整个图集）； 可以尝试对公共图集进行预加载，通常公共图集较大，且被使用的概率很大。 针对大量UI元素的实例化，这项开销大通常只发生在背包等复杂的界面中，而对于这类复杂界面可以考虑进行分步实例化，即首先实例化如外框、容器等部分的UI元素，然后分帧实例化背包中的UI元素，从而提高界面打开的速度以及流畅性。 PS： ==分帧是关键。在FPS60的情况下，只要100ms内响应即可。一帧是16.7，也就是说5~6帧做完就可以了。== 渲染Unity官方半透明Shader代码在iOS上运行出现问题 PS:遇到了看https://blog.uwa4d.com/archives/TechSharing_70.html","link":"/2017/12/02/2017-12-2-每天一点UWA：第十七周/"},{"title":"《Unity預計算即時GI》笔记：三、Clusters和总结","text":"说明 这篇文章是对《Unity預計算即時GI》这个系列文章的笔记。 Clusters 叢集，透過修改叢集(Clusters)也是一個降低Unity預計算流程所需要執行的工作數量的好方法。降低叢集數量也能提高執行時的效能。 當採用PRGI來計算場景光照時，Unity會簡化產生一個立體像素化結構的計算，這些立體像素(Voxel)叫做叢集。叢集實際上是反映到場景靜態幾何表面用於照明的表面，叢集用一種層級關聯的結構來儲存，用來預計算Unity的全域光照漫反射所需要的複雜運算。雖然叢集和光照圖很像，但兩者用途是各自獨立的。 通过设置CPU Usage即可。 微調光照參數创建 要建立一個Lightmap Parameters資源，先找到Project視窗,從Create下拉選單建立(Create &gt; Lightmap Parameters) 我們也可以在Project介面裡按右鍵選(Asset &gt; Create &gt; Lightmap Parameters) 來建立。 使用 從Hierarchy介面選擇你要指定變數集的物件，物件必須是帶有Mesh Renderer元件的靜態物件。 開啟Lighting介面(Window &gt; Lighting)並選擇Object頁籤 從Advance Parameters下拉選單指定你的變數集給物件，右邊的”Edit”按鈕是開啟編輯光照變數的捷徑。 光照參數集說明Resolution 解析度的值確訂了物件採用的光照貼圖解析，這個值會和Lighting介面裡的解析度做加乘。比如說，如果場景解析度設為2，這裡的解析度設為0.5，那所有帶有這個參數集的物件都會採用1texel/unit來計算光照貼圖。 这个Lighting介面裡的解析度指的是Scene-wide Realtime Resolution specified in the Scene tab of the Lighting window，翻译的时候没说清楚啊。 Irradiance Budget 解析度值很大光照貼圖所產生的影子斑點可以把Irradiance Budget這個參數調高來獲得緩解。 注意，當解析度值很大時，在較低解析度下可能會產生奇怪的陰影，這些陰影在最終的光照貼圖裡可能看起來像是斑點或髒汙。如果有這種情況可以試著把Irradiance Budget參數提高來獲得改善。 Cluster Resolution 叢集解析度用來決定1個像素裡能有多少叢集數量。假如這個值設為1，代表光照圖裡面每個像素都都會有一個叢集，0.5代表一個像素會有2個叢集，換句話說叢集會是光照圖的兩倍大。 imagine our Scene’s global Realtime Resolution was set to 1. We create a cube with a size of 1x1x1 units, and then assign a Lightmap Parameters asset to this object. If our Lightmap Parameters asset specified a Resolution of 1 and a Cluster Resolution of 1, we would have 1 Cluster per side of the cube. If we then increased our Resolution to 2, the result would be 2x(1x1) Clusters per side of the cube, giving 4 Clusters. 將光照貼圖解析和叢集解析度保持指定比例，這樣我們可以和場景整體的解析度建立一個相對關係。我們可以把Lighting介面裡面的解析度定義為高解析度作為整體設定，然後針對個別物件微調各自的光照參數集。 说白了，数值越大单位像素上cluster越多，与计算时间越长。 Irradiance Budget 我們之前說明過光照計算是如何用叢集來計算靜態物件的預計算光照，在預計算的過程裡，叢集之間的關係被建立起來，好讓光線得以在叢集網內快速傳遞。 在本質上，光照貼圖像素值的算法是基於叢集從該像素的位置對場景的一個檢視所計算得來，這會讓我們可以很快計算叢集之間的光照反射最後產生一個全域光照，這些叢集就能在畫面渲染完之前給予適當的樣本數。 Irradiance Budget(輻照度範圍)用來制訂當叢集採樣時每個光照貼圖像素所使用到的記憶體量，這會決定照明結果的精度，數值太低代表每個貼圖像素在記錄時使用較少記憶體同時提升CPU效能，代價就是會失真，數值越低光照結果會越模糊。反過來看，數值拉高GI會更準確，但記憶體和CPU的消耗都會提升。 越低效率越高，适合大精细的模型，很大、模糊或者遥远的模型。 Irradiance Quality 當計算PRGI時，每個光照貼圖像素會開始對場景投出射線，然後將可視資料報告給附近的叢集，然後貼圖像素就會得到每個叢集的百分比數值，這個值用來定義光照貼圖裡每個像素從叢集所分到的可視數據，而一欄設定就是用來設定每個像素能對場景投射多少射線。 如果場景裡的物件和周圍物件光照不合的情況下可以斟酌加大這個值，有時該暗的時候光照結果卻意想不到的亮，有可能是因為投射到場景的射線不足或遮擋到，導致漏算叢集資料。同樣該亮的的放如果射線沒有檢查到，可能會造成過暗。 提高射線的投射量就能解決類似的問題，代價就是增加預計算的時間，要優化這個時間，我們應該找出最適合的值來達到我們理想的照明效果。請注意，這個值不會影響到Runtime時的效能。 -还是越大越耗性能。 Backface Tolerance 當射線從光照貼圖像素投射出，從場景叢集蒐集光線時有時會打到幾何的背面，當計算全域光照時我們只需要關心投射到物體表面的光照，從背面來的光照資源通常都會忽略掉，這些從背面來的光照資料會破壞光照結果，因此調整這個值能防止這類情況發生。這裡的地板上的陰影就是Unity在計算期間從物件無效的背面所創造的，增加Backface Tolerance能改善這個問題。 Backface Tolerance必須指定從前方光源來的百分比，好讓正面的像素被判定為有效。假如一個貼圖像素沒通過測試，Unity會採用鄰近的像素值嘗試算得正確光照資料。 調整這個值並不會影響PRGI運算效能，也不會對預計算時間長度有太大影響。反而是蠻適合在調整Irradiance Budget都無法解決的場景貼圖太亮或太暗問題時，Backface tolerance會是一個不錯的除錯工具。 調整這個值並不會影響PRGI運算效能，也不會對預計算時間長度有太大影響。2333333333 总结 學習如何評估專案場景並決定適合的光照解析度了解光照圖，PRGI過程中最耗效能的元素之一，並學習如何降低它的數量。 核心，需掌握。 學習如何幫小物件設定光照探針。 蛋疼的玩意。 學習如何調整Unity的預計算參數，讓拆UV過程可以減少光照圖的數量。了解甚麼是叢集，如何使用與它對全域光照的影響。 核心，需掌握。 學習如何微調影響場景物件的光照貼圖變數，在不失真的情況下還能提高預計算效能。 还是比较有用的，主要还是通过影响cluster。 个人总结：这个系列的文章本质上是讲的如何减少光照图。通过改变分辨率、优化UV展开的结果等手段来实现。不过这篇文章如果单纯的看有点单薄，建议结合《Unity 5 中的全局光照技术详解！》这篇文章看。回头看完在写笔记。 这个系列文章中提到的一些有意思的点 PRGI只會呈現場景裡的漫反射(diffuse)和間接照明 Unity的拆解演算法會嘗試把不同Shell做調整將UV邊緣拼接在一起來簡化UV貼圖 在某些情況下，網格匯入器可能會拆開幾何圖形。例如，如果有個網格有非常多的三角面，Unity可以為了效能把它分割成幾個獨立的子網格。通常這麼做是為了符合特定硬體需求，例如為了減少每個Draw Call所需要呼叫的三角面數量。分割通常會發生在相鄰的網格面之間法向角度有大變化的區域，比如銳角邊(hard edges)。這樣的拆分網格方式會在模型導入流程時執行，在這個過程中，UV Shell也可能會被拆分開來放到不同的光照圖，造成額外的光照圖消耗。 當計算PRGI時，每個光照貼圖像素會開始對場景投出射線，然後將可視資料報告給附近的叢集，然後貼圖像素就會得到每個叢集的百分比數值，這個值用來定義光照貼圖裡每個像素從叢集所分到的可視數據 當計算PRGI時，每個光照貼圖像素會開始對場景投出射線，然後將可視資料報告給附近的叢集，然後貼圖像素就會得到每個叢集的百分比數值，這個值用來定義光照貼圖裡每個像素從叢集所分到的可視數據。","link":"/2017/02/22/2017-2-22-《Unity預計算即時GI》笔记：三、Clusters和总结/"},{"title":"每天一点UWA：第十八周","text":"AssetBundle最近的项目使用了AssetBundle的资源管理方案，对于Shader的部分全部放到了Always include里面（这里不仅是系统内置的Shader，还包括自定义的Shader），然后打Bundle资源的目录里是不包含任何Shader的。但是现在发现，Shader还是被作为依赖关系打进了最终的Bundle里，而且造成了冗余，问问大家有没有遇到这个情况呢？我的Unity版本是5.3.4f1。 首先，只要资源在工程里并且需要用到它，就会被打包进AssetBundle。 然后Always include里built-in Shader不会被打包进AssetBundle，这是一个特例。这个特例仅限于没有放到工程里的部分，有些项目会自己下载built-in Shader放到工程里，这样的Shader和自己写的没有区别，也会被打包。 最后，你遇到的问题是正常现象，需要你们通过资源管理的策略避免掉。 自定义Shader放入Always include里面，造成Bundle 资源冗余。项目中的某一个自定义的Shader 使用了Shader feature ENABLE_CLIP，Shader被打进最终的Bundle包的时候，这个Shader feature 不起作用了，是因为这个Shader Variant没有被打入最终包吗，官方文档里的说明是： the only difference is that unused variants of shader_feature shaders will not be included into game build. So shader_feature makes most sense for keywords that will be set on the materials, while multi_compile for keywords that will be set from code globally. 但是我确实有个材质是使用了这个Shader Feature的，为什么这个Shader Variant 没有进入最终的Bundle包呢？ 据了解，Unity官方有在英文论坛里提到Asset Bundle team正在解决这个问题。如果不将Shader对应的Material与Shader一同打包，当前另外的解决方案包括： 使用dummy materials / ShaderVariantCollection 与shader打在同一ab内。 使用multi_compile替换shader_feature。 我把FBX和粒子系统分开打包了。加载的时候先加载FBX文件，然后再加载粒子系统，结果那些粒子系统是Mesh模式的时候，它们的UV会消失。怎么办呢？开了Read/Write able就不会消失。不分开打包也不会消失，这种情况如何破？ 建议考虑在 FBX 的 AssetBundle 里再放一个带粒子系统，并且引用这个 Mesh 的 Prefab（但不去加载，也不去使用它），只是为了让 UV 可以被正确获得。 理论上这样做的话，基本不需要修改原来的加载方式，也不用开Read/Write。 Gameplay我写了一个顶点动画的Shader，对物体顶点位置进行了修改，使其能够跟随相机移动，并总是出现在相机前面。当游戏运行后，开始时物体能够正常显示。相机在场景中移动一段距离后，物体便不再显示，但相机换一下朝向，物体又能显示。目前排除了面剔除的原因，在Shader中已经关闭了Cull（Cull Off），请问还可能是什么其他原因呢？ 消失的原因应当是Unity的Frustum Culling引起。因为顶点动画是在shader中修改的顶点位置，而Frustum Culling是根据顶点修改之前的Mesh的bounds进行的，因此随着相机移动，Mesh实际已经出了Frustum的范围。最简单的解决方法是直接将Mesh的bounds设置足够大，让Unity始终不对其进行Culling： 12mesh.bounds = new UnityEngine.Bounds(transform.position, new Vector3(float.MaxValue, float.MaxValue,float.MaxValue)); 使用SystemInfo.graphicsDeviceName获取的GPU信息不太详细。比如ARM系列的Mali，T880 MP2与T880 MP12相差甚远，但是只能获取到T880，无法获取MP的信息。各位是否有办法？ 对于获取GPU名称信息，在Android的Java层中可以利用API：GLES20.glGetString(GLES20.GLRENDERER)获取显示设备名。可以尝试在Unity中利用AndroidJavaClass(https://docs.unity3d.com/ScriptReference/AndroidJavaClass.html)来调用该API，尝试获取更详细的型号。 如果获取GPU名称的目的是判断GPU性能，可以看下SystemInfo中其他graphicsDevice相关的GPU性能信息是否够用。 物理两个挂了Collider的物体，一个物体挂了Rigidbody，去碰撞另一物体，为什么每次OnCollisionEnter这个函数在实际还没有碰撞的时候就调用了呢？如下图，这时OnCollsionEnter已经被调用，但从图上可以看到两物体实际还没有接触，这个函数调用之后才会真正碰撞在一起。 物理系统在FixedUpdate中触发，包括OnCollisionEnter。而FixedUpdate早于Frame Rendering，因此碰撞实际已经发生，只是画面还没更新。其实在运行时这点时间差几乎应该可以忽略。 性能综合想对场景中的静态物件做一个遮挡剔除，不知道Unity自带的Occlusion Culling对性能优化的提升有多少呢？我们用Unity官方例子测试，启用Occlusion Culling后发现DrawCall、Triangle几乎没有变化。另外也想获知，Occlusion Culling的数据能否像NavMeshData那样可以动态加载呢？ Occlusion Culling在使用后具体能提升多少，这个其实是没有明确数值的，甚至可能不升反降！这个只能题主在自己的项目中进行尝试。 一般来说，Occlusion Culling功能特别适合第一人称或第三人称跟随的平视角相机（比如传统意义上的MMO等类似游戏），且适用于在场景中存在大量的遮挡情况。因此，在城市街道漫游、峡谷漫游等特定场景中，比较推荐开启Occlusion Culling功能。 但是Occlusion Culling功能本身存在一定的性能开销，因为需要每帧均遍历烘焙的Cell来明确哪些物体需要或不需要渲染，所以场景中Cell越细，那么其查询开销也就越大。因此，如果场景中本身没有大量的遮挡关系，那么开启Occlusion Culling功能后，其节省下来的渲染耗时可能抵不上其Cell查询耗时来的大，这样就得不偿失了。 最后，Occlusion Culling的Data目前并不能动态加载，只能随场景来进行加载。因此，可以尝试创造一个拥有Occlusion Culling Data的“空场景”，然后通过LoadLevelAdditive方式来进行加载，从而来达到“动态”加载的效果。 通过Profiler.GetMonoHeapSize()获取到的堆内存，在操作UI的时候，打开某个节点比较多的UI界面，根据上面接口取到的堆内存会突然涨6~8MB，但是Profiler取不到这个数据，该怎么办呢？我不是固定打开某个界面，而是随机出现在某个界面上，这样的问题该如何入手呢？ Mono总体堆内存一次性涨6-8MB是比较正常的。Mono内存并不是随用随分配的，而是当其发现不够用时，一次性从系统中获取一段连续的内存。在游戏运行一段时间后，这个值一般是8MB。所以，题主遇到的情况很有可能是在连续操作UI界面时，Mono发现堆内存不够用了，于是就有了题主观察到的内存分配。 渲染下图这一项是指渲染透明物体的渲染消耗么，主要是提交DrawCall是么，现在游戏的GPU消耗在20ms以内Xcode Profiler结果。但是有些粒子系统比较耗CPU，就是这个涨得比较厉害，峰值有7~8ms，请问有没有什么优化建议? 首先，需要说明的是，Draw Call是CPU端的耗时开销，XCode上GPU上的开销统计与其关系不大。 其次，图中红框所示确实表示的是半透明物体渲染在CPU端的耗时，其不仅与Draw Call数量相关，也和渲染State的切换相关（从图中可以看出，项目使用的是Unity 4.x版本，对应的需要关注Shader.SetPass的开销）。 再次，粒子系统的耗时开销很高，如果还是持续在7~8ms左右，那么研发团队关注较高耗时处的游戏场景，并控制粒子系统的使用数量，粒子系统的优化并没有“神奇”的方案，目前研发团队需尽可能控制粒子系统的使用数量。","link":"/2017/12/03/2017-12-3-每天一点UWA：第十八周/"},{"title":"AssetBundle学习笔记：1、概述和创建","text":"前言 打算彻底搞清楚AssetBundle的原理和使用，目前计划刷完官方文档和最佳实践系列文章，而且笔记中的内容会大量是官方文档的内容。 概述 AssetBundle可以包含任意unity能识别的类型文件，甚至是一个场景。如果想包含自定义的二进制文件，需要文件后缀名是.bytes，unity会将这样的文件导入为TextAsset。 AB流程 Editor编辑，场景中使用。 上传AB到服务器，其实这个不是必须的，也可以放到本地，后面会讲到这种case下怎么做才是最高效的。程序会按需加载AB，然后每个AB中的asset各自处理。其实就是在AssetBundle中按照需要加载不同的资源。 下载AB到本地，方法也非常多，各有优劣，后面会说。 从AssetBundle中加载GameObject，这个有一个AssetBundle→asset→GameObject的过程。而AB之前还可能有www。 友情提示 你必须看这个 创建AssetBundle设置AssetBundle 定义AssetBundle名称，在一个资源的最下方会有一个AssetBundle的设置。 点击New按钮可以创建新包，并给它命名。下图的例子中资源被添加到一个名为environment/desert的AssetBundle中，这里面可能包含了之前已经放置的资源。另外在AssetBundle命名时unity会当名称转为小写。 如果创建了一些AssetBundle，但是没有放置任何的资源通过Remove Unused Names选项可以删除定义的名字。 从上述的说明感觉这个new出来的是一个空文件夹识，在设置资源时这个文件夹的名字作为了标识来使用。而Remove Unused Names按钮就是一键删除空文件夹。 代码生成AssetBundle 这里有一段代码。代码很简单，而且没有很多容错机制。而且说实话这个代码很粗暴，所有被标记（就是上面说的设置）了AssetBundle的资源：prefab、scene文件等都会被无脑的build进指定的AssetBundle中。 12345678910using UnityEditor;public class CreateAssetBundles{ [MenuItem (&quot;Assets/Build AssetBundles&quot;)] static void BuildAllAssetBundles () { BuildPipeline.BuildAssetBundles (&quot;Assets/AssetBundles&quot;, BuildAssetBundleOptions.None, BuildTarget.StandaloneOSXUniversal); }} 同时生成的manifest文件包含一下内容： CRC AssetFileHash：AssetBundle中所有asset文件的hash，一个单独的hash。只用来做增量build时的检查。 TypeTreeHash：AssetBundle中所有类型的hash，只用来做增量build时的检查。 ClassTypes： AssetBundle中包含的所有类类型，这些数据用来得到一个新的单独的hash当typetree做增量build检测。 Asset names.所有在AssetBundle中的asset的名称。 Dependent AssetBundle names. AssetBundle所依赖的其它AssetBundle的名字 这个manifest文件只是用来做增量build的，非运行时必须。 放一个自己的测试数据 123456789101112131415ManifestFileVersion: 0CRC: 1763426742Hashes: AssetFileHash: serializedVersion: 2 Hash: eed209af1be31231fa135faaff2ab7b6 TypeTreeHash: serializedVersion: 2 Hash: 31d6cfe0d16ae931b73c59d7e0c089c0HashAppended: 0ClassTypes: []Assets:- Assets/Test.unityDependencies:- E:/CodeDemo/New Unity Project 2/Assets/AssetBundles/sphere 还有两个文件生成，文件名就是打包目的地文件夹的名字，比如上面的代码就在AssetBundles文件夹下生成，名字是AssetBundles，一个是没有后缀的一个是以manifest为后缀，打开manifest文件可以看到下面的内容，可以看出来是这个目录下AssetBundle的信息。其实它只包含两个 信息，一个是所有的AssetBundle名字和它们的依赖。12345678910ManifestFileVersion: 0CRC: 4270654667AssetBundleManifest: AssetBundleInfos: Info_0: Name: cube Dependencies: {} Info_1: Name: scene Dependencies: {} 做了个小测试，添加了两个新的AssetBundle，名字也不一样，每次添加这个文件的内容跟着变，并且CRC也在变。 123456789101112131415161718ManifestFileVersion: 0CRC: 2591254959AssetBundleManifest: AssetBundleInfos: Info_0: Name: cube Dependencies: {} Info_1: Name: scene Dependencies: Dependency_0: sphere Dependency_1: capsule Info_2: Name: sphere Dependencies: {} Info_3: Name: capsule Dependencies: {} 继续小测试，把Capsule的AssetBundle从capsule改为sphere。果然只是简单记录了下目录中的AssetBundle信息。 1234567891011121314ManifestFileVersion: 0CRC: 3856405611AssetBundleManifest: AssetBundleInfos: Info_0: Name: cube Dependencies: {} Info_1: Name: scene Dependencies: Dependency_0: sphere Info_2: Name: sphere Dependencies: {} 再次小测试，在UI的AssetBundle设定中第一栏设定了多层次的名称结果如下。而且从文件夹结构上看one和two都是两个文件夹，而在two里面则是一个名为xx.three的文件。 1234567891011121314ManifestFileVersion: 0CRC: 2167406161AssetBundleManifest: AssetBundleInfos: Info_0: Name: scene Dependencies: Dependency_0: sphere Info_1: Name: sphere Dependencies: {} Info_2: Name: one/two/xx.three Dependencies: {} shader剥离（Shader stripping） 如果AssetBundle中包含shader，unity编辑器会根据当前场景和光照贴图的设置来决定使用哪种Lightmap modes。这还意味着你在打包的时候需要将打开着一个配置的场景。我的理解是因为需要根据当前场景来作为因素来做某个事情，所以这个场景需要时打开的。 也可以指定一个场景用来计算光照贴图模式，这个在用命令行buildbundle时是必须的。 引擎代码剥离 代码剥离这个事情是将没有在任何场景（特指Build Settings &gt; Scene list中的场景）中使用的代码移除，减少了包的大小。不过只能用在iOS、Android和webGL。选择IL2CPP的是时候是默认打开的。而且顾名思义，只剥离引擎代码，你自己的代码不会被剥离。 如果一个引擎代码在build的时候被剥离了，但是在运行时又被请求使用，那么就会报错，因为被剥离的代码无法再被访问。如何避免这个错呢？把player（此处我认为不是玩家的意思，而是引擎）可能用到的AssetBundle列出来，放置到一个manifest文件中，代码剥离系统使用这个文件中列出来的AssetBundle (along with the Scenes in the build)来确定哪些code需要保留。当一些平台或build不支持代码剥离，又或者没有勾选剥离时assetBundleManifestPath属性是被忽略的。 从代码角度来看就是 123456789101112131415161718192021222324252627282930313233using UnityEngine;using UnityEditor;namespace AssetBundles{ public class BuildScript { public static void BuildPlayer() { BuildPlayerOptions buildPlayerOptions = new BuildPlayerOptions(); // example hard-coded platform manifest path buildPlayerOptions.assetBundleManifestPath = &quot;AssetBundles/iOS/iOS.manifest&quot;; // build the Player ensuring engine code is included for // AssetBundles in the manifest. BuildPipeline.BuildPlayer(buildPlayerOptions); } }} 几个小工具代码 列出所有在build process中产生的AssetBundle的名称 12345678910111213using UnityEditor;using UnityEngine;public class GetAssetBundleNames{ [MenuItem (&quot;Assets/Get AssetBundle names&quot;)] static void GetNames () { var names = AssetDatabase.GetAllAssetBundleNames(); foreach (var name in names) Debug.Log (&quot;AssetBundle: &quot; + name); }} 一个asset发生改变时的监听，讲道理这个函数从说明到函数名都看着真么不协调。从函数名看感觉是AssetBundle名字变化，但是说明又是AssetBundle中一个asset发生变化。 12345678910using UnityEngine;using UnityEditor;public class MyPostprocessor : AssetPostprocessor { void OnPostprocessAssetbundleNameChanged ( string path, string previous, string next) { Debug.Log(&quot;AB: &quot; + path + &quot; old: &quot; + previous + &quot; new: &quot; + next); }} AssetBundle变体 这个玩意有什么意义呢？ 下图中在后一个label中填入一个名字，就可以形成变体。 从文档上看可以同一批asset创建不同的变体，而且在这些变体AssetBundle中asset有意义的内部ID。需要注意这样的变体AssetBundle的全名是由AssetBundle name + the variant name组成的，如果你创建了一个名为MyAssets.hd的AssetBundle，那它只是一个普通的AssetBundle而不是变体的。而且 “MyAssets”+“hd”和“MyAssets.hd”+””不能同时存在因为它们具有相同的全称。 脚本建议 妈蛋总算快完了。 呵呵，我不打算写了。 Typetrees 默认写到AssetBundle中，但是metro除外，因为不同的序列化方案。 一些实验 以熊作为测试，如果将bear文件夹下的所有asset打包，会出现明显的依赖。而且贴图的AssetBundle大小比prefab本身要大。 1234567891011121314151617181920212223ManifestFileVersion: 0CRC: 519453993AssetBundleManifest: AssetBundleInfos: Info_0: Name: xiong.assetbundle Dependencies: Dependency_0: baixiong.assetbundle Dependency_1: baixiongyachi.assetbundle Dependency_2: xiong@run.assetbundle Dependency_3: xiong@stand.assetbundle Info_1: Name: baixiong.assetbundle Dependencies: {} Info_2: Name: baixiongyachi.assetbundle Dependencies: {} Info_3: Name: xiong@run.assetbundle Dependencies: {} Info_4: Name: xiong@stand.assetbundle Dependencies: {} 如果只是打包xiong这个prefab，会产生一个100多K的xiaong的AssetBundle。可以正常使用。 但是如果做一个xiong2，其实就是xiong的复制体的话。会发现运行的时候avatar、mesh、shader等都是双份的。这个就是不把依赖单独打包的坏处了。 对于shader的双份问题可以通过Editor-&gt;Project Settings-&gt;Graphics-&gt;Always Included Shaders添加你用的shader，这样就不会出现了。","link":"/2017/03/14/2017-3-14-AssetBundle学习笔记：1、概述和创建/"},{"title":"《Unity預計算即時GI》笔记：二、光照图","text":"说明 这篇文章是对《Unity預計算即時GI》这个系列文章的笔记。 光照图什么是光照图 光照图在第三章中有如下的定义，读起来很是费解。 一個光照圖(Chart)是表示一個光照貼圖的區域，用來映射場景物件的光照貼圖UV。你可以想像是能影響物件的一張小磁磚圖，一張光照圖由兩部分組成:輻照度(照明)和方向性(主要光線方向編碼)。 到了第六章又有如下讲解，读完之后我更加费解了，所以暂时搁置吧。 產生光照圖(Charts)的目的主要是用來包住靜態網格著色器(Static Mesh Renderer)的UV貼圖座標。 如何生成 一個物件所需要的光照圖數量主要是看物件有多少片UV shell需要拆解。所謂拆UV的學問就是保持幾何面上貼圖像素扭曲度和所需的Shell數量之間的平衡。 光照圖是在網格導入流程的一個拆解階段(Unwrapping stage)被產生出來的。對於PRGI來說，這些光照圖會在預計算裡的幾何階段(Geometry stage)被打包到不同的圖集(Atlas)裡，這是為了確保它們不會相互重疊。一旦預計算的幾何階段完成之後就會產生可視化數據，我們就能預覽光照圖。 这个部分要结合原文的图来看，从这个部分的文章中可以看到，在模型导入时决定了它需要几个光照图，而場景裡面有大量的光照圖可能會是PRGI耗時的原因之一。 从上下文的介绍来看，光照图是光照贴图的映射，记录了实时计算的结果，当计算光照时，需要从中提取信息。 看看下列範例圖: 這樣的UV拆解不會變形，但需要多張UV shells 用單一UV shell所產生的結果，但貼圖變形很嚴重 比較理想的結果，單一UV shell且貼圖沒有變形 從上面我們可以看到三個拆UV不同的例子 從第一張圖裡我們可以看到做為貼圖的棋盤格圖案像磁磚一樣保持比例的貼在方塊表面上並沒有變形。試想如果這個棋盤圖案是一個光照貼圖(一個打在物件上的光照圖像)，我們會得到一個視覺上看起來沒有問題的結果，只是會需要耗費六個UV shells。那就表示待會用Unity PRGI計算的時候也會產生六張光照圖，不管條件如何，每個光照圖最少都需要4x4個貼圖像素來表示，還沒考慮解析度之前最少就會耗掉96個像素。 在第二張圖裡我們會遇到不同的狀況，物件的UV貼圖座標只用一個UV shell就涵蓋所有範圍，雖然這樣所產生的光照圖最少，但視覺效果卻不是我們要的。我們會看到物件表面上的貼圖歪掉了，貼圖在UV空間裡也相互重疊，代表如果這是一張光照貼圖，物件一面的光照可能會錯投到相反面上。很明顯的這種拆法是有問題的。 *第三張圖的結果比較理想，棋盤沒有扭曲，磁磚比例也保持正方形。而且還成功用一張UV shell覆蓋物體的所有面。屆時透過連接或縫合對應在模型上的邊緣來把位置合上。如果用技術的邏輯來看，整個過程做了哪些事情呢? 首先，我們會將UV圖用正交投影(Orthogonal Projection)在物件上來產生獨立的Shell，然後我們就會分析哪些Shell和物件的邊緣有相連關係，一旦我們找到了這些邊緣，我們就會把UV shell的內容移進去並和相鄰的Shell縫合起來。 * 如何查看已经生成的光照图 首先需要生成LightingData数据，将场景中的模型勾选static，然后在light window中点击build(也可以选择Auto) 。 场景窗口中选择，UV Charts模式會把場景裡不同光照圖用不同顏色表示 如何减少光照图 需要对以下几个参数进行设置 先放一下原模型的图，后续会有大量的结果图。 Auto UV Max Distance(自動最大UV距離) Unity的拆解演算法會嘗試把不同Shell做調整將UV邊緣拼接在一起來簡化UV貼圖。當Shell放入後還能保持在Auto UV Max Distance規定的範圍內時才會被考慮進來。這個範圍是用Unity的世界空間座標來定義的，在我們的範例裡是1米。 在許多情況下，預設的0.5就能給出不錯的結果，但對於具有大面積的特大物件可能要提高這個值來防止本來應該被縫合的UV圖被演算法排除在外。 增加這個值通常會讓物件所需的光照圖數量減少，而降低這個值通常有助於解決貼圖像素被拉扯的問題，當然就會需要產生更多的光照圖來覆蓋。改變這個值後你可以透過檢視場景UV Charts繪製模式，從覆蓋的棋盤圖來評估並實驗出一個最好的平衡點。 这个属性应该是用于控制拼接UV图的，值越大就会使得原本一些间距比较大的shell能够进行合并，这样就可以减少光照图的数量。 做了一个简单的测试，分别设置为0.1、0.5、0.8。明显可以看出来，当数值很小的时候会分出更多的光照图，而且从浅蓝色线条可以看出是模型的边。 Auto UV Max Distance:0.1 / Auto UV Max Angle:89 Auto UV Max Distance:0.5 / Auto UV Max Angle:89 Auto UV Max Distance:0.8 / Auto UV Max Angle:89 Auto UV Max Angle(自動最大UV角度) 提高這個值會讓Unity的演算法更容易組合UV圖，這也表示能透過這個功能來降低單一物件的光照圖數量，但是如果設的太寬鬆有時候會出現貼圖被拉扯的狀況。反之降低這個值會造成演算法不好把相鄰的UV排一起，雖然拉扯的情況會降低但是會產生更多光照圖。相同，檢視UV Charts繪製模式裡的棋盤圖並試出一個最適合的值。 基本原理和Auto UV Max Distance一直，更大的数值使得更多比较扭曲的UV Shell能够合并，弊端也说的比较明确。 以下仍旧是一组对比图 Auto UV Max Distance:0.5 / Auto UV Max Angle:50 Auto UV Max Distance:0.5 / Auto UV Max Angle:89 Auto UV Max Distance:0.5 / Auto UV Max Angle:120 Preserve UVs(保留UV) 在某些情況下，自動拆UV如果無法獲得理想結果，可能會產生過多的光照圖或是貼圖失真(GI Charts繪製模式可以做拉扯檢查)。在這種情況下可能需要在模型的UV01通道手動建立UV。這必須要在其他工具完成。 如果這種情況發生，我們可以在Preserve UVs選項讓Unity演算法強制採用模型UV01通道指定的UV Shell。 當需要手動保持UV圖時，Preserve UVs選項很有用 要注意的是這些Shell會被重新打包來節省光照貼圖空間，它們會被單獨解開保留，而不是只有把在光照貼圖內的座標記錄起來而已。 使用這個功能時必須小心，當指定的UV貼圖包含著大量的UV shells時，這個功能可能會讓預計算的時間拉長，因為Unity的拆解演算法被跳過，手動保留的UV Shells到時候會全餵給預計算流程。記住，最好的結果是儘可能的降低UV shells和光照圖並保持可以接受的貼圖拉扯範圍。 感觉大多数时间是不需要这个东西的，即使unity自己UI展开的不好如果不伤大雅也可以不用。 生成的图放到下面进行对比 Ignore Normals(忽略法線) 在某些情況下，網格匯入器可能會拆開幾何圖形，這也會影響到光照圖的數量。例如，如果有個網格有非常多的三角面，Unity可以為了效能把它分割成幾個獨立的子網格。通常這麼做是為了符合特定硬體需求，例如為了減少每個Draw Call所需要呼叫的三角面數量。分割通常會發生在相鄰的網格面之間法向角度有大變化的區域，比如銳角邊(hard edges)。這樣的拆分網格方式會在模型導入流程時執行，在這個過程中，UV Shell也可能會被拆分開來放到不同的光照圖，造成額外的光照圖消耗。 信息量略大，首先为了减少Draw Call时三角形面数过多，unity在导入网格是进行拆分，自然这就导致了产生一些多余的UV Shell。 Ignore Normals選項可以防止模型在匯入時光照圖被拆開 有時候放著上述的問題不管不太值得，得到的結果讓光照圖數量增加拉長了預計算的時間，還有可能在照明的接縫造成不必要的視覺假象。在這樣的情況下，啟用Ignore Normals選項有助於防止光照圖在預計算的時候被分割開來。 請注意，這個選項只有對預計算即時光照(PRGI)有影響，物件被拆分的網格仍然會被保留以用在其他用途。 挺好，只是为了PRGI，正常的网格还是会被拆分已做别的用途。 最后放下结果对比 Auto UV Max Distance:0.5 / Auto UV Max Angle:89 / 使用模型UV Auto UV Max Distance:0.5 / Auto UV Max Angle:89 Auto UV Max Distance:0.5 / Auto UV Max Angle:89 / 忽略法线 目测这个模型按照默认设置效果就挺好的。 后续讲了一些实际的操作，还是自己读文章吧。 光照图总结 目前来看整个PRGI的大头在于光照图，而如何减少光照图是重中之重。 参数虽然都已经很清楚，而且UV Charts中可以看到具体的效果。不过，在多个模型的场景中每个模型做优化也是个很费时间的事情。","link":"/2017/02/22/2017-2-22-《Unity預計算即時GI》笔记：二、光照图/"},{"title":"AssetBundle学习笔记：4、AssetBundle的下载与asset的加载","text":"AssetBundle的下载下载AssetBundle 首先需要理解的是这个下载就是指的从网络下载。因此只有WWW和 WWW.LoadFromCacheOrDownload两个方法。 www是不带缓存的，而后者是带缓存的。 LoadFromCacheOrDownload的version参数，如果缓存中不存在，或者version低于指定的版本就会重新下载，否则直接从缓存拿数据。缓存数据应该是始终在磁盘上的，而5.3以后缓存文件也压缩为LZ4(好像是可配置的)，所以读取cache的数据很可能与LoadFromFile是等效的。 如果多个AssetBundle使用WWW.LoadFromCacheOrDownload下载，每帧只能完成一个。 LoadFromCacheOrDownload中如果发现缓存文件夹已经满了，会优先删除最近没有使用的cache，但是如果磁盘本身就满了或者说cache folder已经满了（这个东西是有容量限制的）那么会把AssetBundle数据直接按照stream的形式放到内存，这个和new WWW的做法完全一样。 生成AssetBundle 当访问.assetBundle属性时，会从下载的数据中提取并生产AssetBundle对象。此时就可以加载AssetBundle中的asset了。 其它 后面在editor中加载asset的demo中API已经过时，可以用AssetDatabase.LoadAssetAtPath代替。 Asset加载AssetBundle加载API概述 具体表格可以参考原文 WWW 在使用WWW时需要及时释放，因为它会在内存（WebStream）中保留下载的文件的大小。 LoadFromCacheOrDownload LoadFromCacheOrDownload没有什么额外的内存使用（其实应该有序列化文件（SerializedFile）的内存使用，而且如果prefab过多，有可能SerializedFile比WebStream还大，来源） 从表中可以看到在性能上也只有读磁盘的操作，然而LoadFromCacheOrDownload本质上是个网络操作，因此它会产生一些例如CRC检测的操作，所以unity的建议是如果是本地的AssetBundle不要用这个函数加载。 如果是加载缓存行为与 LoadFromFile一致，但是按照上面的说法看应该有差异吧。 补充：关于SerializedFile在4.7上每个的大小并不一定。在5.3-5.5期间Unity引擎目前的做法，为了保证Android端apk解压速度而保证的两个256KB的buffer，在pc上只有7KB。而到了5.6会改为2x8KB。但是经过测试这个不是必然的。 LoadFromMemory (Async) LoadFromMemory (Async)，不推荐使用，因为它的操作几乎都是在内存中完成的。加载AssetBundle需要占用大概AB size两倍的内存，一个API创建的内容还有就是参数里面的数据内存。如果是load一个asset会在内存中出现三个asset的拷贝，一个是托管代码字节数组，一个是 AssetBundle 的本地内存，第三个是在 GPU 或者系统内存中的资产本身。（第一个是参数、一个是AssetBundle本身、一个是Load函数产生的对象内存）。 LoadFromFile(Async) LoadFromFile(Async)，++不能加载LZMA（特么的你敢信）。而且在Android上5.3和之前的unity无法加载StreamingAssets中的AssetBundle。++ 移动端上：当使用AssetBundle.LoadFromFile加载LZ4格式的文件时，其实不会将问价加载到内容，而是加载AssetBundle的Header。 Editor下会将AssetBundle加载到内容，因此在Profiler中会出现峰值，不用担心。 WebRequest WebRequest。(also supports caching)，这个东西算是WWW的替代品，很好用，回头写个总结。 其它 使用WWW, WebRequest下载AssetBundle时，还有一个8x64KB的缓冲池buff来保存socket中的数据。so，这也是内存啊。 从压缩格式角度看: 不压缩没啥优势，除了访问速度快。其实如果是不考虑内存或者磁盘的占用问题，倒是可以用这个。 LZ4，从文档看unity应该用的是LZ4HC，一个LZ4的高压缩版本。由于unity从5.3以后缓存也可以压缩了，而且这个算法是基于块的，所以在综合性上比较好。 LZMA，必须先解压在压缩，如果不是因为网络传输需要节省流量，不建议使用。 加载二进制数据 按照建议应该将原始的二进制文件保存为后缀为.bytes的文件，unity会视这个后缀的文件为TextAsset，作为一个TextAsset文件然后打包到AssetBundle。加载的时候也是一样，从AssetBundle中按照TextAsset类型得到asset，然后TextAsset.bytes属性得到byte数组。1234567891011121314151617181920string url = &quot;http://www.mywebsite.com/mygame/assetbundles/assetbundle1.unity3d&quot;;IEnumerator Start () { while (!Caching.ready) yield return null; // Start a download of the given URL WWW www = WWW.LoadFromCacheOrDownload (url, 1); // Wait for download to complete yield return www; // Load and retrieve the AssetBundle AssetBundle bundle = www.assetBundle; // Load the TextAsset object TextAsset txt = bundle.Load(&quot;myBinaryAsText&quot;, typeof(TextAsset)) as TextAsset; // Retrieve the binary data as an array of bytes byte[] bytes = txt.bytes;} 对于加密资源的处理 三个套路： 加密自己的原始数据，然后改后缀为.byte，按照上面说的二进制的套路走。客户端拿到二进制数据后进行解密。 加密AssetBundle，后缀名不限。用WWW的形式拿到数据后解密，然后用AssetBundle.CreateFromMemory生成AssetBundle。 一个普通的AssetBundle中包含一个加密的AssetBundle（蛋疼不？）。需要经历获取TextAsset-&gt;拿到二进制数据-&gt;解密二进制数据-&gt;生成未加密AssetBundle-&gt;加载AssetBundle中的asset。 Script Asset的处理 script-&gt;assembly(pre-compiled)-&gt;TextAsset-&gt;AssetBundle-&gt;TextAsset-&gt;byte[]-&gt; 123456var assembly = System.Reflection.Assembly.Load(txt.bytes);var type = assembly.GetType(&quot;MyClassDerivedFromMonoBehaviour&quot;);// Instantiate a GameObject and add a component with the loaded classGameObject go = new GameObject();go.AddComponent(type); 卸载asset或者说AssetBundle AssetBundle.Unload方法是目前AssetBundle唯一能够使用的方法，与Resources.UnloadAsset比起来缺乏灵活性。 参数是个bool，传递falseunload the compressed data from memory，按照第二部分的说明，什么是压缩的数据，那就是LZ4的数据，也就是AssetBundle。如果传递true，那么已经load出来的asset也会被清理。 一些策略 一个AssetBundle对象在同一时刻只能存在一份，所以当反复使用www下载并调用www.assetBundle时会报错` Cannot load cached AssetBundle. A file of the same name is already loaded from another AssetBundle`。这个时候要么自己unload要么就代码控制只保留一个对象。unity的建议是尽快删除不用的AssetBundle。 unity5之前bundle在unload之前如果有load，需要等到load结束才会执行unload。so，可能会卡线程。 文中有一个完整的解决方案。 优化AssetBundle的磁盘寻道(Seek) unity序列化数据是为使得数据在读取时是线性的，减少寻道的次数。因为HDDs的硬盘比SSD慢很多。 一个场景的数据按照对象类型进行排序，在场景加载时，场景中的asset先按顺序加载，然后画面中的对象才加载。（完全可以理解，场景中摆放的多是prefab，肯定要先加载prefab所需要的资源。）而Scene AssetBundle也是这个顺序。 一个来自non-Scene AssetBundles中的asset在序列化上是和Scene AssetBundles一样的，但是加载方式取决于调用的API。LoadAllAssets这样的API会采用线性的方式加载所有的资源。但是如果是LoadAsset会随机读取的形式加载。 DeterministicAssetBundles不破坏线性读取和类型排序，但是保留对象位置在一个特点的范围(没看懂)。 LZ4不影响线性读取，但是会影响读取的颗粒度。（想来是因为按需加载，所以。。。） 一些需要注意的行为 一些异步加载API会打破线性读取的模式，即使是读取场景。 因为有依赖的存在，所即使AssetBundle.LoadAllAssets这样的API也不能保证是线性读取的。因为可能出现依赖的资源在别的AssetBundle中，所以最好是将所有依赖的资源都读取出来放好了，这样可以使用最小的寻道次数。 参考 MMAP 一些内存测试数据。第二个测试结果符合unity使用MMAP的结论。 一些不错的文章 简单好理解 震惊！男人看了会沉默，女人看了会流泪，不看不是中国人之事实的真相系列。","link":"/2017/04/04/2017-4-4-AssetBundle学习笔记：4、AssetBundle的下载与asset的加载/"},{"title":"AssetBundle学习笔记：资产、对象和序列化","text":"前言 这篇及后续的几篇笔记是我阅读A guide to AssetBundles and Resources的一些记录。官方的这个系列文章详细的阐述了unity是管理资源的。从一个asset的导入开始，unity就在背后开始了它的工作。它为每个资源创造了一个mate文件，给予了资源一个唯一的ID，从此这个资源的一切都与这个ID紧密结合到了一起。可能我们的一些操作会导致资源丢失它的mate文件，这会造成一些很不好的后果。 与此同时，系列文章中还重点阐述了什么是AssetBundle，如何下载AssetBundle和如何从AssetBundle中加载asset。 最关键的是最后一章，在这一章中详细的描写了AssetBundle的制作策略。AssetBundle可以说是unity中至关重要的一个概念，但是在日常的工作中按照怎么样的颗粒度来划分AssetBundle，如何平衡AssetBundle的精细度和方便性，这一直以来是一个让人头痛的问题，第四章中给出了一些答案。 资产、对象和序列化 这是系列文章的第一部分（前面还有一个类似介绍的章节），讲述了unity如何处理导入的资源，如何去标识它们，管理它们。 资产的导入 首先asset这个词如果只是看翻译的话可以是资产，其实在我看来它可以是资源，和resource这个词的含义几乎一样。但是因为Resource这个词在unity中有着特殊的含义，它代表了一个特别的文件夹，所以可能需要用一个别的词语来表示资源的概念。 asset可以是一个脚本、一个音频文件或者是一个美术从3D建模工具中导出的FBX文件，它保存在unity工程的Assets文件夹下，它的格式可能unity能够直接使用的(比如一个material)，也可能是不能直接使用的（比如FBX）。 每一个asset在导入到unity时都会进行一项工作，就是将asset序列化，因为只有只有unity引擎才能够使用它们。在这个导入的过程中可能会对纹理等进行压缩，所以这个过程会比较久。 这些被序列化后的数据保存在工程的Library文件夹下，我们不需要修改这些数据，因为这个是unity自动做的，每次你导入新的数据的时候都会生成这些文件。而且如果你留意的话，会发现你切换unity的目标平台时（Android→ios）会重现生成一次序列化文件，因为每个平台能够识别的数据类型不同。同一个纹理文件可能对于了不同的序列化文件。（没事不要删除Library文件夹，因为这个序列化过程非常耗时。） 通常我们在unity的IDE中看到的asset文件都是原始的文件，因为导入的过程中虽然做了序列化，但是其实是生成了新的文件，而原始的文件并没有被修改。（给出一个参考文档） 资产导入的结果是什么 答案是序列化文件，那么我们通过什么使用这些序列化文件呢？答案是 UnityEngine.Object,或者是大写O的Object。 Object是一套序列化数据用来描述一个具体的资源实例。它（object）的类型可以是任何引擎使用的类型，比如一个mesh、一个音频片段等。基本上所有的内置对象类型都是UnityEngine.Object的子类型，除了ScriptableObject和MonoScript。 需要注意的是，一个外部文件的导入可能产生了多个asset，比如FBX文件的导入，可能产了mesh、material和texture。 什么是ScriptableObject和MonoScript ScriptableObject在我看来是一种内置的数据存储格式 MonoScript代表了工程中的一个脚本文件，它是个editor类。用法 12345678#if UNITY_EDITOR mediatorClass = RTEditorGUI.ObjectField&lt;MonoScript&gt;(mediatorClass, true); if (mediatorClass != null) { mediatorName = mediatorClass.GetClass().Name; }#endif unity如何区分这些导入的asset 这是一个核心的问题。unity在生成（以FBX文件导入为例，可能一个FBX生成了unity中的多个asset）一个asset时，会同时生成一个mate文件。这个asset会分配一个File GUID，而这个asset中的多个UnityEngine.Object会生成多个Local ID。这个理解起来比较容易，一个asset就是一栋房子，有一个唯一的门牌号。而一栋房子的每个房间又有一个唯一的房间号。 unity editor将这个File GUID与asset的路径关联了起来。这样一来，如果你移动了asset的位置，unity会更新这个File GUID对应的路径，这也是为何unity建议我们移动或者重命名或者删除文件已经要在IDE中做，因为unity会监控文件的变化。如果你在外面改了文件名字或者路径，回到unity后会发现unity会给这个asset重新生成一个mate文件，显然这样会分配一个新的GUID。 后果是什么？如果你的这个asset中的内容已经被使用，那么会出现丢失的情况。总的来说，unity就是靠File GUID和Local ID来管理资源，一切变化它都会关注，而且也会帮我们处理好。但是外在的变化它无从得知，所以只能出现错误。有趣的一点是，如果你只是删除了mate文件，但是不改变asset的位置，那么unity在重新生成mate时会给asset一个原来的GUID。 unity是如何在运行时管理资源的PersistentManager缓存的概念 由于GUID在运行时比较的时候效率较低，所以unity使用了一套其它的机制来管理运行时的资源。这就是PersistentManager缓存。unity将File GUID和Local ID翻译（个人认为应该是经过某种变换）成一个叫做Instance ID的整型数据，它在单独的会话（single session，难以理解）中是唯一的。我个人的理解是在一个进程中这个Instance ID是唯一的。 缓存维护了一个InstanceID和内存中实例对象的映射图。UnityEngine.Objects通过这个做到了强引用。通过Instance ID可以快速的找到内存中的对象。 PersistentManager缓存的初始化和更新 这个映射图在游戏启动的时候就会初始化。数据包含：游戏启动时初始场景中用到的对象的映射，Resources文件中所有的对象信息都会被映射到缓存中（这个缓存建立是需要时间的，所以如果Resources文件中内容太多启动会变慢）。 在游戏运行的过程中这个缓存也会进行更新。比如在运行时新的asset被导入了（不能理解这是一个什么场景），或者一些对象从AssetBundle中加载的时候，会生成新的Instance ID，新的对象，也就有了新的映射。 还有当AssetBundle被卸载的时候（这个卸载应该指的是所有已经实例化对象也被卸载），对应的映射数据会被删除。而当对象重新从AssetBundle中加载时，会产生一个新的Instance ID。这个也是后面会说到的AssetBundle管理的一个重要内容，如何保证无效的资源在卸载时也被删除掉。 需要注意一点就是有时一些特别的事件会导致内存中的对象被删除了，比如ios的挂起，此时unity是没有办法重新加载这些数据的（比如材质数据），此时场景中看到的就是品红色的对象了。所以如果手机上出现这个问题了，就要考虑是不是内存中对象被删除了。 Resource的生命周期加载 按照文中的说法有两种方式来加载UnityEngine.Objects，第一是被自动加载，这个需要一个实例ID映射到这个对象，同时这个对象没有加载进内存并被间接引用，而且对象的数据源存在。我对这个的理解是参考初始场景中的对象，前文说过它们会进入缓存中，而且在一开始肯定是内存中不存在的，而且如果这个实例ID对应的FILE ID和local ID是有效的，那么就会被自动的加载；至于说间接引用，讲真，没理解。 第二种加载就是代码加载了，这个API就多了，resources的load或者AssetBundle的load都可以做到。 当一个对象被加载，Unity 会尝试将所有引用从文件 GUID 和本地 ID 转换成实例 ID。（这个应该是为了把运行时的引用关系都保存在PersistentManager所管理的映射图中。） 卸载 如果一个fileID和localID没有对应的实例ID，或者实例ID所对应的fileID和localID无效了，那么就会出现missing的情况，此时实例ID仍旧是存在的，在场景中它也被别的对象引用着，但是你可能看不到它或者它显示为品红色。 这个情况其实挺常见的，由于操作问题导致asset的fileID发生了变化，但是原来的实例ID没有跟着更新，就容易出现。 文中列举了三个被卸载的情况 在未使用的asset被清理时对象会被自动卸载。这个过程会在场景切换的时候发生。 从Resources文件夹中加载的对象在调用Resources.UnloadAsset时会卸载。但是对象对应的实例ID保持有效，而且也对应着有效的fileID和localID。这些对象如果被其它的mono变了或者对象引用着，那么在调用Resources.UnloadAsset后这些对象会被重新加载。（这个就有意思了，代表在Resources.UnloadAsset函数有时不会实现我们想要的效果。） 当调用AssetBundle.Unload(false)时，unity不会将从这个AssetBundle中加载的还处于激活状态的对象销毁掉，但是会使这些对象对应的实例ID与fileID和localID断开引用。如果这些对象从内存中卸载并且对这些已卸载的对象的引用依然保持着，Unity将无法重新加载对象。 上面这段讲的比较奇怪，因为在后面的最后一章中应该是描述了这样的情况，此时是可以重新加载asset的，只不过会造成内存泄漏。 在注视中讲到了这个情况的一个例子就是APP被挂起后，GPU内存中的纹理、网格被删除了，那么在APP恢复后需要重新加载这些内容。 加载大的层次结构几个点 在序列化层级结构时会将所有对象和组件都单独的序列化到序列化文件中。这对于层级的加载产生阴影。 层级加载时CPU时间消耗在以下内容上： 读取序列化数据 在新创建出的transform中设置层级结构 实例化对象和组件 唤醒对象和组件（awake） 后面三条基本上花费的时间是固定的，但是第一条不一样。层级越复杂加载的越慢。 在所有平台上，内存读取速度快过磁盘，PC读取快过手机。因此当层级过于复杂时可能读取的时间都要长于实例化的时间。 对于层级中数据相同的对象会多次进行序列化，比如UI上30个复制出来的相同的元素会序列化三十次，加载的时候也是加载30个不同的数据，因此很耗时。 5.4之后unity修改了transform在内存中的呈现形式。每个根节点下的所有子层级都保存在一段紧密连续的内存中。当实例化一个会导致重新指定父级的新对象时，考虑使用GameObject.Instantiate方法的带父对象参数的重载。使用这个重载可以避免给新物体新分配根 tranform 层次。测试结果中，这个可以提高 5 - 10 % 的实例化时间。 总结 这个章节讲述了unity中对UnityEngine.Objects和asset的管理，从资材的导入到运行时的加载卸载。读完后应该明白一下几点： UnityEngine.Objects与asset的关系 asset导入后产生了mate文件，产生了fileID和localID的概念 asset在运行时中产生了实例ID的概念，并且实例ID和fileID、localID是通过一个映射图结合到了一起，这个映射图也让内存中的object与磁盘上的asset产生了联系。 asset可以被加载也可以被卸载，而它的卸载需要注意不要让资源出现内存泄漏的问题。 最后在场景中的层级结构需要合理的规划。","link":"/2017/07/16/2017-7-16-AssetBundle学习笔记：资产、对象和序列化/"},{"title":"Lua学习笔记：基本语法","text":"初步印象 语法和python、js这些很像，解释型语言、弱类型等等。写着舒服是真的。 while do\\repeat until这样的语法其实真心不舒服，感觉在语法上有些累赘。大多数语言都是do while，但是它非要是repeat until，也是无语。 我个人认为语法中的then和do设计的很混淆。比如if是和then，for是和do。从我对语言的理解上感觉可以统一用do或者then。 基本语法变量 只有布尔、字符串、数字、table和nil。但是没有一个明确的类型定义，完全按照赋值来进行推断。 默认是public，如果想private需要变量前加local。 可以一次性多复制，如果变量和值不对称，没有复制的变量为nil。 12345678910a,b,c = 1,2print(a)print(b)print(c)--结果12nil 作用域 在lua中一个local变量的作用域可以是在一个循环中或者在一段if代码中。也可以是贯穿整个的table中（感觉table在某种角度完全可以看做是一个类）。但是如果你想控制一个local变量的值作用域某个区间，那么可以使用do end来明确划分一个block。下面这个例子的结果是nil，因为x在作用域只在do end之间。但是这个不适用于全局变量，需要注意。 12345678do local x = 10endprint(x)-- 结果nil 对比一下下面两段代码的不同结果。其实尽可能的不要出现变量同名的情况，尤其是第二段代码的行为可能不是我们想要的。 12345678910x = 1do local x = 10 print(x)endprint(x)-- 结果101 12345678910x = 1local x = 10print(x)print(x)-- 结果11 关于do end还有个用法，在lua中return和break需要在end\\else\\until之前（发现在print之前也可以），否则编译会出错。此时就需要do end来包住return了。 12345678function boo() local x = 10 do return end local i = 10 print(1)end 循环 for\\while do\\repeat until，最后一个对象do while。 for分为数值型和泛型： 1234-- var从exp1变化到exp2，每次变化以exp3为步长递增var，并执行一次&quot;执行体&quot;。exp3是可选的，如果不指定，默认为1。for var=exp1,exp2,exp3 do &lt;执行体&gt; end 123for i,v in ipairs(a) do print(v) end for的循环中没有continue，这样导致了在for中可能出现if嵌套if的情况，因为没办法通过拆解if来实现简练的代码。不爽！！另外lua的 迭代 需要注意pairs 和 ipairs异同同：都是能遍历集合（表、数组）异：ipairs 仅仅遍历值，按照索引升序遍历，索引中断停止遍历。即不能返回 nil,只能返回数字 0，如果遇到 nil 则退出。它只能遍历到集合中出现的第一个不是整数的 key。pairs 能遍历集合的所有元素。即 pairs 可以遍历集合中所有的 key，并且除了迭代器本身以及遍历表本身还可以返回 nil。 1234567891011121314151617181920212223242526272829303132333435363738394041Demo1：local tabFiles = { [1] = &quot;test2&quot;, [6] = &quot;test3&quot;, [4] = &quot;test1&quot; }for k, v in ipairs(tabFiles) do --输出&quot;test2&quot;,在key等于2处断开 print(k, v)endDemo2：local tabFiles = { [2] = &quot;test2&quot;, [6] = &quot;test3&quot;, [4] = &quot;test1&quot;}for k, v in ipairs(tabFiles) do --[[什么都没输出，为什么？因为控制变量初始值是按升序来遍历的，当key为1时，value为nil，此时便停止了遍历， 所有什么结果都没输出]]-- print(k, v)endDemo3：local tabFiles = { [2] = &quot;test2&quot;, [6] = &quot;test3&quot;, [4] = &quot;test1&quot;}for k, v in pairs(tabFiles) do --输出2 test2, 6 test3, 4 test1 print(k, v)endDemo4：local tabFiles = {&quot;alpha&quot;, &quot;beta&quot;, [3] = &quot;no&quot;, [&quot;two&quot;] = &quot;yes&quot;} for i,v in ipairs(tabFiles ) do --输出前三个 备注：因为第四个key不是整数 print( tabFiles [i] ) end for i,v in pairs(tabFiles ) do --全部输出 print( tabFiles [i] ) end table概念 table 是 Lua 的一种数据结构用来帮助我们创建不同的数据类型，如：数字、字典等。 Lua table 使用关联型数组，你可以用任意类型的值来作数组的索引，但这个值不能是 nil。 Lua table 是不固定大小的，你可以根据自己需要进行扩容。 上面是runoob.com的lua教程中对table的描述。在我看来很难去描述table是个什么东西，但是我们可以通过对它的使用来总结它所扮演的一些角色，或者说什么场景下table能够作为什么来使用。 看下第二条，table中索引可以是任何类型的值，所以索引是个table也是可以的。但是必须不是nil，所以look = {[www] = &quot;ok&quot;} 这样是不对的，www没有赋值，所以默认为nil因此出错table index is nil 常见用法 数组 ： table一个典型的用法就是作为其它语言中的数组 12str = { 1,2,3}print(str[2]) 字典 ： 也是常见的用法 123str = {name=&quot;Sai&quot;,age=33}print(str[&quot;age&quot;])print(str.name) table使用中容易出现的问题 看下这段代码 1234567891011temp = 1tab = {[temp] = 1, 11}print(tab[1])for i,v in pairs(tab) do print(i,v)end-- 输出的结果是 ： 111 11 why?第一个print中为何结果不是1，因为tab[]这个用法的参数是key，而像11这样没有显示定义key的value默认的key就是1，所以这句话认为是输出key=1的value了。而且从遍历看居然只有一个数据，也就是说value 1的数据被替换掉了。 那么怎么让这个1显示出来呢？以我目前掌握的只能是改temp的值。 总结一下就是注意三点： 第一，所有元素之间，总是用逗号 “，” 隔开； 第二，所有索引值都需要用 “[“和”]”括起来；如果是字符串，还可以去掉引号和中括号； 即如果没有[]括起，则认为是字符串索引 第三，如果不写索引，则索引就会被认为是数字，并按顺序自动从 1往后编； 数组（lua叫table）下标从1开始，有点不习惯。 判断table是否是空（参考） 1234a={2}if next(a) ~= nil then print(next(a))end 字符串 ..是字符串相加，my god… 对于string的处理，除了用string.xxx(strArg)这样的方式外，还可以用strArg:xxx的方法。 函数 function可以返回也可以不返回结果，在定义时没有明确的约束。 支持多返回值，nice Lua函数不支持参数默认值，可以通过or来实现。 1234567function sum(a , b) a = a or 1.1 b = b or 2.2 return a + bend print(sum()) 支持闭包 12345678910111213tab = {1,2,3,4,5,6,7,8} function iter() local index = 0 return function() index = index + 1 return tab[index] endend for i in iter() do print(i)end 可变参数，这里有点小特别： Lua将函数的参数放在一个叫arg的表中，#arg 表示传入参数的个数。 1234567891011function average(...) result = 0 local arg={...} for i,v in ipairs(arg) do result = result + v end print(&quot;总共传入 &quot; .. #arg .. &quot; 个数&quot;) return result/#argendprint(&quot;平均值为&quot;,average(10,5,3,4,5,6)) 这个#还能来取table中元素的个数，但是使用限制比较大。建议还是开启循环来计算个数。 :和.的区别: 是个语法糖，调用的函数会自动传递参数self，即： 1234567891011121314local a = {x = 0}function a.foo(self, a) self.x = aendfunction a:foo2(a) self.x = aend--调用时：a.foo(a, 2)a.foo2(2)--上述两个操作是等价的，用:时就省去了定义和调用时需要额外添加self用来指代自身的麻烦. 需要注意的是如果一个table中的方法调local的非table方法（简单来说就是一个类方法要访问非类方法）需要将非类的方法定义在前面，这个和C的机制一样。同样的，非类方法之间的调用也要有顺序，都尼玛血泪的教训 API 标准库的API可以在这里查询到。 math.random的行为很是奇怪，一次调用永远产生相同的值。如果想得到不同的值，需要多次调用。 对于table等的操作建议看参考2的连接。","link":"/2017/07/29/2017-7-29-Lua学习笔记：基本语法/"},{"title":"每天一点UWA：第一周","text":"初衷 首先UWA一直以来都是一个我很喜欢的网站，因为他们在unity的优化方面是非常专业的，而且他们对于技术的分享也是毫不吝啬的。在他们的网站上有很多的技术文章，很久以来都想系统的阅读一遍，但是一直没有去做。这周开始下定决心要从第一篇开始，把UWA所有的技术分享文章读完，这个系列的文章会对每周读到的技术做一个总结，但是因为文章涉及的方向比较杂，因此会简单的用技术进行一个分类。 CPU方面的优化（很有用） 就目前的Unity移动游戏而言，CPU方面的性能开销主要可归结为两大类：引擎模块性能开销和自身代码性能开销。其中，引擎模块中又可细致划分为渲染模块、动画模块、物理模块、UI模块、粒子系统、加载模块和GC调用等等。 渲染模块 减少draw call。减少dc的核心办法在unity里面就是减少材质球。因为如果多个物体共用一个材质球（共同的贴图和shader）那么对于一次draw call来说就是传递顶点数多少的问题。 顶点数的多少引出了另一个问题，传输渲染数据的总线带宽。当大量GameObject满足批处理条件时（900个数据值），unity会合并mesh，但是一个超大的mesh数据传输起来也有瓶颈。因此关于draw call的优化不能是无脑的，需要平衡dc次数和总线带宽。 简化资源 渲染模块在CPU方面的优化方法还有很多，比如LOD、Occlusion Culling和Culling Distance等等 UI模块 文中以NGUI为例进行了函数的分析，但是UGUI应该也有借鉴的意义。 在NGUI的优化方面，UIPanel.LateUpdate为性能优化的重中之重，它是NGUI中CPU开销最大的函数，没有之一。对于UIPanel.LateUpdate的优化，主要着眼于UIPanel的布局，其原则如下： 尽可能将动态UI元素和静态UI元素分离到不同的UIPanel中（UI的重建以UIPanel为单位），从而尽可能将因为变动的UI元素引起的重构控制在较小的范围内； 尽可能让动态UI元素按照同步性进行划分，即运动频率不同的UI元素尽可能分离放在不同的UIPanel中； 控制同一个UIPanel中动态UI元素的数量，数量越多，所创建的Mesh越大，从而使得重构的开销显著增加。比如，战斗过程中的HUD运动血条可能会出现较多，此时，建议研发团队将运动血条分离成不同的UIPanel，每组UIPanel下5~10个动态UI为宜。这种做法，其本质是从概率上尽可能降低单帧中UIPanel的重建开销。 PS：结合之前关于UI优化的文章，UI优化的核心在于拆分UI元素。始终不变的归为一类，动态变化的归为一类。对于UGUI来说就是拆分Canvas。 PS2：关于UI重建的说明。UI其实是一些3D的quad，这一下就能够理解为什么存在UI的减少drawcall了，这个和模型的减dc完全一个原理。多个UI在一个Canvas下就存在多个UI的mesh合并问题（批处理），但是像血条这样的UI一般用的是progress，它的原理就是默认模式下改变quad的顶点数据来实现进度大小的改变，fxxx模式下是顶点和UV一起变，只要改变了顶点位置，那么mesh必要每次dc的时候都要重新计算。和它一起的那些不变的UI的计算是浪费的。 加载模块 目前加载模块性能开销主要在场景切换，分为前一场景的场景卸载和下一场景的场景加载。 场景卸载：主要是Destroy和Resources.UnloadUnusedAssets两个函数，前者的消耗多少主要取决于事件函数中代码的功能多少。后者耗时开销主要取决于场景中Asset和Object的数量，数量越多，则耗时越慢。 场景加载：主要是资源加载和Instantiate实例化。 资源加载几乎占据了整个加载过程的90%时间以上，其加载效率主要取决于资源的加载方式（Resource.Load或AssetBundle加载）、加载量（纹理、网格、材质等资源数据的大小）和资源格式（纹理格式、音频格式等）等等。不同的加载方式、不同的资源格式，其加载效率可谓千差万别。 在场景加载过程中，往往伴随着大量的Instantiate实例化操作，比如UI界面实例化、角色/怪物实例化、场景建筑实例化等等。在Instantiate实例化时，引擎底层会查看其相关的资源是否已经被加载，如果没有，则会先加载其相关资源，再进行实例化，这其实是大家遇到的大多数“Instantiate耗时问题”的根本原因，这也是为什么我们在之前的AssetBundle文章中所提倡的资源依赖关系打包并进行预加载，从而来缓解Instantiate实例化时的压力。 另一方面，Instantiate实例化的性能开销还体现在脚本代码的序列化上，如果脚本中需要序列化的信息很多，则Instantiate实例化时的时间亦会很长。最直接的例子就是NGUI，其代码中存在很多SerializedField标识，从而在实例化时带来了较多的代码序列化开销。因此，在大家为代码增加序列化信息时，这一点是需要大家时刻关注的。 以上是游戏项目中性能开销最大的三个模块，当然，游戏类型的不同、设计的不同，其他模块仍然会有较大的CPU占用。比如，ARPG游戏中的动画系统和物理系统，音乐休闲类游戏中的音频系统和粒子系统等。 PS：关于场景加载在之前的文章中也有讲到，尤其是AssetBundle系列文章中。根据unity对资源的管理方式，Resources文件夹里面的asset会全部加载到PersistentManager，当然这个过程只是建立InstanceID的过程，但是仍旧消耗了时间。 代码效率 一图胜千言 AssetBundle 4.x的内容就不考虑写出来了。 AssetBundle5.x怎么制作我在之前的一个blog中写过,可以说5.x极大的简化了AssetBundle的打包流程。 不考虑5.3前的情况，之后的版本建议使用LZ4打包，因为是按需解压加载的。 新增的AppendHashToAssetBundleName选项很不错，可以在生成AssetBundle时加入hash值，便于判定是否有更新，AssetBundleBrowser中支持。 几个注意的点： 新机制打包无法指定Assetbundle.mainAsset，因此无法再通过mainAsset来直接获取资源。 开启DisableWriteTypeTree可能造成AssetBundle对Unity版本的兼容问题，但会使Bundle更小，同时也会略微提高加载速度。 abName可通过脚本进行设置和清除，也可以通过构造一个AssetBundleBuild数组来打包。 Prefab之间不会建立依赖，即如果Prefab-A和Prefab-B引用了同一张纹理，而他们设置了不同的abName，而共享的纹理并未设置abName，那么Prefab-A和Prefab-B可视为分别打包，各自Bundle中都包含共享的纹理。因此在使用UGUI，开启Sprite Packer时，由于Atlas无法标记abName，在设置UI界面Prefab的abName时就需要注意这个问题。 5.x中加入了Shader stripping功能,在打包时，默认情况下会根据当前场景的Lightmap及Fog设置对资源中的Shader进行代码剥离。这意味着，如果在一个空场景下进行打包，则Bundle中的Shader会失去对Lightmap和Fog的支持，从而出现运行时Lightmap和Fog丢失的情况.而通过将Edit-&gt;Project Settings-&gt;Graphics下shader Stripping中的modes改为Manual，并勾选相应的mode即可避免这一问题。 Shader被打包到不同AssetBundle中了，WarmupAllShaders仅能对当前内存中的Shader进行warm up。后续如果又有Shader加载进来，则仍然会出现CreateGPUProgram操作。 PS:这一条在2017中发现custom选项中是全选的。 纹理 对于图片如果可以的话，建议直接将其制作成POT（ power of two，即图片的size是2次幂，这个也是unity建议的）图片，而非进行二次转换。ToLarger确实可以将纹理拉伸成POT纹理，但如果是UI界面（开启Pixel Perfect）的话，可能显示时会有较大视觉损失。 Texture占用内存总是双倍：出现这种情况的原因有两种：一种是在真机运行时开启了Read&amp;Write。另一种可能是Unity的Bug，目前的Unity 5.2.3 release note如下 ：(735644) - OpenGL: Fixed texture memory usage reporting in profiler, was twice the actual size for most textures. 纹理Atlas是合成一张2048（尺寸）的纹理还是四张1024的纹理在其他设置一致的情况下，这两种方式无论在加载还是渲染方面其实并没有实质上的差别。在我们接触到的大多数案例中，纹理资源方面的问题除了尺寸外，纹理格式、Mipmap设置和Read&amp;Write功能同样是需要研发团队时刻关注的。 PS:看来纹理的Read&amp;Write选项很重要 unity的工具 Overhead： Overhead的计算方法是：Profiler当前帧统计的总耗时时间减去所有已知选项的累加时间，即引擎当前还无法识别模块的耗时时间。 Overhead数值理论上是趋向于0的，但是由于目前市面上的硬件设备、系统框架过于丰富，所以引擎可能无法识别所有模块的CPU开销。 unity的分析工具中的Reserved Total 和 Used Total为Unity引擎在内存方面的总体分配量和总体使用量。 一般来说，引擎在分配内存时并不是向操作系统 “即拿即用”，而是首先获取一定量的连续内存，然后供自己内部使用，待空余内存不够时，引擎才会向系统再次申请一定量的连续内存进行使用。","link":"/2017/07/29/2017-7-29-每天一点UWA：第一周/"},{"title":"每天一点UWA：第三周","text":"内存资源复用 如果一个prefab被简单的多复制几次，里面的mesh、Texture、AnimationClip、Material这些都是被复用的，在profile中可以看到。但是如果prefab从AssetBundle中获取，并且多次的加载、实例化、卸载可能造成内存泄漏，因为unload(false)并没有真正卸载内存中的已经实例化的prefab，再次load时PersistentManager会认为是一个新的对象。 UI在多次开关后出现profile中资源重复 刚进游戏时获取的图中出现的“重复”资源可能并不是冗余，因为 Atlas的一个 Group 中可能包含多张一样大小的Page（即纹理），而这几个Page在内存中的名字是一样的。 但是，如果同一UI界面多次开启后，内存中出现了更多同样的资源，则说明UI的管理方式存在一定问题。对于频繁使用的UI，我们建议在加载之后通过缓冲池对其进行缓存，后续使用时，直接通过缓冲池获取即可。而不要每次均通过AssetBundle进行加载，这种做法既会造成更大的CPU占用，同样会很大几率造成资源的冗余。 同时，如果多次开启的是不同UI界面，并且造成内存中同种资源的增加，则很有可能是UI在AssetBundle打包时形成了冗余（这种情况在目前的UGUI系统中较为常见）。对此，如果开发团队使用的是UGUI，那么我们的建议如下： 对于使用Unity 5.x的新AssetBundle打包系统，则打包时尽可能将同种Atlas的UI界面打成一个AssetBundle文件，否则将很有可能出现资源冗余的情况； 对于使用Unity 4.x的老AssetBundle打包系统，则可以将一个含有Atlas的Prefab（或其他Object）先打包，其他UI元素对其进行依赖即可。 物理RigidBody + CapsuleCollider替换CharacterController 高效一些，因为 move 函数本身会进行较复杂的模拟运算。 Static Collider.Move (Expensive Delayed cost)警告 Static Collider.Move (Expensive Delayed cost) 意味着场景中有静态碰撞体（不带有RigidBody的Collider）发生了移动，而该操作在Unity 4.x版本的PhysX 中会在后续的模拟中产生较高的开销，但在 5.x 中理论上开销并不明显。如果要消除该问题，只需定位到发生位移的Collider并挂上RigidBody 组件，打开其is kinematic 选项即可。 渲染什么在影响lightmap尺寸 首先确认下Lightmap的类型，Single类型只生成一张，而Dual和Directional会生成两张。 其次，确认下当前的发布平台，Android下的Lightmap会比Standalone更小。因为不同平台采用的压缩格式不同。此外，Lightmapping中的Lock Atlas，Resolution，Padding等选项也会影响最后烘焙光照图的大小。 原先的Lightmap不再影响合并后的Mesh 总结一句就是不要讲使用了多个lightmap的mesh进行合并。 关于抗锯齿和BLOOM，有什么好的优化方案或者优秀插件推荐？ 通常在中低端的设备上，抗锯齿并没有比较高效的方案；而对于中高端的设备，可尝试直接使用 Unity 内置的 MSAA 功能，但也只推荐使用 2x。关于Bloom效果，以下是适用于移动端，且评价较好的一款插件：BloomPro AssetBundle5.x后设置好AssetBundle Name就可以实现依赖资源的独立打包4.x时代不同版本之间的AssetBundle不能通用unload顺序 在 Resources.UnloadUnusedAssets() 时，如果还没有进行AssetBunlde的Unload 操作，那么从AssetBunlde中加载的资源依然会因为被AssetBunlde引用而无法被卸载。 开发团队可以尝试 Destory 后做 AssetBunlde的Unload，最后进行 Resources.UnloadUnusedAssets()。 生成AssetBundle的时候每个文件会多生成一个Manifest文件，这个文件也需要一起随着AssetBundle上传吗，在资源加载的时候具体怎么用呢？ 每个文件多生成的Manifest 文件是不需要上传的，其作用就是供开发人员查看AssetBundle 中的依赖关系等信息。 但除了每个文件多生成的 Manifest 以外，根目录下还会有一个与根目录同名的AssetBundle 以及 Manifest 文件，通过运行时加载这个AssetBundle，可以得到一个 AssetBundleManifest 对象，然后就可以通过这个对象得到AssetBundle直接的依赖关系。 选择移动平台后，editor下shader显示错误 是Unity已知的一个问题，Android 和 iOS 的部分Shader在打包后，在Editor 下无法正常显示。 主要原因是在打包时，只会把对应平台的Shader预编译代码（如 gles ）打入包中，因此在 Editor 下会执行失败（通常 Editor 是 d3d 驱动）。 因此，目前只能尝试在Editor下重新指定Shader来绕过这个问题。 Textureios上的ASTC格式 ASTC在 iOS 的高端机上是被支持的，因此理论上在 Editor 下不会强制把 ASTC 转为 RGBA32，建议尝试设置为 ASTC 后打包，从 Editor.log 中或者直接从包体大小上可以看出是否确实使用了ASTC。 一般来说，如果 RGBA16 的效果可以接受的话，建议使用 RGBA16，虽然打包时相对大一些，但是内存中相比 RGBA32 能够减半，但使用 ASTC 的话，虽然打包时比较小，但是在普通机型上会被处理成 RGBA32，导致过大的内存开销。 UIShared UI Mesh Shared UI Mesh是在Unity 5.2 版本后UGUI系统维护的UI Mesh。在以前的版本中，UGUI会为每一个Canvas维护一个Mesh（名为BatchedMesh，其中再按材质分为不同的SubMesh）。而在Unity 5.2版本后，UGUI底层引入了多线程机制，而其Mesh的维护也发生了改变，目前Shared UI Mesh作为静态全局变量，由底层直接维护，其大小与当前场景中所有激活的UI元素所生成的网格数相关。 一般来说当界面上UI元素较多，或者文字较多时该值都会较高，在使用UI/Effect/shadow和UI/Effect/Outline时需要注意该值，因为这两个Effect会明显增加文字所带来的网格数。 Build打包注意 打包的时候Resources文件夹下所有的内容都会被打入resources.assets，要想包体小就删除不要的资源。而且Resources目录下所以资源启动时参与persistentmanager的初始化，内容多了会卡。 static选项 如果在Editor中进行勾选，则会在项目中生成一个较大的VBO，Runtime时通过该VBO来进行渲染，优点是有效减少了Draw Call，缺点是增大了发布游戏包的体积。 如果在Runtime通过脚本来进行Batching，则相当于把拼合的时间由Editor中搬到了Runtime，所以加载时间（一般在场景加载时执行Batching）会稍有增加，但游戏包的体积将相应减少。 动画Optimize GameObject 在选择Optimize GameObjects后，可在Extra Transforms中加入你想挂载特效的骨骼结点，这样该骨骼结点将不会进行优化处理，即其Transfrom将不会消失。 工具WaitForTargetFPS 该参数一般出现在CPU开销过低，且通过设定了目标帧率的情况下（Application.targetFrameRate）。当上一帧低于目标帧率时，将会在本帧产生一个WaitForTargetFPS的空闲等待耗时，以维持目标帧率。 该项在Unity引擎的主循环中其实是最早执行的。 Gfx.WaitForPresent &amp; Graphics.PresentAndSync 这两个参数在Profiler中经常出现CPU占用较高的情况，其实是CPU和GPU之间的垂直同步（VSync）导致的，之所以会有两种参数，主要是与项目是否开启多线程渲染有关。当项目开启多线程渲染时，你看到的则是Gfx.WaitForPresent；当项目未开启多线程渲染时，看到的则是Graphics.PresentAndSync。 Gfx.WaitForPresent其真实的意思应该是为了在渲染子线程（Rendering Thread）中进行Present，当前主线程（MainThread）需要等待的时间。 最后，如何优化并降低这两个参数的CPU占用呢？ 那就是，忽略Gfx.WaitForPresent 和 Graphics.PresentAndSync这两个参数，优化其他你能优化的一切！WTF！ PS：这篇内容相当不错，建议看原文。 editor下出现AssetDatabase内存过高可以无视Canvas.SendWillRenderCanvases Canvas.SendWillRenderCanvases为UGUI中非常重要的接口，经常会出现较高的性能开销。当Canvas中的UI元素出现了长、宽或Alpha变化时，UGUI会更新其所在Canvas中所有UI元素的Transform、状态等等。Canvas中UI Mesh顶点较多的话，则该项将会出现较高的CPU开销。 Loading.UpdatePreloading Loading.UpdatePreloading为Unity引擎的主要加载函数。场景中的资源加载（包括Texture、Mesh、Shader、AnimationClip等）和相关序列化操作均在其中体现。因此，如果该值开销较高，建议研发团队对资源进行进一步的优化和控制。 脚本如果脚本引用了GameObject，那转换场景的时候脚本和GameObject都没了，还会产生堆内存的吗？ 如果脚本是MonoBehaviour，而且在切换场景后所挂的Game Object被释放了，那么这个脚本对象所引用的堆内存就会在GC的时候被释放。 但有一种例外，如果是通过Static变量引用的堆内存，那么依然是释放不掉的，除非手动解开引用，比如变量置Null，数组Clear等等。 粒子粒子动态合并 粒子系统的Draw Call动态拼合与半透明物体的动态拼合机制相当（粒子基本都是半透明材质）。而对半透明物体，由于其渲染顺序的限制（必须从后向前渲染，以保证渲染结果的正确性），动态拼合只能对渲染顺序相邻且材质相同的物体有效。而在决定半透明物体的渲染顺序时，Unity首先会按Shader中的RenderQueue进行排序；其次（相同RenderQueue时），会根据每个半透明物件到屏幕的距离，距离大的优先渲染。 因此，需要尽可能地将相同材质的粒子系统放在比较接近的深度下，才能更多地使动态拼合生效。但通常由于相机的运动、粒子系统的分散分布等原因造成粒子系统之间的穿插，能够动态拼合的数量往往都是很少的。 目前粒子系统已经不再进行 Draw Call 的拼合，因为在新版本5.3 中已通过多线程进行更新，暂时无法支持拼合，但性能已经得到提升。","link":"/2017/08/14/2017-8-14-每天一点UWA：第三周/"},{"title":"每天一点UWA：第四周","text":"AssetBundleResources.UnloadAsset仅能释放非GameObject和Component的资源，比如Texture、Mesh等真正的资源。对于由Prefab加载出来的Object或Component，则不能通过该函数来进行释放。 用的是Resource的加载方式，并且已经预加载好了材质所在的Prefab ，但是为什么在第一次显示材质的时候还要Load这个材质？ 我的理解是prefab只是个资源GUID的合集，并不包含真正的资源。所以要使用真正的资源（mesh\\texture等时要加载。） 通过 Resources 加载和通过 AssetBundle 加载是有所区别的。Resources.Load 和 Instantiate 操作都不会立刻加载其依赖的材质，因此在loadPrefab = Resources.Load之后，其依赖的材质（包括相关的 Shader 和纹理）实际并没有被加载到内存中，在实例化后也是一样，直到某个 Camera 需要对其进行渲染时（调用了 Material.SetPastFast），才发现该材质还没进内存，此时才开始进行加载。 因此，在使用 Resources 加载的情况下，如果希望提前加载该 Material 以及相关的 Shader 和纹理，可以尝试通过调用 Resources.Load 直接加载该材质和纹理，并通过 Shader.Find 来加载 Shader。也可以尝试通过 Player Settings 中的 Preload Shaders（配合 Graphics Settings 下的 Preloaded Shaders） 和 Preloaded Assets 来批量预加载。 BuildEditorOnly tag prefab打上EditorOnly tag，但是放到了Resources文件夹下一样会打包进入，因为理论上只对场景中的GameObject有效。- 不放到Resources文件夹下，然后在使用EditorOnly tag，打包时就会认为没有场景中的物件引用prefab，就不会打包了。 内置的shader怎么打包？ 通常有两种方式对内置的Shader进行打包： 将其添加到Graphics Settings中的Always Included Shaders 中，此时添加后的内置Shader就不会被打入AssetBundle包中； 在http://unity3d.com/cn/get-unity/download/archive下载内置的 Shader，将其导入项目，并替换成非内置的材质球，从而可以直接通过脚本来控制其打包的方式。 GC.MarkDependencies的CPU消耗有过高，虽然在退出战斗的时候调用了Resources.UnloadUnusedAssets(); 可是卡顿还是很明显 GC.MarkDependencies的消耗是由Resources.UnloadUnusedAssets引起的。该函数的主要作用是查找并卸载不再使用的资源。游戏场景越复杂、资源越多，该函数的开销越大，一般在300~2000 ms范围内。 对于该函数的优化，我们建议一方面控制场景中不必要的资源量，同时通过UnloadAsset来及时卸载不再使用的资源，以减少Resources.UnloadUnusedAssets的耗时压力。 打包时候AssetBundle的md5总变化(被打包的东西没变) 对于Unity 4.x版本的AssetBundle文件，其md5值在某些情况下确实会前后不一致（哪怕是完全一样的内容进行打包）。对于该系列版本，仅能建议开发团队建立配置文件来对AssetBundle进行管理。 而对于Unity 5.x版本，则可以在打包时开启 AppendHashToAssetBundleName 选项，这样Unity引擎会在每个AssetBundle文件后生成一个唯一的HashID（显示地放在文件名后），开发团队可以通过该ID来判断对应的AssetBundle文件是否发生改变。 CPU第一次执行GameObject.Instantiate一些资源的时候会卡 Instantiate的卡顿与三部分开销相关：相关资源加载、脚本组件的序列化和构造函数的执行，并且绝大部分原因均是相关资源加载导致。所以，我们的建议如下： 通过 Profiler 查看 Instantiate 具体的CPU分配情况； 如果是资源加载导致的性能瓶颈，则一方面通过简化资源来缓解CPU耗时压力，另一方面通过 AssetBundle 依赖关系打包将资源预先加载，即将此处 Instantiate 的总体耗时拆分，平摊到之前帧进行执行（比如切换场景处等），从而让 Instantiate 实例化操作的局部耗时更加平滑； 如果是脚本组件序列化导致的性能瓶颈，则可尝试减少脚本中的序列化信息； 如果是构造函数的执行导致的性能瓶颈，一般只能在策略上进行规避，比如降低 Instantiate 的调用频率等。 UI本周的UI有很多不错的技术知识能否对提升NGUI的渲染效率提供一些思路？ 开发团队可以从以下几点入手： 通常一个Panel会产生1个或多个Draw Call，以一个Panel为单位，Draw Call 的数量通常由当前 Panel 中使用的Atlas、Font的数量所决定。 要降低UI渲染时的 Draw Call数量则需要对 Atlas 的制作进行合理的规划，即在保证使用较少的 Atlas 的同时，还需要保证 Atlas之间不会存在交叉遮挡。 要注意UI Texture的使用，每个UITexture自身会占用一个Draw Call，同时如果其Depth值穿插在了其他来自相同Atlas的UISprite中，还会导致Draw Call的打断，造成不必要的额外Draw Call。 另外还可以借助Panel Tool和Draw Call Tool来对UI部分的Draw Call进行分析，前者可以显示每个UIPanel包含了多少个Draw Call，而后者可以显示每个Draw Call由哪些UIWidget组成。 如何查看每次Rebuild Batch影响的顶点数， Memory Profiler是个办法但是不好定位。 5.2后开始使用Shared UI Mesh来存储UI Mesh，所以很难查看每次Rebuild的UI顶点数。可以尝试通过Frame Debugger工具对UI界面进行进一步的查看。 通过移动位置来隐藏UI界面，会使得被隐藏的UIPanel继续执行更新（LateUpdate有持续开销），那么如果打开的界面比较多，CPU的持续开销是否就会超过一次SetActive所带来的开销？ 通过移动的方式“隐藏”的UI界面只适用于几个切换频率最高的界面 一般来说在没有UI元素变化的情况下，持续的 Update 开销是不太明显的。 游戏中出现UI界面重叠，该怎么处理较好？比如当前有一个全屏显示的UI界面，点其中一个按钮会再起一个全屏界面，并把第一个UI界面盖住。我现在的做法是把被覆盖的界面 SetActive(False)，但发现后续 SetActive(True) 的时候会有 GC.Alloc 产生。这种情况下，希望既降低 Batches 又降低 GC Alloc 的话，有什么推荐的方案吗？ 可以尝试通过添加一个 Layer 如 OutUI， 且在 Camera 的 Culling Mask 中将其取消勾选（即不渲染该 Layer）。从而在 UI 界面切换时，直接通过修改 Canvas 的 Layer 来实现“隐藏”。但需要注意事件的屏蔽，禁用动态的 UI 元素等等。这种做法的优点在于切换时基本没有开销，也不会产生多余的 Draw Call，但缺点在于“隐藏时”依然还会有一定的持续开销（通常不太大），而其对应的 Mesh 也会始终存在于内存中（通常也不太大）。 PS：一个经典的场景，一个非常巧妙的答案。学到了。 在UI界面中，用Canvas还是用RectTransform做根节点更好？哪种方法效率更高？ 简单来说，因为一个Canvas下的所有UI元素都是合在一个Mesh中的，过大的Mesh在更新时开销很大，所以一般建议每个较复杂的UI界面，都自成一个Canvas(可以是子Canvas)，在UI界面很复杂时，甚至要划分更多的子Canvas。 同时还要注意动态元素和静态元素的分离，因为动态元素会导致Canvas的mesh的更新。最后，Canvas又不能细分的太多，因为会导致Draw Call的上升。 PS：总结来说就是不分子Canvas会导致mesh过大，分的太多dc过高，在于平衡。 使用File类来读取图片的bytes流，512x512的RGBA32格式图片使用了2MB内存 首先正常的512x512的RGBA32图片的大小为4byte * 512 * 512 / 1024 / 1024 = 1MB，这个2MB是因为内存和显存各需要一份。file read的时候本身会产出一份，在向GPU发送的时候会备份一份，推测是这样。 一般来说，比较建议通过AssetBundle来动态加载资源，而非通过bytes流来进行加载。如果你的项目正在使用这种方式来加载纹理，我们建议从策略上考虑将其更改。 在我们目前来看，通过bytes流来生成资源，绝大部分原因是想对其进行加密，从而让资源难于破解。但其实这种加密方式用处不大，因为据我们所知，现在有很多工具可以直接通过底层显卡层来直接查看各种纹理、Mesh资源，比如Mali Graphics Debugger、Qualcomn Profiler等。因此，如果是从加密的角度来通过bytes流生成资源，那么我们建议通过AssetBundle这种直接的方式进行加载。 动画CullCompletely 使用 CullCompletely 在开启 RootMotion 时是需要注意的，比如人物有一个巡逻动画是通过 RootMotion 制作的，那么在人物走出屏幕后，其动画就停止了，即不会再走回屏幕中。 渲染场景中一个点光源，烘焙前暗，后亮是为何？ 简单来说，这就是实时的直接光照和全局光照的差别。在渲染时前者只能处理光源和单个物件之间的直接光照，而后者在烘焙时是通过光线跟踪或者辐射度等复杂算法，计算出所有物体各个表面之间相互反射的光照信息，这也是烘焙Lightmap需要较久的时间的原因 。可以发现在全局光照下，即使是物体的背面也会因为其它表面的反射而被照亮，这在直接光线下就无法实现这样的效果。 相同效果前提下，就性能而言，Shader 是用 V&amp;F 还是Surface好？ V&amp;F，Surface生成的V&amp;F比较庞杂，分支较多，如果不注意 #pragma surface 参数的选择，容易出现不必要的开销。 大面积的面片会导致baked GI时间过久，拆分大面积的面片对渲染性能也会有所提升Handheld.PlayFullScreenMovie 首先这天放在这里似乎不合适。 Android上PlayFullScreenMovie 的实现实际上是通过Android原生的接口直接播放的，播放过程中Unity也是停止更新的，因此这部分的内存理论上并不会记录在 Unity 中，同样也不影响mono。","link":"/2017/08/27/2017-8-27-每天一点UWA：第四周/"},{"title":"每天一点UWA：第二周","text":"内存概述 内存的开销无外乎以下三大部分：1.资源内存占用；2.引擎模块自身内存占用；3.托管堆内存占用。 资源内存 大头在纹理，其次在网格、动画片段和音频。 纹理从格式解决内存占用问题 选择正确的格式，比如Android上是ETC，ios的PVRTC，PC上DXT。 不同格式可能出现的问题： 因为ETC、PVRTC都是有损压缩因此可能出现色阶问题，如果用RGB32这样的格式虽然能解决问题但是内存占用太大。好的办法是在做纹理的时候减少色差范围，必要做出高对比度的阶梯式的图。 比如，同样一张1024x1024的纹理，如果不开启Mipmap，并且为PVRTC格式，则其内存占用为512KB，而如果转换为RGBA32位，则很可能占用达到4MB。 OpenGL ES2的设备只支持ETC1，但是ETC1不支持alpha通道。解决办法是将透明图分成两张，一个RGB24的保存RGB通道，一个alpha8的保存A通道，然后在使用时使用定制的shader去分别读取两个纹理图。 PS：OpenGL ES 3.0支持ETC2甚至ASTC，都是很好的支持透明通道的压缩格式。 选择合适的纹理设置 能512解决的事情别用1024 选择性的使用mipmap，对于UI这样的纹理使用完全没有必要用mipmap。 Read &amp; Write选项会使得纹理的内存使用量增加一倍。 网格 mesh中顶点信息可以进行相关的优化，比如Normal、Color和Tangent这些数据要按照需要来做，不用的就不要做。而且顶点信息超多900还不能动态批处理。不需要就计算发现的时候就可以不用tangent数据了，有贴图的话color数据也不需要。 Color数据和Normal数据主要为3DMax、Maya等建模软件导出时设置所生成，而Tangent一般为导入引擎时生成。 如果项目对Mesh进行Draw Call Batching操作的话，那么将很有可能进一步增大总体内存的占用。比如，100个Mesh进行拼合，其中99个Mesh均没有Color、Tangent等属性，剩下一个则包含有Color、Normal和Tangent属性，那么Mesh拼合后，CombinedMesh中将为每个Mesh来添加上此三个顶点属性，进而造成很大的内存开销。 引擎模块自身占用内存 引擎自身中存在内存开销的部分纷繁复杂，可以说是由巨量的“微小”内存所累积起来的，比如GameObject及其各种Component（最大量的Component应该算是Transform了）、ParticleSystem、MonoScript以及各种各样的模块Manager（SceneManager、CanvasManager、PersistentManager等)… 一般情况下，上面所指出的引擎各组成部分的内存开销均比较小，真正占据较大内存开销的是这两处：WebStream 和 SerializedFile。 PS：5.4以后没有webStream的概念了，不过还是要考虑WWW和LoadFromMemory中会保存AssetBundle原始数据的问题，参见Asset Bundle Compression AssetBundle所占的内存也需要考虑，尽可能做到按需加载，用完后及时的清理。 托管堆内存占用/无效的Mono堆内存开销 Mono的堆内存一旦分配，就不会返还给系统。这意味着Mono的堆内存是只升不降的。 不必要的堆内存分配主要来自于以下几个方面： 高频率地 New Class/Container/Array等。不要再update占用的函数中实例化对象。 Log输出，需要适当的减少log，只保留最关键的。 UIPanel.LateUpdate。这是NGUI中CPU和堆内存开销最大的函数,是由UI网格的重建造成。 一些推荐的办法 不要一次加载一个过大的资源，比如配置文件、纹理图等。这样会造成一次性申请过多的内存，但是还不回去了。 内存泄漏 首先通过工具发现场景切换开始和结束时内存使用没有一致，这个现象不能说明内存就一定有泄漏。比如资源加载后常驻内存以备后续使用、Mono堆内存的只升不降等等，这些均可造成内存无法完全回落。 检查资源的使用情况，特别是纹理、网格等资源的使用 这段主要介绍了如何使用UWA的工具对纹理和网格进行检查，查看是否出现资源的内存泄漏。 通过Profiler来检测WebStream或SerializedFile的使用情况 直接通过Profiler Memory中的Take Sample来对其进行检测，通过直接查看WebStream或SerializedFile中的AssetBundle名称，即可判断是否存在“泄露”情况。 资源冗余 是指在某一时刻内存中存在两份甚至多份同样的资源。导致这种情况的出现主要有两种原因： AssetBundle打包机制出现问题 显而易见，对于公用资源需要进行合理的划分打包。 资源的实例化所致 在Unity引擎中，当我们修改了一些特定GameObject的资源属性时，引擎会为该GameObject自动实例化一份资源供其使用，比如Material、Mesh等。以Material为例，我们在研发时经常会有这样的做法：在角色被攻击时，改变其Material中的属性来得到特定的受击效果。这种做法则会导致引擎为特定的GameObject重新实例化一个Material，后缀会加上（instance）字样。其本身没有特别大的问题，但是当有改变Material属性需求的GameObject越来越多时（比如ARPG、MMORPG、MOBA等游戏类型），其内存中的冗余数量则会大量增长。虽然Material的内存占用不大，但是过多的冗余资源却为Resources.UnloadUnusedAssets API的调用效率增加了相当大的压力。 上面描述的material的问题是个常见的问题。如果是直接改变还好说，会产生一个material instance，但是如果是在一段时间内线性的改变某个属性，那么后果很难说。 建议 一般情况下，资源属性的改变情况都是固定的，并非随机出现。比如，假设GameObject受到攻击时，其Material属性改变随攻击类型的不同而有三种不同的参数设置。那么，对于这种需求，我们建议你直接制作三种不同的Material，在Runtime情况下通过代码直接替换对应GameObject的Material，而非改变其Material的属性。这样，你会发现，成百上千的instance Material在内存中消失了，取而代之的，则是这三个不同的Material资源。其中的益处，对于能够阅读到这里的你来说，应该已经不需要我多说了。 粒子 Navmesh是不支持动态加载的目前的，办法是将多个场景做成prefab，然后用LoadLevelAdditive的方式加载，去拼接。 AssetBundle 本周第一篇关于AssetBundle的文章可以说有点陈旧了，在5.3以后解决了一些功能，比如AssetBundle.LoadFromFile加载LZMA文件的失败的问题。 还有就是在5.4以后已经没有webstream的概念了。 最后开始使用UnityWebRequest 热更新打包时LightmapSnapshot.asset无法导出，导致场景丢失lightmap LightmapSnapshot.asset是editor模式下的无法打包。解决办法是整个scene打包，lightmap信息会打包进去。或者在运行时调用Lightmapsettings.Lightmaps来设置，但是5.x后lightmap信息不会保存在prefab中，因此需要重设Prefab的Lightmap信息（Lightmapindex和Lightmapscaleoffset）。 还有一种可能是因为打包场景的时候shader会根据当前场景的使用情况来打包，如果打包是在一个空场景中那么bundle中的shader会失去lightmap和fog的支持。这个 PS: 这个问题在5.5.2中也存在，而且打包的时候是按照场景打包的，但是是不是shader丢失确实需要测试。 prefab打包 如果有一个Prefab，它的Dependencies都在Resources文件夹中，那么，当我在AssetBundle打包时，只打包这个Prefab（不指定BuildAssetBundleOptions.CompleteAssets和BuildAssetBundleOptionsCollectDependencies）是不能正确实例化的，因为AssetBundle中的资源和Resource文件夹下资源是不会建立依赖关系的（脚本除外，因为开启BuildAssetBundleOptionsCollectDependencies 时，脚本依然不会打包到AssetBundle中）。所以会出现Mesh、Material等的丢失。 卸载依赖AssetBundle的问题 比如prefabA和prefabB依赖于AtlasC，那么分别打包的话首先肯定是要先加载AtlasC的AssetBundle的。 但是如果先从AtlasC的AssetBundle中load了AtlasC，然后unload这个AssetBundle，此后加载或实例化A和B时，引擎将无法自动将C绑定给A和B进行使用。这个需要注意。 纹理格式 目前来讲，并不存在一个所有GPU平台都支持硬件解压的压缩格式。 ETC1 和 PVRTC 分别是Android和iOS上我们最推荐的格式。 但对于透明纹理，ETC1不支持，而 PVRTC 则可能有较大失真，因此更推荐使用 RGBA 16。 一般来说建议直接使用 Unity 默认的压缩格式（即选择 Compressed 即可，不需要做特殊设置），Unity 会做如下处理： Android 上不带Alpha通道的图片采用 ETC1，带Alpha通道的图片采用True Color中的RGB16，TrueColor中的 RGBA16 会&gt;比 RGBA32 更节省空间，但图像的显示质量会差一些； iOS 上使用 PVRTC，但PVRTC格式要求纹理的长宽相等，且都是2的幂次（即POT，在ImportSettings中可以将NPOT的纹理自动转换成POT）。 同时，我们不建议直接使用 RGBA32 格式的纹理，因为它占用了很大的内存。一般建议使用 RGBA16 和 ETC 格式的纹理来进行加载。 如果转换到 RGBA16 格式时出现了类似“色阶”的颜色问题，则建议尽可能避免大量的过渡色使用。 工具 unity的分析工具中的Reserved Total 和 Used Total为Unity引擎在内存方面的总体分配量和总体使用量。 一般来说，引擎在分配内存时并不是向操作系统 “即拿即用”，而是首先获取一定量的连续内存，然后供自己内部使用，待空余内存不够时，引擎才会向系统再次申请一定量的连续内存进行使用。 Overhead： Overhead的计算方法是：Profiler当前帧统计的总耗时时间减去所有已知选项的累加时间，即引擎当前还无法识别模块的耗时时间。 Overhead数值理论上是趋向于0的，但是由于目前市面上的硬件设备、系统框架过于丰富，所以引擎可能无法识别所有模块的CPU开销。 Unity Profiler反馈的则是引擎的真实物理使用内存，有时内存使用数值比原生的分析工具小是正常的。 Profiler中ManagedHeap.UsedSize是项目逻辑代码在运行时申请的堆内存，ManagedHeap.UsedSize过大，一方面可能会影响一次GC的耗时；另一方面也可能反映出脚本中不合理的GC Alloc。该选项只能通过优化代码来进行降低。 优化方法一般如下： 尽可能地复用变量，减少new的次数； 使用StringBuilder代替String连接，使用for代替foreach； 对于局部变量或非常驻变量，尽可能使用Struct来代替Class。 本周读到的所有关于内存监控的部分都提到了一个概念就是Profiler所监控到的数据和Android上的PSS或者ios上检测到的会不一致，这 个是因为Unity Profiler反馈的是引擎的真实分配的物理内存，而PSS中记录的则包括系统的部分缓存。一般情况下，Android或iOS并不会及时将所有App卸载数据进行清理，为了保证下次使用时的流畅性，OS会将部分数据放入到缓存，待自身内存不足时，OS Kernel会启动类似LowMemoryKiller的机制来查询缓存甚至杀死一些进程来释放内存。因此，并不能通过一两次的PSS内存没有完全回落来说明内存泄露问题。 Reserved GFX 中的内存，主要是纹理和网格资源。 渲染Lightmap在PC上显示正常，但是转到Android平台上存在色差，颜色普遍偏暗的问题 Unity烘焙的Lightmap是32bit的HDR图，而移动设备通常不支持HDR图(32bit per channel)，会按照LDR图(8bit per channel)的形式进行处理，因此会出现色偏问题。因此需要如下的处理： 在移动平台下使用Mobile/Diffuse材质，可载入Standard Assets(Mobile) package获得。 如果要获得更合适的效果，需要自行修改Lightmap的DecodeLightmap函数，该函数可在Unity\\Editor\\Data\\CGIncludes\\UnityCG.cginc文件中找到。需要说明的是，这种方法也不能达到与PC端完全一致的效果。 如果需要PC和移动平台的显示效果一致，可以用图像编辑软体修改Lightmap為LDR格式，例如PNG(8bit per channel)。 为了避免类似问题，请不要使用过于强烈的Light进行烘焙，因為Light的强度(Intensity)越高，色偏问题会越严重。若有阴影丢失时，可以尝试检查一下模型的Lightmapindex、Lightmapscaleoffset、UV2等影响Lightmap采样的一些参数。 另一种可能是存在过曝现象，可以尝试将playersettings -&gt; use direct3d 11关闭，看问题是否解决。 lightmap动态加载 Lightmap的动态加载，需要通过脚本将烘焙时每个物件的Lightmapindex和Lightmapscaleoffset记录下，并在运行时动态加载后设置回去的方式来实现。因为目前Lightmapindex和Lightmapscaleoffset信息是和场景绑定在一起，储存在Lightmapsnap.assets 中，发布时也是放在场景信息中，因此不会记录在Prefab 上。","link":"/2017/08/07/2017-8-7-每天一点UWA：第二周/"},{"title":"每天一点UWA：第八周","text":"AssetBundle打包AssetBundle的时候，我发现切换场景时，即使打同一个场景的AssetBundle，它们的Hash值都是不一样的，可能是什么原因造成的呢？ 目前很可能是Shader Stripping造成的，其原理可见文档。 简单来说就是根据当前场景对Shader进行简化，因此如果打包时包含的场景的Lightmap或Fog设置不同，打出来的AssetBundle包也有可能是不同的。可以尝试通过把Graphics Settings中的Shader Stripping设置进行修改来避免这个问题。 Prefab目前，只能通过Unload(True)和Resources.UnloadUnusedAssets卸载。 请教一下，为什么NGUI的Atlas通过AssetBudle载入之后，使用Resources.UnloadUnusedAssets()不能够释放呢？分析器里面引用是1，但是又找不到哪里引用了。 如果Unity Profiler中看到了资源的引用计数不为0，则说明该Atlas资源还在被索引，这样使用Resources.UnloadUnusedAssets()是无法进行卸载的。只有将其索引消除，该资源才会被认为是UnUsed资源，这样才能被Resources.UnloadUnusedAssets()卸载。该资源的引用计数不为0的原因可能有以下几种： 它被缓存在某些Container中，即它从AssetBundle或Resources中加载后，被直接缓存到某个容器中，从而产生了索引，只要它没有被清除出容器，那么索引将一直存在； 它被其他Material、Prefab等索引，而这些资源被缓存在某些容器中，即间接被容器缓存，只要索引它的资源不被清楚，那么它的索引页将一直存在。就目前我们遇到的泄露问题来看，上述两点为最为主要的原因。因此，如果你的项目中也存在类似情况，建议首先以此为基础对容器的使用进行排查。 UIUGUI的SrcollView Mask遮挡不住特效，这个有没有可行的解决方案？ UGUI的Scrollview Mask组件使用的是Stencil Buffer，需要严格确保渲染顺序的正确性，这对于粒子系统或是其他的模型较难控制，因此可以尝试通过其他的方式，如实现一个四边形Alpha 裁剪的Shader，将ScrollView的裁剪区域传入Shader，从而模拟一个特效被“遮罩”的效果。以下是宣雨松博客中提出的一种方式，可以作为参考：http://www.xuanyusong.com/archives/3518 Spine动画在NGUI的ScrollView滚动区域的层级也会出现问题，请问怎么裁剪Spine动画呢，Spine是骨骼，这不就等于给特效换Shader了吗？ 同上 我们图标现在是制作成图集后再使用的，但是当图标数量很多的时候，图集的膨胀就很厉害了。对此我们的做法有两种：1）拆为多个图集；2）不再使用图集转而使用UITexture来使用。请问UWA有什么建议呢？ 使用图集的主要缺点在于内存较大，且管理不便；而使用UITexture的主要缺点在于产生的Draw Call较多（每个UITexture都会产生一个Draw Call且无法拼合），影响运行效率。 一切在于平衡，dc换内存或者内存换dc。 我发现当把UI挪到屏幕外时，Draw Call不会减少，只有设置Enabled去掉才能减少。UI是没有遮罩剔除这类功能吗？ 那是否意味着ScrollRect只能自己做动态加载或者动态设置Enabled之类的优化了？ 因为UGUI合并网格时是以Canvas为单位的，所以只把一部分UI元素移除屏幕并不能降低Draw Call，在Unity 5.2版本以前需要满足两点： 1． 使用Screen Space – Camera 的 Render Mode； 2． 需要将移出的UI元素放在独立的Canvas中，然后整体移出屏幕。 但在Unity 5.2版本之后，上述方法也已经失效。 因此我们建议，在移出后，通过将Canvas的Layer修改为相机Culling Mask中未选中的Layer来去除这部分多余的Draw Call， 但这种方法同样需要将移出的UI元素放在独立的Canvas中。这种方法，相比Enabled的设置，可以减少一定的CPU开销。而对于ScrollRect，如果包含的UI元素较多，确实需要自己做动态加载和动态设置Enabled来进行优化。 UI展示动画时，使用Mask做和使用UI本身做 ，哪个效率会更高些? 一般来说建议尽可能少用Mask组件，该组件的使用对于Draw Call会有较大的影响，也可尝试用 Rect2D Mask来代替。而如果直接通过改变UI元素本身来做动画，当涉及的UI元素数量较大时，容易引起较高的网格重建开销。 工具关于定位游戏中冗余资源引用的问题。UWA的报告中能定位到具体的引用代码么？ 在Profiler只能看到ManagedStaticReferences但是具体不到引用的位置。比如Static ClassA引用一个ClassB，ClassB上引用了一个资源，就定位不出这个引用的过程。请问这种情况下有没有比较好的方法找到引用关系呢？ 该问题在Unity 5.3 之前的版本中都没有方式来进行定位，只能由研发团队根据对代码的推测了进行定位；而在Unity 5.3之后的版本则可以借助Memory Profiler来尝试定位，而Memory Profiler尚未原生集成在Unity Editor中，需要在以下网址进行下载：https://bitbucket.org/Unity-Technologies/memoryprofiler 只是记一下有这么个工具。 粒子粒子系统的Prewarm主要用来做什么的，这个怎么优化呢？ ParticleSystem.Prewarm的出现表示当前加载、激活或者首次渲染的粒子系统开启了”Prewarm”选项，而开启该选项的粒子系统在加载后会立即执行一次完整的模拟。以“火焰”为例，Prewarm开启时，加载后第一帧即能看到“大火”，而不是从“火苗”开始逐渐变大。但Prewarm的操作通常都有一定的耗时，建议在可以不用的情况下，将其关闭。 模型&amp;动画我在Profiler中看到Animator.Initialize这个耗时很大，这个有什么建议么?Animator.Instance 是因为Animator过多造成的吗？ 由图中可知，Animator.Initialize主要是在Instantiate实例化时引起（实际上，GameObject.Active操作也会引起Animator.Initialize），而其具体的耗时原因是相关资源（主要是AnimationClip资源）的加载所致。因此，我们的建议如下： 对GameObject的Instantiate实例化操作进行检测，对于频繁Instantiate的GameObject尝试进行缓存； 对Animator Controller中的AnimationClip资源进行精简，可尝试动态加载和替换Animator Controller中的AnimationClip； 由（1）引申出来，对于已经在缓存池中通过GameObject.Active操作造成的Animator.Initialize开销，建议通过Active/Deactive Animator组件来代替Active/Deactive GameObject，这种操作可以避免Animator.Initialize时内部组织结构创建的开销，进而降低Animator.Initialize时的CPU开销。 性能综合GameObject.Instantiate()每实例化一个GameObject到场景中，会造成卡顿，有什么办法可以优化吗？就算我采用了异步加载，仍然会有稍许的卡顿感。除了缓存池，是否还有别的方法？ 建议研发团队先通过Unity Profiler来确定该性能卡顿的位置。如果只是一个空的GameObject，Instantiate实例化是很快的。一般来说，Instantiate实例化时间较长，主要由以下三个原因： 与资源的加载有关：对于这种情况，研发团度需要精简资源，或者预加载资源来降低实例化的开销； 序列化信息比较多：当GameObject上的Component比较多时，其Instantiate实例化性能会受到影响，比如说粒子系统，这种情况就只能通过分帧实例化，或者通过缓存池来避免； 自定义组件的Awake：在Instantiate实例化时，其GameObject上挂载脚本的Awake函数也会被触发，其中产生的CPU占用，也会被计算在Instantiate实例化内。 预设中的变量，拖拽到Inspector面板和Transform.find这两种方法对加载影响是一样的吗？ 对加载性能有微小的不同。Transform.Find 是可以灵活控制调用时机的，可以真正要用的时候再进行Transform.Find，这样GameObject被实例化时效率会更高一些 。但如果拖上去，GameObject被实例化时，该变量就需要进行序列化。因此，加载和实例化时两者的性能会存在一些微小的变化。 我有一个关于AssetBundle资源加密问题。CreateFromMemory这里不推荐大规模使用，那是不是我们要放弃对一部分资源的加密？还是说有其它的解决办法？ 由于CreateFromMemory的加载速度相较其他的接口而言，耗时明显增大，因此我们确实不建议大规模使用。 就目前而言，除了使用CreateFromMemory，并没有其他高效直接的方法进行资源加密，因此，确实需要放弃对一部分资源的加密。同时，目前存在一些工具可以从更底层的方式来获取和导出渲染相关的资源，如纹理、网格等，因此，对于这部分的资源加密并没有十分的必要性。","link":"/2017/09/25/2017-9-25-每天一点UWA：第八周/"},{"title":"从零开始开发一款AR应用","text":"Vuforia什么是vuforia 我没有自己看过它的概念，但是在使用的过程中它的作用实现图片、模型的识别，识别后就可以显示我们预设好的内容了。 怎么使用 进入Vuforia，右上角注册。 点击Develop进入下图 License Manager：管理你的授权，其实和其它一些SDK一样就是管理一下APP key（就是一串字符串）。在使用vuforia的SDK的时候需要用到。 Target Manager：target就是你扫描的图片或者模型或者其它什么的东西，当你扫描完成后如果匹配上了，就会在手机上显示相关的内容。 生成License 点击add按钮→选择类型（我选的是Development，因为只是用来学习）→输入APP name→点击Confirm 完成上述内容后你会得到下图的内容 点击ddd这个license，会进入下图。这个license key在程序开发中需要用到。 生成Target 选择Target Manager tab 点击add database。其实这里用database是很准确的，因为生成的target就像一个数据库，而我们摄像头扫描到的内容就是数据，通过查询如果在DB中找到了相同的数据就认为是匹配到了。 选择类型（我用的是Device），输入名字，点击Create。结果如下： 点击target（ddd）进入 点击add target。这个里面有多种target类型。我们选择最简单的single image。这个也是市面上很多AR应用使用的，也就是手机扫描一个图片，然后显示一个对应的模型。在这个页面中，file是选择你要上传的图片。width设置和场景中虚拟内容大小一致即可。 输入名字然后点击add，下图是我之前设置好的一些target。 -这里如果点击一个target，会进入下图。注意两个红色框，点击下面那个【Show Features】按钮后图片上会出现黄色区域，这个有点像做了个卷积识别色块的边缘。黄色部分越多说明在摄像头识别时越容易。而Augmentable指数对于了这个数值，也是越高越好。 add target页面有个download database按钮，可以选择要下载什么数据。注意对于target的理解完全可以用数据库的概念套入。你下载了什么数据，在应用中才能对下载数据进行使用和比对。点击download后出现 选unity editor，然后点击download按钮。会得到一个unitypackage文件，然后导入到工程中。 Unity部分的开发导入vuforia sdk 可以在vuforia官网下载unity对应的sdk，也可以通过asset store下载Vuforia AR Starter Kit来直接使用，我两个都试过在设置上是一样的。后者有很多自带的demo很不错。 导入刚才获得的target package。 从asset store上随便下载个免费的模型。 场景设置 创建新场景 找到ARCamera和ImageTarget的prefab拖入场景。 ARCamera设置 点击ARCamera，再点击图中按钮进行设置。 上图中第一个框就是之前申请的APP key 第二个框是它们导入的target，我在这个demo中导入的target的名字就是【target_images】,注意这两个复选框一定要都选。 ImageTarget 设置 红框部分Type需要选择图中的 db选择我们导入的target_images。如果是导入了Vuforia AR Starter Kit会有几个自带的target。 image target选择你要用的图片。在一个场景中可以有多个ImageTarget对象，不同的对象选择不同的图片即可。 上图中的马就是要显示的模型，注意要作为ImageTarget的子对象。马下面的那个白色就是ImageTarget。 对于要显示模型的位置和角度，只要记住手机摄像头面向的方向是白色方块的方向，只要要怎么显示模型就有了参考。我图中的设置是因为我要用摄像头扫描显示器上的图片，所以马是这样放置的。 测试 如果你用的笔记本电脑带摄像头的，可以直接运行测试了。没有的，找个webcam就行了。 有用的事件代码 DefaultTrackableEventHandler类的OnTrackingFound函数是match到了图片后调用的函数，在这个里面可以做一些逻辑功能。 打包apk生成keystore build里面选择Android 在player setting里面的publishing setting中可以生成keystore，方法看最后的附录。 至于jdk和SDK都可以在网上下载到。NDK比较尴尬，unity在Android上的IL2CPP需要r10e，这个版本已经有点难下到了。我最后没用这个。 结束语 到此为止一个最简单的AR应用就做完了，整个过程浪费时间在注册和下载Android SDK。 附录keystore生成The keystore is a signature file that is used to sign your apk. When you create development builds Unity will not sign the apk. You only need one Keystore file for your projects. The file is your signature. To create one do this: In the publishing settings check the “Create New Keystore” box. Click browse and choose a location where you want to store the file. It should be somewhere central since it’s not really related to your project. Set a protection password for the file and confirm it. Select “Create a new key” from the “Key Alias” dropdown. -PS:此处注意，选择了create a new key后最上面会自动勾选use existing keystore，无视即可。在弹出的窗口里面输入相关内容。 A window should open which you have to fill with your personal data about your organisation / person. The alias at the top is just a name of the keystore. If you have multiple identities make sure you choose a meaningful name. You need to set a keystore password. Note this is not the same as the protection password above. As far as i know they can be the same, but for security you should use two different. If you haven’t write the passwords onto a sheet of paper ;) Click “Create Key” to generate your keystore file. To use a keystore for signing you have to: Check the “Use Existing Keystore” box. Click browse and select your keystore file. enter your protection key. select your desired identity from the alias dropdown. enter the alias password in the field below Make sure you have set your Android Market Licensing RSA Public Key at the bottom of the publishing settings. The public key has to be acquired from your Google market account. Now create your APK file and it will be signed with your identity. Note: You can create multiple Keys / Identities in one Keystore file. The first protection password will protect the file itself. When you select an identity from the file in the alias dropdown you have to type in the password for the identity.","link":"/2017/09/09/2017-9-9-从零开始开发一款AR应用/"},{"title":"七周七并发模式：Lambda架构","text":"Lambda架构定义 Lambda架构使用了可以进行大规模数据批处理的MapReduce技术，也使用了可以快速处理数据并及时反馈的流处理技术，这样的混搭能够为大数据问题提供扩展性、响应性和容错性都很优秀的解决方案。 Lambda架构是站在大规模场景的角度来解决问题的，它可以将数据和计算分布到几十台或几百台机器构成的集群上进行。这种技术不但解决了之前因为规模庞大而无法解决的难题，还可以构建出对硬件错误和人为错误进行容错的系统。 Lambda架构源自于它与函数式编程的相似性。从本质上说，Lambda架构是将计算函数施加于大量数据的一种通用方法。 不变原始数据是Lambda架构的基础。对于不变的数据进行处理的时候，不在需要锁机制和事物机制。多个线程可以并行地访问数据，而不用担心相互之间的作用。我们可以对数据进行复制，再对副本进行操作，而不用担心数据过期，所以在集群中分布地处理数据就变得非常容易。 传统数据系统的缺陷 扩展性：利用某些技术（比如复制、分片等）可以将传统数据库扩展到多台计算机上，但随着计算机数量和查询数量的增加，应用这种方案会变得越来越困难。超过一定程度，增加计算机资源将无法继续改善性能。 维护成本：维护一个跨多台计算机的数据库的成本是比较高的。如果要求维护时不能停机，那么维护将变得更加困难——比如对数据库进行重新分片。随着数据量和查询数量的增加，容错、备份、确保数据一致性等工作的难度都会呈几何级数增长。 复杂度：复制和分片通常要求应用层面提供一些支持——应用需要知道将查询发给哪一台计算机，以及应该更新哪一个数据分片（每个更新所对应的分片通常不一样，规则也比较复杂）。 人为错误 报表和分析：在独立的数据仓库中用另一种格式来维护历史数据。数据从业务数据库向数据仓库的迁移过程就是著名的萃取（extract）、转置（transform）、加载（load）（简称ETL）。这种方案不仅复杂，而且需要准确预测将来我们需要什么信息。有时会碰到这种情况：由于缺乏必要的信息或者信息格式不对，无法生成所需报表或进行某些分析。 批处理视图（批处理层） &amp; 服务层 如果能够准确预测出未来会对原始数据进行怎样的查询，就可以预计算出一个批处理视图，这个视图包含这些查询将要返回的衍生信息，或者那些可以计算出这些衍生信息的数据。Lambda架构的批处理层就是用来计算这些批处理视图的。 批处理视图可以包含衍生信息，比如：假设要用一系列编辑记录来构建Wikipedia的页面——批处理视图将只包含从页面的编辑记录中计算得来的页面内容。 批处理视图也可以包含可以计算出衍生信息的数据，这类情况会稍微复杂一些。 需要对生成的批处理视图进行索引，这样就可以对索引进行查询了。另外，还需要一个地方来存放程序逻辑（说明一个查询该如何合并批处理视图的逻辑）。这就是服务层的任务。 总结来说利用不变数据利于并行的特显对海量数据进行加工（mapper + reducer），生成批处理视图。然后再通过简单的查询得到想要的结果。 后面提到的Hadoop就是应用于批处理层 加速层 有新数据产生时，除了会将数据投入到原始数据还会进行扔给加速层生成实时视图，结合最新的批处理视图可以满足对于新数据的查询。 当新的批处理视图产生后，实时视图就被丢弃了。 这个东西的目的应该是为了快速响应新数据，在批处理层还没有出新版本时，临时使用实时视图+当前最新的批处理视图就组成了未来会出现的批处理视图。 后面讲的Storm系统应用于加速层 最后放一张架构图 MapReduce定义 MapReduce是一个多义的术语。其可以指代一类算法，这类算法分为两个步骤：对一个数据结构首先进行映射（map）操作，然后进行化简（reduce）操作。之前的词频统计的函数式版本正是这样的例子（frequencies就是用reduce函数实现的）。 MapReduce还可以指代一类系统——这类系统使用了上面的算法，将计算过程高效地分布到一个集群上。这类系统不仅可以将数据和数据处理分布到集群的多台计算机上，还可以在一台或多台计算机崩溃时继续正常运转。 一个MapReduce任务由两种主要的组件构成：mapper和reducer。mapper负责将某种输入格式（通常是文本）映射为许多键值对。reducer负责将这些键值对转换成最终的输出格式（通常也是一系列键值对）。mapper和reducer可以分布在很多不同的计算机上（它们的数目不必相同）。 Hadoop 一个包含了MapReduce的 输入通常由一个或多个大文本文件构成。Hadoop对这些文件进行分片（每一片的大小是可配置的，通常为64 MB），并将每个分片发送给一个mapper。mapper将输出一系列键值对，Hadoop再将这些键值对发送给reducer。 一个mapper产生的键值对可以发送给多个reducer。键值对的键决定了哪个reducer会接受这个键值对——Hadoop确保具有相同键的键值对（无论是由哪个mapper产生的）都会发送给同一个reducer处理。这个阶段通常被称为洗牌阶段（shuffle phase）。 Hadoop为每个键调用一次reducer，并传入所有与该键对应的值。reducer将这些值合并，再生成最终输出结果（通常是键值对，也可以不是）。 mapper &amp; reducer 书中demo的Map继承了Hadoop的Mapper类，其接受四个类型参数：输入的键类型、输入的值类型、输出的键类型、输出的值类型。它里面的方法本质是将一行文本进行拆分，输出一个键值对。 对于每个键，都会调用一次reduce()方法，values是这个键对应的所有值的集合。reduce()方法对这些值进行求和，并产生描述某个单词出现总数的键值对。 Hadoop在键值对传给reducer前会对键进行排序 Driver 从下面的代码看driver就是配置Hadoop。 这里不需要设置输入的键类型和值类型，因为默认情况下Hadoop认为我们处理的是文本文件。也不需要分别设置mapper输出的键/值类型和reducer输入的键/值类型，因为默认情况下Hadoop认为mapper的输出和reducer的输入具有相同的键/值类型。 使用setInputFormatClass()将XmlInputFormat设置为分片器，并且配置xmlinput.start和xmlinput.end来告诉分片器我们关注的是哪个标签。 setCombinerClass()来设置combiner。combiner是一种优化手段，使键值对可以在发往reducer前进行合并。 1234567891011121314151617181920212223public class WordCount extends Configured implements Tool { public int run(String[] args) throws Exception { Configuration conf = getConf(); conf.set(&quot;xmlinput.start&quot;, &quot;&lt;text&quot;); conf.set(&quot;xmlinput.end&quot;, &quot;&lt;/text&gt;&quot;); Job job = Job.getInstance(conf, &quot;wordcount&quot;); job.setJarByClass(WordCount.class); job.setInputFormatClass(XmlInputFormat.class); job.setMapperClass(Map.class); job.setCombinerClass(Reduce.class); job.setReducerClass(Reduce.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); FileInputFormat.addInputPath(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); boolean success = job.waitForCompletion(true); return success ? 0 : 1; 15 } public static void main(String[] args) throws Exception { int res = ToolRunner.run(new Configuration(), new WordCount(), args); System.exit(res); } } Hadoop的优势 可以在多台计算机上更快地处理海量的数据 Hadoop天生就具有处理错误和从错误中恢复的能力，这点很好保证了在使用集群时的稳定性。 与上一条相关，不仅要考虑将节点崩溃时正在处理的任务重新执行，还需要考虑当存储发生故障时如何保证数据不丢失。Hadoop默认使用Hadoop分布式文件系统（HDFS），这个有容错能力的分布式文件系统可以在多个节点之间冗余数据。 涉及吉字节级别以上的数据时，就不能将所有中间数据或结果全部存放在内存中。Hadoop在处理过程中将键值对存储在HDFS中，这样就可以不受内存限制，完成数据量非常大的任务。 StormSpout、Bolt和Topology Storm系统处理的是元组（tuple）的流。Storm的元组类似于之前我们在第5章看到的actor模型的元组，但不同于Elixir的元组，Storm元组的元素是有名字的。 元组由spout（出水管）组件创建，并由bolt（螺栓）组件进行处理，bolt也会输出元组。用流将spout和bolt连接在一起，就形成了topology（拓扑结构）。 topology也可以很复杂——bolt可以消费多个流，而一个流也可以被多个bolt消费，构成一个有向无环图。spout和bolt都是并行化和分布式的。 worker：spout和bolt不仅相互之间是并行的，而且其内部也都是并行的——每一个个体内部都是由很多worker实现的。 下图是一个topology 容错 将一个spout或bolt的多个worker分布在多台计算机上的主要原因是容错性。如果集群中的某一台计算机发生故障，topology可以将元组分发给仍存活的计算机，这样topology就可以继续运行。 Storm会监视元组之间的依赖——如果某一个元组没能完成，Storm会将其依赖的spout元组置为失败并进行重试。这也就是说Storm默认使用的是“至少会执行一次”的处理策略。应用必须知道这个事实：元组可能会被重试，直到其结果正确。 总结 Lambda目前主要作为大数据平台的架构 如果用Hadoop作为Batch Layer，而用Storm作为Speed Layer，那就需要维护两份使用不同技术的代码。所以目前有另外的一个解决方案是Apache Spark，它可以作为Lambda Architecture一体化的解决方案。 引用 与 Hadoop 对比，如何看待 Spark 技术？","link":"/2018/04/20/2018-4-20-七周七并发模式：Lambda架构/"},{"title":"游戏设计模式读书笔记：游戏循环","text":"游戏循环 游戏循环是一个游戏系统中最为关键的环节，可以说只要开发游戏就会用到这个模式，只不过它很多时候已经被集成到了引擎当中。在使用Unity引擎的过程中，可以体会到一个游戏中所有的表现都依赖于循环。 不同于传统软件循环中只等待输入的情况，一个游戏循环在游玩中不断运行。每一次循环，它无阻塞地处理玩家输入，更新游戏状态，渲染游戏。它追踪时间的消耗并控制游戏的速度。 有时候在某个平台开发游戏循环时，需要使用平台特有的事件循环。 帧率（FPS） 如果我们用实际时间来测算游戏循环运行的速度，就得到了游戏的“帧率”(FPS)。 如果游戏循环的更快，FPS就更高，游戏运行得更流畅、更快。 如果循环得过慢，游戏看上去就像是慢动作电影。 两个因素决定了帧率: 一个是每帧要做多少工作。复杂的物理，众多游戏对象，图形细节都让CPU和GPU繁忙，这决定了需要多久能完成一帧。 另一个是底层平台的速度。 更快的芯片可以在同样的时间里执行更多的代码。 多核，GPU组，独立声卡，以及系统的调度都影响了在一次滴答中能够做多少东西。 当前的游戏开发中，游戏循环的一个重要任务就是不管潜在的硬件条件，以固定速度运行游戏。 循环的演化跑，能跑多快跑多快 下面这个可以说是最简单的循环，它完全不控制帧率，可能在性能好的设备上运行的非常快，在不好的设备上运行缓慢。 123456while (true){ processInput(); update(); render();} 休息一下 假设你想要你的游戏以60FPS运行。这样每帧大约16毫秒。 只要你用少于这个的时长进行游戏所有的处理和渲染，就可以以稳定的帧率运行。 你需要做的就是处理这一帧然后等待，直到处理下一帧的时候，就像这样： 123456789while (true){ double start = getCurrentTime(); processInput(); update(); render(); sleep(start + MS_PER_FRAME - getCurrentTime());} 但是如果每帧超过了16ms，那么仍旧无法保障帧率。 一小步，一大步 游戏循环中需要实现变化的时间间隔。如果说我们在每次更新中将游戏时间推动一个固定量，那么当每帧的真实执行时间超过这个固定量时，会导致游戏时间慢与实际时间。 因此一般都会将上一帧的真实执行时间作为参考来决定这一帧游戏时间的推动量。 12345678910double lastTime = getCurrentTime();while (true){ double current = getCurrentTime(); double elapsed = current - lastTime; processInput(); update(elapsed); render(); lastTime = current;} 每一帧，我们计算上次游戏更新到现在有多少真实时间过去了（即变量elapsed）。 当我们更新游戏状态时将其传入。 然后游戏引擎让游戏世界推进一定的时间量。 这样处理的问题：不同性能的设备会导致帧率不同，从而计算浮点型数据的结果在一秒内会有偏差。对于联机游戏来说就是问题了。现在很多的联机游戏已经是在服务器计算位置等数据了，避免了不同设备性能差异造成的错误。 追逐时间 其本质是在固定时间间隔更新游戏。但是这个更新的内容却并非是游戏的全部内容，而是与物理、AI等相关的部分。用过unity的同学应该已经感觉有点熟悉了，这个在unity中就是FixedUpdate。 对于render，因为它只是将某一个时间点的内容显示出来，因此并不受动态时间间隔的影响，只要保证每一帧都做一次就好。 12345678910111213141516171819double previous = getCurrentTime();double lag = 0.0;while (true){ double current = getCurrentTime(); double elapsed = current - previous; previous = current; lag += elapsed; processInput(); while (lag &gt;= MS_PER_UPDATE) { update(); lag -= MS_PER_UPDATE; } render();} 上面的代码某种程度是也是unity内部的实现。而里面的update函数可以换做FixedUpdate，这也是为何在输出log的情况下，可能会发现一个Update中会穿插多个FixedUpdate。因为unity中默认是FixedUpdate是一秒执行50次，即0.02秒一次，但是如果说一帧的真实时间超过了0.02s，那么为了追赶时间一帧中会执行多次FixedUpdate。 卡在中间 其实上面一步已经算是比较完善的循环过程，在固定的时间更新游戏，而在任意一个时刻渲染。但是这样也意味着某次渲染可能是在两次更新之间。如下图所示，在第三次渲染时刚好渲染的时间点处于更新的中间。 这个会造成什么问题呢？如果说是一颗子弹在运行，玩家在渲染的一瞬间期望看到的是子弹处于两个更新点之间的位置，但是因为下一个Update没有执行，所以真正看到的是子弹在左边的位置。也就是说期望与现实不符。其实人眼很可能根本看不到这么细微的差别，但是这个问题确实是存在的。 为了解决这个问题我们可以采用这样的一个方式render(lag / MS_PER_UPDATE);， 在上面的代码中可以看出，lag经过计算后在render调用前的值为到下一帧的值。因此在渲染时考虑这个时间可以平滑的预计算物体的位置。但是这个位置并不一定是正确的，因为也许物体会碰撞发生位置的变化，但是这个必须要等下一帧中的update里面确认。 PS：我并不确定这个操作是否有实际的意义。 设计决策拥有游戏循环的是你，还是平台？ 在使用循环的时候我们可能会遇到这样三种情况： 处于某个特定的平台，而这个平台有自己的循环，比如web browser上开发游戏就会受到浏览器本身的事件驱动机制阻碍。 已经在使用某个游戏引擎了，比如说unity引擎，它就已经具备了内置的循环并且通过Update函数开放。 编写自己的循环 以上三种情况各有利弊： 平台循环可以让你不必编写和优化自己的核心循环，但是你失去了对于时间的控制。 游戏引擎循环与平台的情况基本一致。而且目前我们大多数开发都在使用商业引擎。 自己编写当然最大的好处是完全可以自己控制，但是如果你在某个平台或者引擎上开发就需要考虑如何与其它循环协作的问题。 如何管理能量消耗？ 随着移动游戏时代的到来，越快越好的策略被舍弃，因为必须考虑手机设备的电量使用和CPU过度使用而造成的发热问题。 移动游戏更加注意游戏的体验质量，而不是最大化图像画质。 很多这种游戏都会设置最大帧率（通常是30或60FPS）。 如果游戏循环在分配的时间片消耗完之前完成，剩余的时间它会休眠。这给了玩家“足够好的”游戏体验，也让电池轻松了一点。 你如何控制游戏速度？ 固定时间步长，没有同步：也就是最开始的那套循环，完全依赖于硬件设备的性能。这个最大的弊端是影响游戏速度。 固定时间步长，有同步：它的前提是游戏运行帧率很高，所以加了限制。这样可以节约电量，但是如果一旦帧率不够高其实也会造成游戏时间比现实时间慢的问题。 动态时间步长：能适应并调整，避免运行得太快或者太慢。 如果游戏不能追上真实时间，它用越来越长的时间步长更新，直到追上。但是它也让游戏不确定而且不稳定。这是真正的问题，当然。在物理和网络部分使用动态时间步长会遇见更多的困难。 固定更新时间步长，动态渲染：能适应并调整，避免运行得太快或者太慢。 只要能实时更新，游戏状态就不会落后于真实时间。如果玩家用高端的机器，它会回以更平滑的游戏体验。但是它更复杂。主要负面问题是需要在实现中写更多东西。 你需要将更新的时间步长调整得尽可能小来适应高端机，同时不至于在低端机上太慢。 参考 Unity中的循环 Game Loop Fix Your Timestep!","link":"/2018/05/06/2018-5-6-游戏设计模式读书笔记：游戏循环/"},{"title":"计算机组成原理：2、基本组成","text":"冯·诺依曼计算机基本概念 本文中的内存结构只是课程中用到的一个特定的机器的设计，并非所有的计算机都是这样的。 现在的计算机都是程序存储计算机，也就是冯诺依曼计算机。 特点： 计算机有五大部件组成：输入、输出、控制器（CU）、运算器(ALU)、存储器(主存、辅存) 指令和数据以同等地位存于存储器中，按地址寻访。 指令和数据按照二进制保存 指令由操作码和地址码组成（e.g 0001 00001000，0001代表读取，00001000代表要读取 数据在内存（寄存器）中的位置）。 存储程序，存储在存储器中。 以运算器为中心。 现代计算机： ALU + CU = CPU CPU + 主存（RAM\\ROM\\Cache（inter上cache有L1\\L2\\L3）） = 主机 输入 + 输出 + 辅存 = IO设备 主机 + IO = 计算机系统硬件 CU控制数据的读取+写入，操作的是存储器，还可以控制指令的执行顺序操作的是运算器。 如果以运算器为中心进行硬件设计会是的运算器成为系统的瓶颈（overhead）。所以改进成以存储器为中心，这样可以是的IO设备直接和存储器关联。 计算机解决问题的步骤： 建立数学模型 确定计算方法 编制程序：程序就是运算的全部步骤，指令就是每一个步骤。 计算机主要组成存储器 存储器的组成由以下： 存储体: 大楼-&gt;若干房间-&gt;如果床位 存储单元：房间 存储原件：床位，本质就是0/1了 存储单元：存放一串二进制代码 存储字：存储单元中二进制代码的组合 存储字长：存储单元中二进制代码的位数 每一个存储单元都有一个地址，通过地址进行访问。存储单元保存的可以是数据，也可以是指令。 MAR：存储器地址寄存器，保存存储单元地址或编号。反应存储单元个数。 MDR：存储器数据寄存器，要保持到存储体的数据，或者刚刚从存储体取出的数据。反应了存储字长。 硬件结构 运算器 在我理解中运算器是真正进行数据计算的地方，都是采用二级制的加减乘除。具体实现应该是数字电路方面的知识了。 对于不同的运算，在指令执行过程中使用到的寄存器数量不同。比如加减法是不需要MQ（乘商寄存器，multiplication &amp; quotient的缩写）的。 ALU：运算器核心 ACC：累加寄存器 X：保存数据的寄存器 MQ：乘商寄存器 控制器 功能： 解释指令 保证指令的按序执行 解释指令过程，也是一个指令的执行过程： 取指令：从内存单元中取指令。→ PC 分析指令：把操作码部分送到控制单元进行分析 → IR 执行指令：控制单元控制相应的执行部件来执行操作 → CU 硬件结构 PC：程序计数器：寄存器，存放当中要执行的指令的地址，具有计数功能（PC）+ 1-&gt; PC，（类似指针操作） IR：指令寄存器，存放当前要执行的指令。控制单元从IR中取出操作码进行分析。 CU：发出控制信号 所以控制器的执行顺序是：CU（不确定，因为没有讲清楚）从PC取当前要执行指令的地址，根据地址找到指令后存到IR，CU分析指令后得到操作码，然后执行。PC++后就是到了下一条指令的地址，然后继续之前的操作。 存储器、运算器和控制器是如何协作的取数例子 PC中保存着指令的地址，将地址放入MAR。 用MAR中的地址从存储体中得到指令（操作码+操作数据地址码） 将得到的指令放到MDR 将指令从MDR放到IR ——————–取指令结束——————– IR将操作码送到CU，CU译码，开始操作元器件。 IR中地址码送到MAR，这个地址码就是我们真正要操作的数据。 MAR从存储体取到数据 数据保存到MDR MDR讲输入送到ACC ——————–整个操作结束—————— NOTE: 在这个图中没有体现的是如何将最初的取值指令地址放到PC中 存数例子 PC中保存着指令的地址，将地址放入MAR。 用MAR中的地址从存储体中得到指令（操作码+操作数据地址码） 将得到的指令放到MDR 将指令从MDR放到IR ——————–取指令结束——————– IR将操作码送到CU，CU译码，开始操作元器件。 IR中地址码送到MAR，这个地址码就是我们真正要操作的数据。 MAR将地址告诉存储体，这个数据要存起来 ACC中的数据保存到MDR MDR将数据放到存储体 ——————–整个操作结束—————— 计算机执行程序的过程 这里就回答了之前的问题，在程序被输入到计算机的内存后，第一个指令的地址会被放入到PC中。在指令执行的过程中，PC+1操作使得能够不断的执行新的指令。 延展阅读主存、副存、内存、外存 存储器是计算机的重要组成部分，用于存储程序与数据，可分为：计算机内部的存储器（内存储器，简称内存）、计算机外部的存储器（外存储器，简称外存） 一般来说，主存指的是内存；但是在一些专业性较强的场合，主存与内存还是有一定区别的。内存储存器还有其他形式。而外存指的是辅存，比如硬盘、U盘、光盘及软盘等。 cpu中的存储器和主存是两个概念。处理器需要自己的内存储器，它们以寄存器的形式存在。 内存： 内存又称主存，是CPU能直接寻址的存储空间，它的特点是存取速率快。内存是电脑中主要部件，它是相对于外存来说。 内存一般采用半导体存储单元，包括随机存储器（RAM）、只读存储器（ROM）和高级缓存（Cache）。 RAM（Random Access Memory）： 高速存取，支持读写数据，读写时间相等，且与地址无关，但是断电后其中的数据会丢失。 ROM（Read Only Memory）： 断电后信息不丢失，如计算机启动用的BIOS芯片。存取速度很低，（较RAM而言）且不能改写。由于不能改写信息，不能升级，现已很少使用。 Cache： 介于CPU与内存之间，常用有一级缓存（L1）、二级缓存（L2）、三级缓存（L3）（一般存在于Intel系列）。它的读写速度比内存还快，当CPU在内存中读取或写入数据时，数据会被保存在高级缓冲存储器中，当下次访问该数据时，CPU直接读取高级缓冲存储器，而不是更慢的内存。 外存： 外储存器是指除计算机内存及CPU缓存以外的储存器，此类储存器一般断电后仍然能保存数据。外存需要通过I/O系统与之交换数据，又称为辅助存储器。常见的外储存器有硬盘、软盘、光盘、U盘等 参考 https://blog.csdn.net/lewky_liu/article/details/78147842","link":"/2018/09/19/2018-9-19-计算机组成原理：2、基本组成/"},{"title":"计算机组成原理：3、总线","text":"概要 总线（bus）：是连接各个部件的信息传输线，是各个部件共享的传输介质。 一条总线是总是主模块向从模块发出地址和命令，但是在分离式通信时是没有从模块的。 总线解决的是什么问题？ 计算机的不同模块需要用线连接起来，如果采用分散连接（两两连接）那么需要的线路太多，都设计在电路板上难度太大，而且设备的连接接口太多。 分散连接还存在一个扩展困难的问题，如果新加一个接口就要将这个接口与已存在的接口相连。 计算机总线使用有限的线路数量将所有的部件连接起来，解决了上面两个问题。 劣势是什么 因为总线是共享的，在一个时刻只能有一对（两个）部件进行数据的传输，因此会成为系统的瓶颈。e.g IO与主存在数据传输时，CPU与主存就无法传输了。因此在传输周期上设计了分离式的传输方式，用于解决总线被占用期间出现无效的等待。 总线并行传输在线路比较长时会出现信号干扰，所以一般并行都是在PC机箱内。 多总线 为了解决同一时刻只能一对部件使用总线的问题，引入了多路的总线。 其中一种是：以主存作为中心，一条存储总线，一条系统总线。 总线分类 芯片内总线：芯片内部 系统总线：计算机各部件之间的信息传输线。根据传输信号类型的不同分为： 数据总线： 双向； 宽度通常小于等于机器字长、存储字长。 e.g 64位计算器，数字总线可以是8位，要进行一次64位计算，需要传输64位的数据，那么就需要传输8次。 地址总线： 通过地址才能找到存储单元和设备。 通常单向：CPU到IO和主存； 与存储地址、IO地址有关。 地址总线的条数与地址单元个数相关。在本书中地址总线宽度和MAR寄存器宽度一样。 控制总线： 向系统各个部件传递控制信号； 或者各个部件向外传递状态信号。 e.g : 存储器的读写、总线使用的许可、中断确认。 通信总线： 计算机之间或者与其它设备的连接。 串行 并行 总线的特效 机械特性：尺寸、形状、管脚数、排列顺序 电器特性：传输方向（上面的单双向），有效电平范围 功能特性：地址、数据、控制 时间特性：信号的时序关系 性能指标 总线宽度：数据线的根数 标准传输率：每秒传输的最大字节数 MBps 时钟同步/异步：同步、不同步 总线复用：地址线与数据线的复用，这个复用其实是共享使用。这样设计是为了减少CPU管脚数。e.g 8086CPU，20个地址线中16跟还作为数据线使用。 信号线数：地址线、数据线、控制箱总和 总线控制方式：突发、自动、仲裁、逻辑、计算 其他指标：负载 总线结构 总结结构有很多，不同的硬件的设计也不同，但是总结来看有几个原则: CPU与主存之间总是有一条专门的总线，或者CPU与cache与主存之间。 高速设备与低俗设备使用不同的总线。 四总线结构 总线占有控制 前面说了总线在同一时刻只能由一对部件来使用，那么当多个部件同时请求使用时是如何来控制的呢？这个就是总线判优的问题了。 总线判优有两种主要方式集中式和分布式。集中式只指优先度是总线控制部件来决定的，它分为三种方式： 链式查询方式 计数器定时查询 独立请求方式 链式查询方式 链式查询实际上是从接口0开始逐个的去询问是谁申请了总线的使用。如果1和N都申请了，但是因为先询问的1所以1就会占有总线。 优先级由接口的顺序来决定，比较死板。 弊端是如果BG上有线路的损坏后续就询问就无法继续了。 计数器定时查询 总线控制器中有个计数器 多了一条设备地址，这条线是用来将计数器的值向外输出的。 当有多个IO接口申请总线时走的还是BR，总线控制器收到申请后如果判断可以交出总线的权限就会将当前的计数器的值通过设备地址线传递出去。 e.g 一开始计数器的值是0，当1和N申请总线时，就会对IO接口0进行查询是否申请了。如果IO接口0没有申请，那么计数器+1，然后开始对接口1进行查询。 这种方式的优势：因为计数器是可以设置的，所以优先级是可以设定的。 设备地址线宽度与设备数量相关 独立请求方式 这个方式在效率上是最高的，因为每个部件都有自己的BR，因此总线控制器在同意后可以很明确的用BG来返回。 缺点是线路太多 总线通信 总线在一段时间内被一对主从设备占用，总线通信的目的是为了解决通信双方协调配合问题。 总线传输周期 申请分配阶段：主模块申请，总线仲裁决定 寻址阶段：主模块通过地址找到从模块，并给出命令。 传数阶段：主模块和从模块数据交换。 结束阶段：主、从模块撤销相关信息。 总线通信的方式同步通信： 由统一定宽定距的时标控制数据传输，主从模块强制同步，在同一个时限内完成规定的操作。 对于速度不同的模块要选择速度最慢的模块作为统一的时标，对于高速模块来说没有发挥它的作用。 同步通信的使用场景是总线比较短，并且各个模块存取时间比较一致的情况。 下面举例说明一下同步式的数据读取（输入） T1时钟上升沿主设备CPU要给出地址信号 T2时钟上升沿要给出读命令信号，告诉从设备CPU要读取数据 T3时钟上升沿之前从设备要给出数据信号 T4时钟上升沿之前数据信号和读信号（控制信号） 撤销 T4结束地址信号撤销 NOTE：上图中每一行的空白区域是对应的信号的存在时间 异步通信： 采用应答方式，没有公共时钟标准。 在通信控制过程中分为不互锁、半互锁和全互锁。 按照下图所展示的进行说明： 不互锁：指的是主设备发出请求信号后从设备发应答信号，然后主设备和从设备依次退出信号。过程中主设备不管是否接收到了应答信号，经过一定延迟后都会撤销请求信号，而从设备也不管主设备是否接受到了应答信号，经过一段时间后就撤销信号。 半互锁：主设备发出请求信号，从设备发应答信号。区别在于主设备的请求信号只有在收到应答信号后才撤销，而从设备仍旧经过一段时间后就撤销了信号。造成的问题就是可能从设备一直不回复，那么主设备就一直等待。 全互锁：本质和TCP三次握手一样。主设备发请求、从设备应答，主设备只有收到应答后才撤销，而从设备只有请求信号撤销后才撤销应答信号。在传输期间发生错误的话，主设备可以要求从设备重新发送或者接受数据。 半同步通信： 同步异步结合，解决两个不同速度的设备交换数据。 同步方面：发送方用系统时钟前沿发信号，接收方用系统时钟后沿判断、识别。 异步方面：运行不同速度的模块和谐工作，增加一条“等待”响应信号”WAIT”，信号线。 从上图可以看出前面在T1和T2都和同步通信是一致的，但是在T3前，如果从设备没有能够准备好数据的传输那么久会发出TW信号。主设备检查到TW存在时就会等待一个时钟周期，然后每过一个时钟周期就检查一下TW是否在低位。知道从设备准备好数据传输了，然后TW变成高电位。然后就继续T3、T4。 前三种小总结 主模块发地址、命令→占用总线 从模块准备数据→不占用总线，总线空闲 从模块想主模块发数据→占用总线 在准备数据时是有总线浪费的，所以有了分离式的通信。 分离式通信： 充分挖掘系统总线每个瞬间的潜力。 本质上分离式通信是讲一个原来的总线传输周期分割成多个子周期 子周期1：主模块申请占用总线，使用完后放弃总线控制权 子周期2：从模块申请占用总线，讲各种信息送到总线上 特点： 各模块都有权申请占用总线，所以都是主模块。 采用同步方式通信，不等对方回答。 各模块准备数据时不占用总线 总线被占用时无空闲（这不是废话么） 延伸阅读总线频率 1.主频：主频也叫时钟频率，单位是MHz，用来表示CPU的运算速度。主频由外频和倍频决定，其计算公式为 主频＝外频 * 倍频。外频就是系统总线的工作频率；而倍频则是指CPU外频与主频相差的倍数。如Intel Pentium4 3.06GHz处理器的外频为133，倍频23，则主频＝133*23＝3.06Ghz 2.外频：外频是CPU的基准频率，单位也是MHz。外频是CPU与主板之间同步运行的速度，而且目前的绝大部分电脑系统中，外频也是内存与主板之间的同步运行的速度，在这种方式下，可以理解为CPU的外频直接与内存相连通，实现两者间的同步运行状态。 3.前端总线：前端总线频率直接影响CPU与内存直接数据的交换速度。由于数据传输最大带宽取决于所有同时传输的数据的宽度和传输频率，即数据传输量＝（总线频率数据带宽）/8。外频与前端总线频率的区别：前端总线的速度指的是数据传输的速度，外频是CPU与主板之间同步运行的速度。比如说，100MHz外频特指数字脉冲信号在每秒钟震荡一千万次：而100MHz前端总线指的是每秒钟CPU可接受的数据传输量是100MHz64bit/（8Byte/bit）＝800MB/s。 4.倍频系数：倍频系数是指CPU主频与外频之间的相对比例关系。在相同的外频下，倍频越高CPU的频率也越高。但实际上，在相同外频的前提下，倍频高的CPU本身意义并不大。这是因为CPU与系统之间数据传输速度是有限的，一味追求高倍频而得到高主频的CPU就会出现明显的“瓶颈”效应——CPU从系统得到数据的极限速度不能满足CPU运算的速度。 5.内存总线速度：CPU处理的数据来自存储器，而主存储器就是内存。一般放在外存（磁盘或者各种存储介质）上面的数据都要通过内存，再进入CPU进行处理。所以CPU与内存之间的通道的内存总线速度对整个系统性能就显得很重要。由于内存和CPU之间的运行速度或多或少会有差异，因此便出现了二级缓存，来协调两者之间的差异，而内存总线速度就是指CPU与二级高速缓存和内存之间的通信速度。 6.扩展总线速度：扩展总线指的是安装在计算机系统上的局部总线如VESA或PCI总线，我们打开电脑的时候会看见一些插槽般的东西，这些就是扩展槽，而扩展总线就是CPU联系这些外部设备的桥梁。 时钟周期 时钟周期也称为振荡周期，定义为时钟频率的倒数。时钟周期是计算机中最基本的、最小的时间单位。在一个时钟周期内，CPU仅完成一个最基本的动作。时钟周期是一个时间的量。时钟周期表示了SDRAM所能运行的最高频率。更小的时钟周期就意味着更高的工作频率。 参考 https://blog.csdn.net/commandow/article/details/5844617 https://baike.baidu.com/item/%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F","link":"/2018/09/20/2018-9-20-计算机组成原理：3、总线/"},{"title":"计算机组成原理：5、主存储器","text":"一、概述1、基本构成 结合上图总结一下之前的数据读取的操作 CPU在第一个时钟周期时通过地址总线发出要取数据的地址，这个地址是指的存储单元的地址。 MAR收到后，经过译码器得到指定的存储单元。 CPU在第二个时钟周期时通过控制总线讲读指令发送到主存储器 控制电路根据信令来操作读写电路 将之前得到主存储器地址中的数据写入MDR 通过数据总线讲MDR中的数据送入到IR或者ACC 2、主存与CPU之间的联系 CPU和主存之间主要是三个总线：地址、数据、命令 数据总线是双向的，而地址是单向 3、主存中存储单元地址的分配 数据在存储器中存储主要有两个方式，大端和小端。 图中高位字节指的是0x12345678中的12，其中从左到右为从高高低 但是在存储器中，地址小的为低位 所以大端中就是高位的12存在了低位，小端就是低位的78存在了低位。 关于按字节寻址和按字寻址详见延展阅读， 二、半导体存储芯片1、基本结构 芯片容量计算：2^(地址线数量) * 数据线带宽，e.g 地址线10跟，数据线 4bit，那么容量就是 2^10 * 4 = 1k * 4bit 片选线： 片选线的作用是来标记一次数据存储过程中，数据是否存在于一个存储芯片中。 两周标识方式:CS\\CE，上面的线表示低电平。也就是说如果管脚是低电平就说明这次要访问的是这个芯片。 比如内存条上有很多存储芯片，那么一次可能用到的数据在一个或者多个芯片上。 读写控制线：可以使用一根或者两个线来表示 2、片选线的作用 上图展示了一个使用片选线的demo 每个芯片16K x 1bit，当计算机需要64K x 8bit时需要32个芯片来实现。 8个芯片串行，用之前大楼的概念来看，就是整个楼有2^16个房间，每个房间8个床位，但是注意这8个床位其实是跨房间的（或者说是跨楼的）。如果要住8个人（8bit数据），那么并不是全住在第一个房间，而是住在8个楼（一组串行芯片）的编号相同房间中编号相同的床位上（图中每个房间其实只有一个床位）。 3、译码驱动 地址总线传到存储器的地址需要进行译码，然后才能得到在存储器对应的地址。 线选法 线选法图中有4根地址线，因此存储单元有 2^4 = 16个，对应字线0-15。 根据4根线上的数据得到具体的字线后，字线上的数据读写到MDR。 弊端是如果想要一个1M*8大小的存储器，那么地址线需要20条，而字线需要1M条，对于芯片来说很难。 重合法 相当于笛卡尔坐标系 10条地址线可以表达出 32 * 32个位置，每个位置是1bit 与线选法比较，1M*8的空间 = 2^20 * 2^3 = 2^23bit , 用重合法可以做 2^12 * 2^11 这样一个矩阵，也就是 4k + 2k = 6k条字线。 最初看到这里的时候有个疑惑，就是根据重合法每次只能拿到一个bit，但是看到后面的Intel 2114 RAM矩阵后就知道了如何使用重合法一次获得多个bit。 三、随机存取机器（RAM）→ 内存1、静态RAM(SRAM)保存0和1的原理 双稳态触发器 基本单元电路如何构成 静态RAM芯片如何读写 Intel 2114 RAM 矩阵 上图很好的解释了在使用重合法时如何一次读取多个bit数据。 行地址译码6位，所以范围是0-63，也就是说字线有64条。 列地址译码有4位，也就是说有16个。 字长为64bit，将64分成4组，每组是16bit（对应列地址位数）。 当行地址是0，列地址也是0时，其实取的是四组中第0位的数据，这样就实现了重合法一次取出多位。 写操作基本相同。 2、动态RAM(DRAM)保存0和1的原理 电容，充电是1，没充电是0。 基本单元电路如何构成 左边3管动态RAM，右边单管。 动态RAM芯片如何读写 行地址译码器这里参加译码的不止是地址还有读写选择线。 三角形是刷新放大器。作用：电容存储电荷的原理，电容会漏掉，经过一段时间电容上信号消失。刷新放大器对电容中保持的信息进行重现。 动态RAM刷新 只和行地址有关，与列地址无关。一次刷新刷的就是一行所有的基本单元电路。 刷新方式 集中式 可以看到2毫秒按照存取周期0.5微秒分成了4000份，其中128个周期是用来刷新的。 在死区时间内CPU和IO设备如果想访问动态RAM只能等待。 分散式 本来每个存取周期是0.5微秒，但是为了刷新又加了0.5，导致一个存取周期变为了1微秒。 没有了死区 和集中式比较，2毫秒内每行要刷新15.6次，存在过度刷新的问题。 异步式 在15.6微秒中可以认为是集中式，在2毫秒的周期内看是分散式的。 确实在安排好的情况下不会出现死区。 3、SRAM和DRAM的比较 注意引脚数，DRAM行地址和列地址可以分开传输，所以少。但是这样在速度上慢。 而且DRAM电容充放电比较慢，所以读取速度慢。 四、只读存储器 ROM 基本都是电子元器件的内容 五、存储器与CPU的连接存储器扩展 位扩展 位扩展利用两个芯片的数据线放到数据总线上不同的线上 字扩展 利用多出来的一条地址线作为片选线，从而实现两个芯片逻辑上的串联。扩展地址线长度。 位和字扩展 多出两根地址线，形成一个范围从0-3的可变数字。 将8个芯片分成4组，刚好对应上面的数字。通过地址线A11 A10加不同的电来实现片选译码。 对于每组2个芯片正常的位扩展。 一个连接的练习 开始学位和字的扩展时觉得很奇怪，但是当会后讲到一个如何设计CPU与存储芯片连接的题时就明白了一个核心：因为CPU的地址线和数据线数量与芯片的不同，因此需要进行位的扩展来适应CPU的数据线，需要合理的设计地址线来做片选译码和地址译码。 通常地址线的高位做片选译码，低位做地址译码。 六、提高访存速度的措施 高位交叉，高位交叉中很大概率是M0被频繁访问，而后面的不会。因为数据或者指令总是按照内存地址的顺序被使用。 低位交叉 这样的地址布局可以使得M0-3这四个存储体可以依次的被CPU使用。如果报错的是代码指令，就是先调用M0的0000位置，然后是M1的0000位置，依次使用。 低位交叉被并发的访问，将一个存储周期分成4份。 延展阅读1、关于按字寻址和按字节寻址的理解 设有一个1MB容量的存储器，字长32位，问：按字节编址，字编址的寻址范围以及各自的寻址范围大小? 如果按字节编址，则 1MB = 2^20B 1字节=1B=8bit 2^20B/1B = 2^20 地址范围为0~(2^20)-1,也就是说需要二十根地址线才能完成对1MB空间的编码，所以地址寄存器为20位,寻址范围大小为 2^20 = 1M 如果按字编址，则 1MB=2^20B 1字=32bit=4B 2^20B/4B = 2^18 地址范围为0~2^18-1，也就是说我们至少要用18根地址线才能完成对1MB空间的编码。因此按字编址的寻址范围是 2^18 以上题目注意几点： 1.区分寻址空间与寻址范围两个不同的概念，寻址范围仅仅是一个数字范围，不带有单位。而寻址范围的大小很明显是一个数，指寻址区间的大小。而寻址空间指能够寻址最大容量，单位一般用MB、B来表示；本题中寻址范围为0~(2^20)-1,寻址空间为1MB。 2.按字节寻址，指的是存储空间的最小编址单位是字节，按字编址，是指存储空间的最小编址单位是字，以上题为例，总的存储器容量是一定的，按字编址和按字节编址所需要的编码数量是不同的，按字编址由于编址单位比较大（1字=32bit=4B），从而编码较少，而按字节编址由于编码单位较小（1字节=1B=8bit），从而编码较多。 3.区别M和MB。 M为数量单位。1024=1K，1024K=1M MB指容量大小。1024B=1KB，1024KB=1MB.参考 https://blog.csdn.net/lishuhuakai/article/details/8934540","link":"/2018/09/30/2018-9-30-计算机组成原理：5、主存储器/"},{"title":"每天一点UWA：第十四周","text":"AssetBundleAssetBundle划分过细的问题，比如每个资源都是AssetBundle。 加载IO次数过多，从而增大了硬件设备耗能和发热的压力； Unity 5.3 ~ 5.5 版本中，Android平台上在不Unload的情况下，每个AssetBundle的加载，其每个文件的SerializedFile内存占用均为512KB（远高于其他平台），所以当内存中贮存了大量AssetBundle时，其SerializedFile的内存占用将会非常巨大。 BuildAssetBundleOptions.DisableWriteTypeTree这个选项的实际用处是什么？ 在Unity 5.x版本中，AssetBundle在制作时会默认写入TypeTree信息，这样做的好处是可以保证AssetBundle文件的向下兼容性，即高版本可以支持以前低版本制作的AssetBundle文件。 所以，如果开启DisableWriteTypeTree选项，则可能造成AssetBundle对Unity版本的兼容问题，虽然关闭TypeTree会使Bundle更小，但我们一般都不建议研发团队在制作AssetBundle文件时开启该选项。 我们项目做AssetBundle打包时，发现如果资源所依赖的C#Script的Public成员变量有变化时，用新代码加载旧的AssetBundle就会不兼容。有没有什么方法能判断这些Script在变化时是否需要重新打AssetBundle呢？目前我们使用.CS文件的MD5来判断是否需要重新打包，但其实这样应该有很多不必要的重复打包，对吗？ 该问题的本质原因是新代码的序列化信息变化所致。建议研发团队使用Unity 5的新的AssetBundle打包方式，默认情况下，Unity 5引擎会自动检测其脚本的序列化信息是否进行改变，从而自动进行增量打包。 PS: 虽然已经可以通过升级来解决，但是这个是个需要关注的点。 AssetBundle颗粒度问题 详见https://blog.uwa4d.com/archives/TechSharing_59.html 第一个问题 总结一下： 不要一个资源一个AssetBundle，因为Android上面一个serializedFile有512k,但是5.6后应该是32k。不过实际测试的情况是不一定是32K。WTF。。 对于AssetBundle小于1MB的限制在5.4后没意义，之前是因为www走webstream，会导致内存中占用AssetBundle大小4-5倍的空间。但是LZ4后基于其Chunk的加载特点，AB加载很快，且内存占用要比之前小很多。 仍旧需要注意的： 对于需要热更新的AB，也如问答中其他朋友的所言，要考虑实际情况控制AB的大小；- PS:可能是考虑网络下载的问题，以为过大的文件如果不做断点续传会是恶梦。 即便是LZ4的AB，其加载方式不同，加载效率也可能完全不一致。 对于AB的打包，尽可能把逻辑上同时出现（一个Prefab中非Share的Asset）、小而细碎的资源（Shader、Material、粒子系统等）尽可能打包在一起，并通过LoadAll来进行加载，因为这样会带来更好的加载效率。 使用LoadFromCacheOrDownload时如果用version参数，缓存的资源如何清除。 AssetBundle，其Version版本号变化时，新的解压Data是不会覆盖旧的解压Data的。清除旧的解压Data主要有三种方式： 设置缓存的过期日期，默认情况下是150天； 调用Caching.CleanCache来全部清空缓存； 当本地Cache已满时，Unity会从最早的AssetBundle来进行自动清理。 WWW.LoadFromCacheOrDownload(System.String url, Int32 version)这个接口加载资源，如果是Unity 4.x的版本，会有500个资源的数量限制，如果超过这个限制，Unity会删除之前缓存的每个资源，是这样吗？那在Unity 5.x 版本上是否还存在这样的问题呢？ 在Unity 4.x的版本中，如果通过LoadFromCacheOrDownload来加载AssetBundle，那么有两种情况需要考虑： -内存中加载的AssetBundle数量。在iOS平台上，通过该接口加载、同时存在于内存中的AssetBundle数量确实是有限的，接近300个，这是由于iOS上文件句柄数的限制导致。而该限制在Unity 5.0以后则被完善了，因为Unity 5引入了虚拟文件系统，所以不再有这个限制；在Android平台上，则没有这个限制，或者说数量限制值非常大，基本可以忽略。 本地Cache中缓存的AsseBundle数量。无论是iOS、Android还是PC版本，都没有500的数量限制，而是有一个硬盘占用大小限制。具体来说，在WebPlayer平台上，有50MB的缓存限制，而在其他平台上，则是4GB的缓存限制。所以只要硬盘占用大小不超过限定值即可。 Font我们在内存优化时发现一个问题，编辑器版本 Unity 5.3.4p6，使用UGUI，场景A中一个Text控件使用自定义字体资源，然后把该控件Text属性勾选为空（disable），再Load一个空场景，看场景A卸载后在内存中的残留，发现有一份引用是 ManagedStaticRefrences（）的 Font 内存。如果不是把Text属性disable，则场景A卸载后内存里不会再残留被引用的Font内存，请问可能是什么原因造成的呢？ UWA对于该例子进行了检测，的确能够在 Editor 复现。查了下 UGUI 代码，能对 Font 产生引用的，主要是这个函数 FontUpdateTracker.TrackText(Text)，其中会把 t.font 引用起来；而对应的解引用的函数为 FontUpdateTracker.UntrackText。因此，如果出现了两者的调用不匹配，就有可能造成 font 的 ManagedStaticRefrences 引用。 进一步查看后，可以看到在定义了 UNITY_EDITOR 宏时，UI 元素会增加一个名为 OnValidate 的函数，Text 组件则在其中进行了 TrackText 的操作。而最关键的是，该函数在 Text 组件以“未激活”的状态被实例化时同样会被触发，同时，如果这样的 Text 组件在后续没有被激活过就被销毁，其 OnDestroy 和 OnDisable 函数是不会被调用的，参见文档中的这句话：OnDestroy will only be called on game objects that have previously been active.而 OnDisable 中才会调用 Untrack 解引用，所以造成了不匹配，导致了 font 的 ManagedStaticRefrences。 但是，OnValidate 函数只在 Editor 上才有，真机上不会发生上面说到的不匹配的情况。所以建议研发团队先在真机上测试下是否还有这种情况，如果确实没有，那么就忽略该问题即可。 PS:Mark Gameplay我想了解如何使用顶点色Mask控制明暗关系，才能达到类似崩坏琪亚娜效果？ https://blog.uwa4d.com/archives/TechSharing_60.html 第五个问题，NB UI我们游戏中用到NGUI的HUD，单位主要是一个进度条和一个倒计时文本(持续更新)，同屏数量达600左右，单位本身在持续移动。现已将这些设置为独立Panel，且只有2个DrawCall(进度条所在图集和文本)，但还是卡顿得很厉害，请问是否有优化的方法？ 简化元素的几何：进度条中的元素尽量避免Sliced 模式（改Simple）；倒计时部分如果使用了Outline或者Shadow，将其转为“图片字”； 降低更新频率：如倒计时按“秒”统一更新；进度条按1%甚至5%的间隔更新一次；移动速度较慢时可以尝试隔帧更新位置等； 拆分子UIPanel：尽可能将更新频率相同的UI元素放在一个UIPanel中，从而降低每次更新时涉及到的UI元素数量。具体的拆分数量，则可能要通过较多的测试来确定。需要说明的是，此处即使增加10到20个DrawCall，对渲染上的影响并不大。 粒子我们项目中有大量的特效，一个特效Prefab可能包含100-200个GameObject，每个GameObject上都挂有一个粒子系统，但是实际上很多特效只有延时和坐标旋转之类的参数的区别。我看了Prefab文件后发现每个粒子系统分别记录了各自的信息，从而导致整体文件很大，内存占用也比较大。请问是否有优化的方法？ 如果开发的是一个手游项目，那么一个Prefab下含有100-200个粒子系统是非常不足取的，主要会造成以下几种问题： 同时播放100个以上的ParticleSystem，其ParticleSystem.Update本身的CPU占用会很高。下图为一款游戏在华为6Plus上的表现。可以看到Active Particle数量还没有达到100，其Update耗时就已经占到了5ms； ParticleSystem.ScheduleGeometryJobs开销会很高。其耗时主要体现在渲染模块中的Culling阶段，与粒子系统的数量相关，场景中Active粒子系统的数量越多，其开销越高； 子线程中的渲染压力较大。Unity5.3版本以后，粒子系统的渲染虽然在主线程中占用很小，但并不意味它没有耗时，其耗时在渲染线程中，当渲染线程压力过大时，主线程同样会出现等待（Gfx.WaitForPresent），因此同样可能对帧率产生影响； GPU的渲染压力较高。同屏中渲染的粒子系统越多，其屏幕每帧的填充率越高，从而更加容易造成设备的发热； 内存压力较高。如果一个Prefab上有100-200个粒子系统，并且如果场景中有10个以上这样的Prefab存在，那么其内存占用将在10~25MB内存区间内。就目前而言，粒子系统仍然是以Clone的形式存在，所以虽然粒子系统可能仅仅是某些参数不同，但其仍然是多个不同的粒子系统。因此，我们在UWA报告中会显示粒子系统在项目运行时的具体显示数量，以方便研发团队对粒子系统进行关注。如下图所示，一般来说，每帧中粒子系统的数量建议在400以下。 模型&amp;动画网格模型FBX文件在不开启Read/Write选项时， 如果通过StaticBatchingUtility的CombineMesh来合批的话，内存会增加么？ 增加内存，主要表现在内存中CombinedMesh的增加以及一定量堆内存的增加。 该API使用的前提必须是网格Fbx模型开启Read/Write，如果不开启，则无法读到网格数据，进而不能完成网格的拼合操作。 如下图，请问这几个参数的单位是什么？ Rotation Error使用角度（degree）作为单位。Position和Scale是距离偏差的百分比（曲线调节前后的距离偏差与某距离值之比，取决于Unity内部实现），取值范围1~100，但实际可以高于100，并有作用。我们建议研发团队在调节该误差时，将调节前后的动画效果进行对比，使文件体积压缩得尽量小，同时使动画效果在视觉上偏差不会太大。 PS:没找到，可能是动画导入的选项。 如下图，这个ResampleCurves选项的作用，以及是否和对内存性能的影响？ ResampleCurves选项是在Unity 5.3版本后加入的，在之前的版本中是隐藏并且默认勾选的。该选项会改变Unity动画数据的存储方式。 动画文件在导入到Unity之前，其关键帧的数据通常是以欧拉角（Euler format）的方式存储。在勾选该选项时导入，Unity会将欧拉角转换为四元数（Quaternion）表示，并且会生成逐帧的数据（不只是关键帧）。新生成的逐帧数据是为了解决四元数插值问题。关闭该选项会使动画文件保持欧拉角表示，但在应用于GameObject时仍会转换为四元数。 建议保持默认勾选该选项，只有当发现Unity中的动画播放效果与在动画编辑工具中的效果出现较大偏差时，尝试取消该选项，查看是否是该选项的原因导致动画偏差。我们在测试中发现该选项对运行性能影响并不明显。在内存方面，勾选该选项会使动画文件略微增加。 动画提出scale 参见https://blog.uwa4d.com/archives/TechSharing_58.html第五个。 PS:很不错。 动画模块中，Animators.ProcessAnimationsJob和Animators.WriteJob的CPU占用较高，这些与什么因素有关？ Animators.WriteJob受模型骨骼数目影响较大（受animation curves影响不明显），骨骼数目越多，该函数耗时越大。同时，开启Optimize GameObject选项能够降低该函数耗时。Animators.ProcessAnimationsJob 同样受骨骼数目影响较大，同时也受animation curves数目影响，二者数目越多，该函数耗时越大。 性能综合在整体的性能消耗上，CPU和GPU各占一半合理吗？如果不是，各占多少为好？还是说需要根据机型来看？其次，我如何知道游戏在手机上的GPU消耗？Profiler是看不到的，有工具推荐吗？ 首先，CPU和GPU是并行的，也就是CPU在运算的时候GPU也在运算，一帧的结束时间是两者中比较晚结束的那个。因此，一般我们在考虑这个问题的时候，经常会说是CPU bound还是GPU bound，也就是GPU在等CPU还是CPU在等GPU。 最理想的情况是两者都并行均衡，且都没有出现互相等待的情况。但在目前的大多数移动游戏中，都是CPU耗时为主要性能瓶颈。这也是为什么有多线程渲染的原因，多线程渲染就是利用CPU端的并行性，让CPU处理得更快，不拖后腿。 对于GPU的压力分析，可以尝试用Intel GPA，Mali或者高通出的针对自家芯片的工具。 为什么Unity里实例化一个Prefab会产生那么多GC Allocated? 这是一个特例，但是从里面可以总结出一个问题，就是在Instantiate一个对象时会发生或者可能发生以下的事情 序列化和反序列化的处理，因为用prefab生成对象本身就是需要反序列化的。而直接clone一个对象可能还有先序列化在反序列化。 可能的资源的加载，比如prefab上用到的mesh、贴图等。 可能的shader编译，如果用了一个之前没有用过的shader就会实时的编译。 对象身上脚本的初始化。如果实例化一个prefab发现很占用时间要注意是不是脚本里面在awake或者start里面的功能太多了。 UI界面的Active和Deactive也会造成UI代码底层的一些相关OnEnable和OnDisable操作，同样会造成一定的堆内存分配。 渲染Unity的材质的宏是有材质用到时才会被编译吗？还是说不手动Skip都会编译？ 在Unity中shader variant也包含两种类型，一种是通过 shader_feature 定义，一种是通过 multi_compile 定义。而只有通过 shader_feature 定义的 variant 在发布时会根据其使用情况来进行剥离。 具体可见Unity官方的文档：https://docs.unity3d.com/Manual/SL-MultipleProgramVariants.html 需要注意的是，放在Always Included Shaders中的Shader，其包含的所有 variant 都不会被剥离，因此对于Standard Shader这类包含了大量 shader_feature的Shader，不推荐将其放入。 PS:没有回答根本的问题： Editor中：修改shader并保存时立即编译。Runtime下，无论哪个平台，都是在进入场景时加载shader object内容到内存，但是首次实际调用渲染时才编译，编译完成之后会cache下来。有两种优化方法：调用Shader.WarmupAllShaders()，自动编译该场景中用到的所有shader。该方法在Unity5中已经废弃。在项目设置的GraphicsSettings中，可以导出ShaderVariantCollection，并在Preloaded Shader中导入，这样的话就可以在载入场景时一并编译需要预加载的shader，这样的优化在移动平台上用得比较多。具体见 听说移动端开启多线程，把后期效果移动到渲染线程会节省后期的消耗。我测试了一下，虽然主线程中后期显示的CPU占用降低了，但是却多了Gfx.WaitForPresent的时间，最后两者相加基本还是一样的。那开启多线程这个功能，对后期到底有没有帮助呢？ 开启多线程渲染一般情况下会极大降低主线程的渲染耗时，但并不会降低其本身的总体计算量。因为这并不是底层算法或硬件上的提升，而是将部分计算从主线程搬到了子线程。所以，开启多线程的好处在于为主线程带来了大量空间来执行其他耗时模块（如代码逻辑等）。 但这并不意味着开启多线程渲染就“万事大吉”。如果渲染模块本身开销就很高，那么子线程一样会很耗时，更有可能出现主线程等待子线程的现象，也就是WaitForPresent开销较高的情况。所以，开启多线程是会降低主线程的渲染压力，但其帧率未必会大幅提升，还需研发团队自行在自己项目中进行尝试和比较。","link":"/2017/11/05/2017-11-5-每天一点UWA：第十四周/"},{"title":"每天一点UWA：第二十周","text":"小结&amp;新的开始 从今年的7月29号发布第一周的笔记算起不知不觉已经二十周了，当时的想法也很简单就是下定决心读完当时算下来是168篇文章。5个月过去了，在写这篇的文章的时候基本上已经通读完了所有厚积薄发版块的关于unity的文章，真的感觉这是我这些年来做的最有毅力的一件事情。可以说在这二十周里面对于unity的理解尤其是图形学上学到了很多东西，而且也学会了很多优化的理论和别人实践的方法。 理论已经学习完了，在后面的工作中就是一个实践的过程了。现在的项目会开始使用GOT工具进行优化的工作，真正的把优化这条路走下去。 由于UWA出文章的速度不可能太快，而且自己的工作也很忙，所以每周的笔记可能会改成每月一篇了，继续加油。 还有就是UWA都开始搞UE了，还有什么理由不开始学UE。 GamePlay在UWA的测评结果中，我们的Mesh文件内存过高（使用UWA GOT测试最大的场景会达到200MB），大部分是由于场景的物件导致的。我们的场景物件是这样加载的：场景有一个基础的框架（地面、天空盒和个别大的物件等），在进入场景后，会根据位置来加载其他的物件，加载的物件在离开视野后，为了防止下次再加载，只将其隐藏了，并没有销毁，这样的话，人物如果在场景里跑了一圈，就相当于整个场景的物件，都会进入内存。请问，是不是将离开视野的场景物件销毁比较好呢，销毁后是不是要调用UnloadUnusedAssets才能彻底从内存中去除呢？ 如果题主做的是移动游戏，那么200MB确实太大了。 建议题主建立一个Memory Pool来缓存场景中的物体，至少有以下两个规则： Pool必须有一个上限，一般为容器的数量，超过最大阈值后即开始进行清理； 为Pool中每个Object记录一个存储时间，当时间超过一定阈值后进行清理，或者当Pool满了后，将时间最长的进行Deactive Object进行清理。 通过缓存池来进行销毁较长时间不再显示的的物体，同时，可以通过UnloadAsset API来卸载相关的资源，Resources.UnloadUnusedAssets API一般只建议在场景切换处进行使用。 PS:说两句，如果一个最长时间的物体正好在视线内就不好办了。所以这个答案有点太粗暴，个人感觉还是要根据摄像机位置进行动态的删除对象。 解析NavMesh.asset数据，用于服务器寻路。 https://blog.uwa4d.com/archives/2110.html Q3 给大佬跪了 ReflectionProbe在移动平台丢失部分高光数据 https://blog.uwa4d.com/archives/2110.html Q4 仅记录，没仔细看过后续版本的bugfix，遇到了在处理吧。 大批量地合入美术资源时，经常会出现构建出来的版本出现材质引用丢失、Animator Controller引用错误、贴图引用错误等资源引用错误的问题。 出现这个问题可能是如下原因： 是否使用代码混淆。在Prefab 上挂的脚本忘记添加到排除混淆的列表，导致序列化的字段被混淆，打完Bundle后的Prefab资源加载时候，挂接的脚本出现引用错误； 资源导入都重载过OnPostProcess并处理了资源设置，这一步是否修改了什么不合理的地方，比如破坏了引用关系； 打包AssetBundle时，在构建Bundle 之前有没有使用文件操作API（不是 Unity 的AssetDatabase的API）来直接修改了某个文件夹或者其他会破坏引用关系的行为，然后构建Bundle，完成后恢复文件夹名字（或者恢复资源原始状态），这样丢失引用关系的几率很大； 有没有可能发布机器上，看着正常，但是Perforce里面已经存在一堆已修改的Meta文件；这种问题常出现于美术本地有两个A1，A2个相同资源在不同文件夹，A1受版本控制，但是由于某种操作，本地临时资源A2使用了原本A1的Guid，原本正确的 A1 被迫使用了不正确的新生成Guid（相当于两人交换），然后上传了A1的Meta，结果发布机器的下来的A1 Meta就会跟别人丢失引用，或者更新下来本地重新分配了新的Guid；美术策划最容易犯这个错误； 我们是Unity 5.3.8p2，上周遇到一个疑似bug，美术多上传了一组相同的资源，我们更新下来都会重新生成Guid，但是很多挂起的Meta在Unity里重新导入后，在版本控制里神奇地消失了，但修改还在； 如果都不是，只能尝试最小排除法了，删除项目绝大部分资源，一点点增加，然后打包，重现，排除原因；不行的话然后删除代码，一点点添加，打包，重现…有时候笨办法也是最容易接近真相的。 游戏对战时因为会频繁更换武器或释放技能（主要是网络玩家），会替换不同的动作，但是发现每次设置animatorOverride[name]=clip（每次设置3-6个），CPU占用50-180ms，请问这是什么原因？我按照官方的指导存了一个list（https://docs.unity3d.com/ScriptReference/AnimatorOverrideController.ApplyOverrides.html） ，然后每次LateUpdate的时候调用ApplyOverrides，发现占用更高了，每次400ms，请问这个要怎么解决？目前每个网络玩家玩家OverRidesCount是73，会不会是Clip过多的原因？ 在真机运行时发现animatorOverride[name]=clip的耗时会受到animatorcotrollor中的clip数目的影响，随数目的增多耗时会明显增加，70个以上的clip耗时确实能达到50ms(红米note2)以上。 换为applyOverrides方法时耗时仍然很高，而且出现了堆内存分配，但并没有达到400ms那么高。 尝试了整体替换AnimatorOverrideController，即不在现用的AnimatorOverrideController中替换clip，而是在另一OverrideController中换好clip后，再整体替换到runtimeAnimatorController，这样耗时就会降到很低了。 TextureUnity 5.5.1版本下，Sprite Packer在iOS平台下RGBA PVRTC4打包图集失真非常严重（对单个的Sprite设置PVRTC4是正常的），参照了4.6.7版本是正常的，我想知道为什么呢？ unity的bug 在 Windows 下尝试用 4.7 的 pvrtextool.exe 替换了 5.x 的，暂时解决了这个问题，建议也尝试一下。 异步纹理加载Asynchronous Texture Upload这个功能最后到底有没有实用？ 这个是默认就开启的，只是得开启多线程渲染才有效，因为要在 Render Thread 里上传纹理，还有文档里提到的各种限制，比如只针对关闭了 Read/Write 的纹理… 非多线程渲染时，异步加载纹理的时候，可以在 Loading.UpdatePreLoading 这个函数里看到较高的 Texture.AwakeFromLoad。但多线程渲染时，这部分的开销就会变得很小，因为这部分开销被放到 Render Thread 去了，如下图中的 Gfx.UploadTexture。 但需要注意的是，这个地方的异步并不是流式的加载，也就是说，当加载一个大纹理的时候，还是一次性完成的，并不会分帧去做，如下图加载了一张2048的纹理，图中绿色峰值是Gfx.WaitForPresent，也就是主线程在等待 Render Thread。 综上，这个功能实际上就是把某些满足要求的纹理的加载时间从主线程移到了渲染线程。在某些情况下，确实是可以提高总体的加载速度的。但这个功能并不能真正地“解决异步加载时纹理却只能同步加载”的问题，只是把卡顿放到渲染线程去了（如果耗时高了，主线程还是要等的）。 非常好的问题，建议直接看答案。 https://blog.uwa4d.com/archives/TechSharing_84.html Q3 在目前的Unity版本中，使用多维材质是否会对效率产生影响，用多维材质和把模型分块哪个更好？ 制作美术资源时，应该尽量避免使用多维材质。 先举例说明多维材质的一个优点是拆分模型做不到的： 一块大石头有石头和草地两个材质，做成一个整体的模型，使用多维材质，作为一个物件进行烘焙，在Lightmap上的UV分布是一个整体，不会出现拆分为两个模型烘焙产生的接缝问题。 除了上面这种情况，其他情况下推荐将模型拆分成多个模型赋予不同的材质。 优点是： 1、多个模型会作为多个MeshObject参与到裁剪、静态批次等优化中 ； 2、拆分的模型和贴图可以进行材质合并，程序才能进行下一步的优化，如果本身是多维材质，就无法进行合并DrawCall的优化； 第一个优点就能带来很大的收益。制作上应该按照一个模型对应一个贴图的做法进行，如果模型是一个整体，比如房子由底座、墙体、屋顶组成，建议将他们多选导出成一个FBX。 另外，不同材质的模型建议做成多个模型，再多选导出成一个FBX，仍然是一个模型对应一个贴图的规范进行制作。 PS: 对于人物模型可能不考虑剪裁，但是至少减少了drawcall。 UI我在UGUI 使用一个UIRoot，类型使用Screen Space - Camera，使用摄像机的 Culling Mask, 如果UIRoot可视，下面的UI子物体设置不可视Layer，是不是不会被裁掉？有没有什么解决办法吗？ UGUI的网格合并是以Canvas为单位的，所以只能改Canvas的Layer才有效。 如果只是个别UI元素要快速隐藏和显示，可以考虑用Scale为0来做，Scale为0时UI的顶点信息会被清空，所以隐藏时就不会参与网格重建了。 PS:顶点清空的第一帧应该会出现rebuild，后续帧不参与rebuild。 在UI中，有两个字体控件每帧都要显示不同的数字，第一个有8个字，第二个有6~7个字，需要开outline增加辨识度，从而引起了较高的性能开销。 把这两个控件单独放到另外独立的Canvas，该问题依然存在。现已确定该开销是由这两个字体控件每帧的文本更改引起的。 提到一个是8个字，一个是6到7个字，都开启了outline。 首先建议再做一次确认，看是不是禁用这两个之后，SendWill就确实没开销了。因为这个字数看上去并不应该造成很明显的开销； 其次，如果确实是这两个造成的，那么就需要先考虑下能不能转成带outline效果的静态字体，不行的话再考虑下能不能降低更新的频率了，是不是确实要每帧都变； 如果要再降低，就只能考虑静态字体了，如果文本是一些比较固定的内容就很好处理，但如果是像聊天一样，内容无法预知的话似乎就没什么办法了。或者就是低端机用shadow来做。 现在用Resources.Load()加载资源时，UI动画会出现卡顿的现象，如果想消除卡顿，是不是只能通过异步加载，分拆Prefab和优化材质网格动画之类的操作来实现？还是说UI动画可以在另外的线程播放之类呢？另外我想问下，异步速度是不是一定比同步慢呢？ 不直接贴答案了 总结一下就是遇到这样的卡顿的解决办法 分析卡顿原因 使用异步方法 拆分功能、预加载 工具Unity中的Frame Debugger中的渲染顺序以及数量和Profiler中看到的Draw Call数量，以及在高通的调试工具里看到的DrawCall数，它们之间有什么关系呢？哪个数值是影响渲染的重要指标？ 简单来说，Unity引擎中Total Batches是我们建议最需要关注的指标。 1个Setpass Call或者Batch，相当于是一次Render State的切换，而1个Draw Call则是CPU让GPU去进行渲染某一个Object的1次操作。在当前的移动设备中，1次Render State的切换要1个Draw Call本身要耗时。 所以，Total Batches是我们较为建议的关注指标，也是UWA性能报告中所提供的Draw Call查看指标。而Frame Debugger中，其数量是与Total Batches相一致的，即查看的是每一个Batch的渲染物体。 更为详细一些的说明，可以查看https://answer.uwa4d.com/question/58d29b8b5a5050b366a6b6ae 而Unity Profiler中的Draw Call，其理论上对应的则是glDrawElements的调用次数，其与高通或其他第三方工具所返回的Gl Trace信息操作数量不太一致，但应该与其中的glDrawElements API的调用次数基本一致，题主可以自行检测看看。 我用UWA GOT进行本地性能测试，在CPU的数据分析中发现，某些帧StackTraceUtility耗时特别高，这是什么原因导致的呢？ StackTraceUtility.XXX是Unity引擎的Log输出，可能是本身Debug.Log/LogError的调用输出，也可能是使用过程中引擎端出现了Warning/Error等信息而自动输出的。 我在Profiler中观察性能曲线，发现某一帧AssetBundle加载中，LockPersistentManager耗时比较大。请问这部分能否优化？ 这说明当前帧或前几帧中存在较大量的资源在通过LoadAsync来进行加载，其本质是所加载的资源过大所致，对自身资源进行合理优化可降低Loading.LockPersistentManager的开销。 另外，将异步加载换成同步加载，LockPersistentManager就不会出现了，但其总加载耗时是没有变化的，因为总加载量没变。 我在安卓真机上跑游戏，发现Profiler下的合批数据和PC或者iOS下的不一样，因此不确定Android的合批是否有效。经过分析，Android上不能设置Graphics Jobs(在Player Settings里面)，也是不断打包测试发现这个问题，想了解一下具体是什么原因呢？ Graphics Job目前在Android平台上是为Vulkan而设计的，也就是只有支持Vulkan设备的才会真正起作用。按照Unity原厂的说法，该选项在不支持Vulkan的Android设备上应该是没有效果的。 另外，Graphics Job和MultiThread Rendering并不建议同时使用，而且以目前的Android设备来说，建议只开启MultiThread Rendering一项即可。 模型&amp;动画在Unity3d的官方文档中，animationclip.framerate的解释如下： “Frame rate at which keyframes are sampled. (Read Only) This is the frame rate that was used in the animation program you used to create the animation or model.” 我对此有些疑问： 1）这个是否为动画系统每一秒钟更新动画的次数？如果是，当这个值高于Application.targetFrameRate时，一秒钟更新动画的次数依据哪个为准 2）这个是否只是调节动画播放速度的一个参数，而每秒钟动画状态更新的次数不受影响？ A: 动画采样的时候是根据当前播放的时间去找对应的前后两个关键帧做插值。所以动画本身得告诉Unity两个关键帧（没做keyframe reduction时）的间隔时间是多少，或者一秒有几帧，这个值就是framerate。所以这个是只读的，导出时就应该是确定的。因此这个值也不会影响运行时动画的更新次数，默认情况下动画就是每帧更新一次的。 在手机上测试LoadLevelAsync和LoadLevel的加载速度，同一个场景，LoadLevelAsync要比LoadLevel多花费40%左右的时间，请问这是正常的么？LoadLevel会有卡顿，导致Loading进度条不平滑，但是LoadLevelAsync好像又会增加Loading的时间？我项目中场景动态加载的做法是，是把物件做成Prefab，然后根据主角的位置做动态加载相应的Prefab，用的是Resources.LoadAsync方法。现在加载一些比较大的物件时，在红米2等低端机上，仍然比较卡，要消耗200ms以上。请问有什么好的方式，能平滑这个加载过程么，谢谢！ LoadLevelAsync一般情况下是要比LoadLevel慢的，但是否要慢40%，这个其实是根据每个场景所要加载的不同量而定的，并不是确数。 LoadLevel和LoadLevelAsync其实最本质的区别，是前者一定要在下一帧结束前完成加载操作，所以当加载场景较大时，其随后的单帧开销就会很大，而后者则没有这个限制，引擎可以根据当前的使用情况或者ThreadPriority（这个值是是否对LoadLevelAsync有影响，还没做过具体实验，但对于LoadAsync确实有影响 ）来自行调控。 还需要说明一点的是，不是说使用Async，它就一定是绝对平滑，下图红框是LoadLevel，绿框是LoadLevelAsync操作。 关于真正“平滑”异步的加载方式，Unity引擎目前还是没有的。在遇到较为复杂的Prefab（比如大纹理、多AnimationClip等等）时，其加载依然会出现卡顿。如果想要缓解该问题，建议如下：定位资源-&gt;查看资源为何开销-&gt;采用预加载的方式处理这样的资源。 我使用了IL2CPP后是否还存在Mono内存呢？使用IL2CPP后，通过Profiler工具获取的managedObject（例如： int32[]）是哪种内存？ 可以简单地认为，Il2CPP只是替换掉了Mono的虚拟机实现，所以该分配堆内存的地方还是会一样的分配（可能会有某些细节的地方不一样）。 IL2CPP在堆内存分配方面和Mono 最大的不同主要是Reserved Total 是可以下降的，而 Mono的 Reserved Total 只会上升不会下降。 PS：原来是这样，我一直以为是直接转成了CPP语言。 物理我的游戏场景中有一个boxcollider2D，位置在(0.0f,0.0f) 到 (1.0f,1.0f)；调用Physics2D.BoxCast(new Vector2(1.0f,1.702), Vector2(1.0f, 1.4f), 0, Vector2(0.0f,1.0f), 2.0f); 会产生碰撞，理论上碰撞的边界在1.700 ，我已经将位置放到1.702，应该是规避了浮点数误差的问题的，如果我将该值放大了1.706就不会产生碰撞了，请问哪里可以调整这个误差值的范围呢? Unity 2017.1版本的Physics2DSettings里面有一个Default Contact Offset，表示当两个collider之间的距离小于它们的ContactOffset之和就会产生碰撞。把这个值设置小一点应该能解决题主的问题。 Unity 5.x中Contact Offset，默认是0.01，这也是为何1.702不行，而1.706可以的原因。 性能综合释放了资源，但纹理还在内存中，且引用数为0，要如何销毁呢？纹理所在的UI的GameObject是通过Destroy销毁的，并且执行了Resources.UnloadUnusedAssets(); Ref Count为0应该就是可以通过Resources.UnloadUnusedAssets或Resources.UnloadAsset来进行卸载了。 出现这种情况建议如下： 尝试将Resources.UnloadUnusedAssets在Destroy稍后几帧执行； 在加载时尝试直接获取这些资源，然后在Destroy后通过Resources.UnloadAsset来卸载指定资源。 Resources.UnloadUnusedAssets() 在卸载旧场景后加载新场景前调用好，还是在加载新场景后调用比较好呢？如果考虑内存峰值的话，我觉得是前者好，但是在UWA上看到有些文章说是加载场景后调用。 如果是通过LoadLevel(Async)类似的方式来加载场景的话，那么Unity自身会在底层执行一次类似Resources.UnloadUnusedAssets的操作。所以，这时如果手动调用Resources.UnloadUnusedAssets操作，时间间隔很短，其实这个是有些重复的。因此才建议在新场景加载后再调用一次。 但如果使用LoadLevelAdditive或其他类似的API来切换场景的话，那么Unity是不会调用Resources.UnloadUnusedAssets的，这时在旧场景卸载后调用，其实也是很不错的选择。","link":"/2017/12/23/每天一点UWA：第二十周/"},{"title":"每天一点UWA：第六周","text":"AssetBundle这是一个很长的问题：字体作为多个资源的依赖包，会在游戏中被加载多次。我们现在有个问题，AssetBundle A资源依赖于这个字体，加载A的时候加载了一份字体，然后B资源也依赖这字体，而后加载B的时候我们没有去重复加载字体，这时候发现B资源上出现了字体丢失的现象。 请问加载资源的时候，Unity会自动去识别内存里是否有它的资源依赖包吗？如果有的话，为什么B加载的时候找不到已经存在内存中的字体？这里需要手动去做些什么处理吗？同时我发现依赖包资源如果进行了bundle.m_AssetBundle.Unload(false)以后，其他依赖于这个包的资源就引用不到了。我们流程上对于每个读进来的AssetBundle，都会加载完后马上进行Unload(false)，请问如果是依赖包的话，是不是不能对其进行这步操作？ 这个问题其实是典型的一个AssetBundle使用的问题，其中牵扯的细节在unity的文档中都有。 总结来说就是对于公共资源的字体，在A和B加载前要提前加载好，这样unity根据依赖关系会自动的找到字体asset。 但是如果加载A完成后直接卸载了字体的AssetBundle，那么加载B时肯定会出错。此时字体asset虽然还在（因为用的是Unload(false)），但是unity已经无法依靠依赖关系来作用在B上了。同时如果测试再次加载字体AssetBundle，则原有的字体asset出现内存泄漏问题。 自己下载了shader包，如何替换buildin资源？ 需要完全的替换，shader自己不会关联，而且很多时候用的是buildin的material，测试用的就是buildin的shader。 还有一个情况是prefab中用的shader的GUID和自己导入的不同，可以用通过如下脚本进行替换。 123456789101112131415161718192021222324using UnityEngine;using System.Collections;using UnityEditor;using System.IO;public class BuildScript { [MenuItem(&quot;Build/RefreshMat&quot;, false, 501)] static void RefreshMat() { var guids = AssetDatabase.FindAssets(&quot;t:Material&quot;); foreach (var guid in guids) { var path = AssetDatabase.GUIDToAssetPath(guid); if (path.ToLower().EndsWith(&quot;mat&quot;)) { var mat = AssetDatabase.LoadAssetAtPath&lt;Material&gt;(path); if (mat &amp;&amp; mat.shader) { Debugger.Log(&quot;{0}\\n{1}\\n{2}\\n{3}\\n&quot;, path, mat.shader.name, mat.shader.GetInstanceID(), Shader.Find(mat.shader.name).GetInstanceID()); mat.shader = Shader.Find(mat.shader.name); } } } }} Font一个字体打包到AssetBundle中，加载后在profiler中看到两份 通常TTF文件会包含一个字体的多个字型，如可能包含正常字型、加粗字型、斜体字型等。而在Unity中会将其分为不同的Font资源，且他们之间会相互依赖。所以，如果项目中确实需要加粗字型的话，内存里出现两个Font是正常的，但如果实际上不需要加粗，那么可以尝试寻找一个不包含加粗字型的字体文件来替换该TTF文件。 在用Profiler真机查看iPhone App时，发现第一次打开某些UI时，Font.CacheFontForText占用时间超过2s，这块主要是由什么影响的?若iPhone5在这个接口消耗2s多，是不是问题很大？这个消耗和已经生成的RenderTexture的大小有关吗？ Font.CacheFontForText主要是指生成动态字体Font Texture的开销, 一次性打开UI界面中的文字越多，其开销越大。 这个消耗也与已经生成的Font Texture有关系。简单来说，它主要是看目前Font Texture中是否有地方可以容下接下来的文字，如果容不下才会进行一步扩大Font Texture，从而造成了性能开销。 Texture游戏里重复的特效较多，有些只是图案相同但改变了颜色参数，如果都打成独立AssetBundle，则内存里面会有多份Texture。关于这样的打包一般有什么推荐的方法呢？ 只保留一份初始纹理资源，并通过Shader在运行时改变其整体配色，从而达到不同的效果。 如果是局部配色不同，那么可以在原始纹理的基础上加一种或几种Mask纹理，用来负责颜色的自适应调配，然后再通过Shader来达到不同的展示效果。 UIGameObject.Deactivate消耗大 GameObject.Activate/Deactivate本身通常不会产生很高的开销，产生高开销的是其OnEnable/OnDisable操作。 如果是自定义脚本，可以考虑优化OnEnable/OnDisable函数中的操作。 如果是UI可以考虑通过移出屏幕或者改摄像机的culling layer来实现隐藏。前面有讲过相关的内容。 动静分离或者多Canvas带来性能提升的理论基础是什么呢？如果静态部分不变动，整个Canvas就不刷新了？ 在UGUI中，网格的更新或重建（为了尽可能合并UI部分的DrawCall）是以Canvas为单位的，且只在其中的UI元素发生变动（位置、颜色等）时才会进行。因此，将动态UI元素与静态UI元素分离后，可以将动态UI元素的变化所引起的网格更新或重建所涉及到的范围变小，从而降低一定的开销。而静态UI元素所在的Canvas则不会出现网格更新和重建的开销。 PS：位置和颜色变化应该会造成更新，如果出现血条那样的会造成mesh变化从而重建。 UI优化UGUI参考的函数 1、Canvas.SendWillRenderCanvases()该API为UI元素自身发生变化（比如被Enable或者被缩放，移动并不算）时所产生的调用。发生在canvas被渲染之前。 2、Canvas.BuildBatch该API为UI元素合并的Mesh需要改变时所产生的调用。通常之前所提到的Canvas.SendWillRenderCanvases()的调用都会引起Canvas.BuildBatch的调用。另外，Canvas中的UI元素发生移动也会引起Canvas.BuildBatch的调用。 NGUI参考的函数 UICamera.Update()该函数通常在点击时出现开销。因此，当该函数的CPU开销较高时，通常都是因为调用了其他的较为耗时的函数引起。 UIRect.Update()该函数通常在需要更新锚点位置时出现开销。因此，当该函数的CPU开销持续较高时，通常是因为当前场景中有较多的UI元素绑定了OnUpdate模式的锚点。 UIPanel.LateUpdate()该函数为NGUI最主要的CPU开销，包含了对所有UI界面包括其下UI元素的状态更新、网格重建、DrawCall合并等操作。大量的UI变动或者不合理的UIPanel布局都有可能导致该函数出现较高的峰值。 UIRect.Start()该函数主要涉及到UI元素的初始化操作，通常在UI界面被实例化时出现并产生一定的CPU开销。 优化建议： 动静分离，动的频率不同也分离，减少Mask组件的使用，使用Mask不仅会增加GPU端渲染的压力，同时也会造成CPU端DrawCall的明显上升。可尝试用RectMask2D来进行替换。 减少OnEnable和OnDisable，通过移动位置、改变摄像机culling mask。后者可能会一定程度地提高内存的开销（UIDrawCall中存储的Mesh）。 NGUI的图集在内存里存了多份，求问怎么清理？ 游戏运行中，UI Mesh出现多份不同内存的情况，是正常的，因为随着UI widget使用的增加或减少，创建的UI Mesh是会随着变化的。 同时，如果不同UIPanel中存在相同Atlas的Widgets，则也会出现上图中的情况。因此，建议大家遇到这种情况时，查看单帧中NGUI UI Mesh重名的是否有多份重名资源。如果存在，则说明相同Atlas中的资源被多个不同的UIPanel所使用，这种情况是需要尽可能避免的。 工具Profiler中Other下System.ExecutableAndDlls的内存很大 一般来说，在移动游戏中，该选项经常在iOS真机运行时会看到，System.ExecutableAndDlls该项显示的是执行文件和所调用的库（物理、渲染、IO等系统库）的总和。 开发团队不用太担心该选项的数值，因为很多应用均在共用这些库，并且它对于真实项目的内存压力非常小，几乎没有影响，而且OS也不会因为该内存而杀掉游戏或应用。 Loading.UpdatePreloading 这是Unity引擎最主要的加载函数。该项一般在切换场景时或主动动态加载资源时较大。 一般来说，加载资源越多、越复杂，则其反映的Loading.UpdatePreloading耗时则越大。 Profiler中Not Saved是指什么？ Profiler中的Not Saved指的是项目中通过代码生成的各种资源记录。如上图所示，其Mesh均为NGUI插件通过脚本生成的UI界面Mesh资源。 脚本判断怪物是否在相机视野范围有没有什么好方法？ 可以在脚本中添加 OnWillRenderObject 或者 OnBecameVisible/OnBecameInvisible 的回调函数，这些函数分别会在对应的Renderer可见或者变为可见/不可见时被调用。 我们测试了下发现，在名为A的MonoBehaviour中，有个数组来存放名为B的 MonoBehaviour对象的引用。当我们其他的逻辑去Destroy了B对象所在的GameObject后，在A对象中的数组里，遍历打印，它们（B的引用）都为Null，在Inspector面板上看是missing。而这时候进行GC，堆内存其实并未释放这些B对象。只有当A对象中的数组被清空后，再调用GC，才可释放这些对象所占内存。这种现象是否正常？为什么值为Null但却还是被引用着，无法通过GC释放呢？ 首先这种现象是正常的。这是Unity中对Null的检测做了特殊的处理所致，在Unity中MonoBehaviour对象除了存在于Managed Heap中（作为“壳”），在Native内存中还会有一个相对应的“实体”，在调用Destroy时，真正被释放的正是这个“实体”。而在判断一个MonoBehaviour对象是否为Null时，Unity会首先检测“实体”是否已经被销毁，如果是则返回为true，但此时Managed Heap中的“壳”实际上依然是被引用的，从而就会出现对象的Null判断为true，但实际上还是被引用着，无法被GC释放的问题。. 相关的细节可见官方blog对Unity中Null判断的解释：http://blogs.unity3d.com/2014/05/16/custom-operator-should-we-keep-it/ PS：本周最佳收获。 粒子真机下关闭粒子使用的FBX的Read/Write Enable属性后crash，Editor模式下没有。 将FBX上的Read/Write Enabled关闭后，内存中便不再保存其Mesh的副本（只存在显存中），因此其属性就不可再被访问和修改。 粒子系统通常需要动态地修改其粒子的顶点属性。因此，理论上来说，供粒子系统使用的Mesh是需要开启Read/Write Enabled的，而在Editor下Mesh和Texture都是强制开启的，所以在真机上就会出现问题。 粒子的优化 减量。总的来说就是减少粒子的数量，减少粒子的范围，如果离摄像机远可以考虑不显示粒子。最后升级到5.3之后，因为粒子系统有优化。 粒子系统拼合。是指引擎会将若干个材质相同且深度相同的粒子系统在渲染前进行合批（Batch），从而通过一个Draw Call来对其粒子系统进行渲染，进而降低粒子系统的渲染开销。至于合并机制之前也写到过。 粒子系统所使用的纹理并不是Sprite类型的，因此不需要设置Packing Tag。模型&amp;动画SkinnedMeshRenderer.BakeMesh这个函数一般是什么时候调用呢?在Instantiate后调用么？ SkinnedMeshRenderer.BakeMesh 的作用在于：将一个蒙皮动画的某个时间点上的动作，Bake成一个不带蒙皮的Mesh，从而可以通过自定义的采样间隔，将一段动画转成一组Mesh序列帧。而后在播放动画时只需选择最近的采样点（即一个Mesh）进行赋值即可，从而省去了骨骼更新与蒙皮计算的时间。 该方法的优点是用内存换计算时间，在场景中大量出现同一个带动画的模型时，效果会非常明显。该方法的缺点是内存的占用极大地受到模型顶点数、动画总时长及采样间隔的限制。因此，该方法只适用于顶点数较少，且动画总时长较短的模型。同时，Bake的时间较长，因此需要在加载场景时完成。比较经典的适用场景为MOBA游戏中的小兵。 PS：关于skinnedmesh转mesh这个问题比较大，可以参考网上的资源。 为什么尽可能使用Mecanim Mecanim动画系统的多线程计算性能较之老版本的单线程计算性能要高； Mecanim动画系统可以对GameObject开启 “Optimize Game Object” 选项。该选项为Unity引擎在4.3版本中加入的新功能，旨在优化Mecanim动画系统的底层计算开销。开启该选项，Animator.Update和MeshSkinning.Update的CPU占用均存在一定程度的降低； Mecanim动画系统的Retargeting功能可以让多个不同的角色使用同一套的AnimationClip资源，比如主城中的NPC角色，其大部分共性动画可尝试使用一套Idle、Wave等动画片段，从而进一步降低动画资源的内存开销； Unity引擎已经不再对老版本动画系统进行维护。 动画的优化 动画模块的开销主要来自于MeshSkinning.Update（蒙皮网格每帧更新）和Animation.Update and Animator.Update（骨骼动画的更新开销）两个函数。 研发团队在尽可能保证动画效果的同时，对模型的网格进行简化，建议尝试使用Unity Asset Store中的SimpleLOD插件来对骨骼蒙皮网格进行简化； 关于MeshSkinning.Update， 一般来说该值的大小取决于蒙皮网格（Skinned Mesh）的面片数和骨骼数。所以如果该值过高，我们的建议是减面。同时我们建议开发团队勾选“GameObject.Optimize”，该方法是将fbx生成的GameObject的层级关系移除，使动画系统不用每帧再去更新这些骨骼节点（GameObject）的Transform，因此能一定程度上降低CPU开销，此优化选项默认是关闭的），该方法特别适合于在配置较低的手机上运用骨骼角色多的情况。 开启Optimize GameObject默认情况下会将动画网格下的所有骨骼结点隐藏，但是，可以通过“Extra Transform to Expose”查看想通过脚本获取的骨骼结点，这样既可以提升该角色的动画模块性能，又可以达到获取某个关键结点的需求。 Optimize Game Objects对于老版本的Animation无效。 使用SkinnedMeshRenderer.BakeMesh 控制场景中具有Animator Controller组件的GameObject。 材质实例数量过多有何影响 Material的内存占用一般很小，所以大量的Material资源对于内存的压力其实很小的。 它本身对于场景的切换时间是有影响的，即资源冗余得越多，切换场景时，UnloadUnusedAssets的开销越大，进而增加了场景的切换时间。 会影响DrawCall的拼合。 物理Profiler中会碰到Static Collider.Move(Expensive delay cost)，有什么办法可以优化掉呢？ 建议给需要移动的静态Collider加上RigidBody并勾选is Kinematic复选框，从而将其变为动态碰撞体。 引起 Physics.Simulate 开销较大的几个因素 Rigidibody。 该组件可使得游戏对象在物理系统的控制下运动。 对于移动设备而言，建议Rigidibody数量控制在50以下。同时需要注意的是，大家常常会用Rigidbody组件配合CapsuleCollider，通过RigidBody.velocity来移动。这些会造成物理计算，特别是网格有很多Mesh Colider的时候，物理计算相当高。 因此，建议尽量用Transform.Position代替物理计算。如果大家的地形是凹凸不平又要有重力的表示，也可以用Navmesh去做，它所引起的工作量在于烘焙Navmesh，并且尽可能地贴合地表 ，但是可以完全不用物理计算。 Contacts &amp; Colider Contacts数量为碰撞对（Contact Pair）数量。任意两个发生碰撞的碰撞体都会产生一个“碰撞对”。 一般来说，Contacts数量越大，则表明碰撞物体的数量越多，即物理系统的CPU开销越大。 碰撞体数量（静态碰撞体和动态碰撞体两者）均控制在100以下，当然越低越好。 PS：动态碰撞体是指带有RigidBody的Collider，而静态碰撞体指不带有RigidBody的Collider。 NGUI减少物理计算 在NGUI界面打开后，往往会有Physics一下涨高的情况。这是因为NGUI为了实现点击事件的检测，在每个UI上都设有Rigidbody，所以当UI Widgets摆在同一深度并存在相互叠加的情况时，会造成较多不必要的Contacts。 定位到OntriggerXXX（如OntriggerEnter）消耗高 这种情况一般是在脚本中触发了其他的逻辑调用，例如在主角被碰撞从而受到伤害时，创建一个伤害数字的UI，这些均有些实例化的逻辑计算，当然这些也会算到Physics开销中。 渲染我用内建的Shader渲染场景，深度图里有内容。而用自己的Shader，取到的深度图什么都没有，都是1，什么原因导致的呢？我已经打开ZWrite了。 4.x中是靠depth buffer直接获取或者通过shader replacement来实现。 5.x后统一考ShadowCaster来实现。 Shader.Parse 和 Shader.CreateGpuProgram 到底是做什么的？他们什么时候执行？ Shader.Parse体现的是Shader的加载和解析， Shader.CreateGpuProgram 是将Shader传入GPU的一次提交，GPU驱动会对其进行编译，以适应于特定的设备或平台。在Unity 5.x版本中，Shader.Parse在Shader资源加载时进行执行，而 Shader.CreateGpuProgram在所在GameObject第一渲染时进行执行。","link":"/2017/09/04/2017-9-4-每天一点UWA：第六周/"},{"title":"每天一点UWA：第十九周","text":"AssetBundle在移动平台上打AssetBundle时，为了控制包体大小，会开启PlayerSettings中的Optimize Mesh Data，对网格文件使用范围比较多的资源有较好的优化效果。 然而这带来了一个问题，就是在部分使用网格的特效中，美术会对模型上一些顶点做特殊处理，以达到一种网格遮罩的效果，而这个设置需要用到网格的顶点色。然而在开启Optimize Mesh Data这一选项后，打出来包中Mesh上的顶点色会丢失。 请问有什么比较好的解决方法，既能使用此方法优化网格，又能保留网格的顶点色效果？ 一般来说，开启“Optimize Mesh Data”选项，引擎会在发布时遍历所有的网格数据，去除其多余数据，从而降低其数据量大小。需要注意的是，这里的“多余”数据是指Mesh数据中包含了渲染时Shader中所不需要的数据，即如果Mesh数据中含有Position、UV、Normal、Color、Tangent等顶点数据，但其渲染所用的Shader中仅需要Position、UV和Normal，则Mesh数据中的Color和Tangent则为“多余”数据，引擎在发布游戏时，会将这些数据自动去除。 开启这个选项是一把双刃剑。对于在Runtime情况下有更换Shader需求的Mesh，建议研发团队对其特别注意。如果Runtime时需要为某一个GameObject更换更为复杂、需要访问更多顶点属性的Shader，则建议先将这些Shader挂载在相应的Prefab上再进行发布，以免引擎去除Runtime时会使用到的网格数据。 对于运行时动态加载的普通模型比如怪物，我们目前的打包策略是把它单独打一个AssetBundle包，通过AssetBundle加载并实例化的消耗。如下图所示，对于WWW、AssetBundle、GameObject，卸载方法分别为WWW.Dispose、assetBundle.Unload、Destroy/DestoyImmediat。但对于通过AssetBundle加载出来的Assets资源， 这块的资源用什么策略清理合适？ 1）Resources.UnloadUnusedAssets，但该函数比较费时，一般只在切换场景时候使用； 2）assetBundle.Unload(true); 运行时Assetbundle在Instantiate prefab完成后也立即执行了unload(false)，所以也不适用； 对实例化出来的GameObject在使用后即使执行了DestroyImmediate，模型引用的贴图还驻留在内存中，难道要遍历GameObject使用的Assets分别执行UnloadAsset么？ 如果是仅加载Prefab，那么随Prefab一起加载进来的资源是不太方便被“优雅”地卸载的，即便是对应的GameObject被Destroy了，那么它对应的资源会变成“游离”状态（没有Refcount），只能等到手动调用Resources.UnloadUnusedAssets或场景切换时被引擎卸载。 所以，一般建议研发团队尝试通过依赖关系进行打包，将资源和Prefab进行分离，这样可以将加载资源和加载Prefab分开，从而可以通过“显式”地方式加载资源并将其进行储存，这样当你想精准释放资源时，则可以直接通过Resources.UnloadAsset来进行卸载。 PS: 这个问题本身就很有内容。 Audio将一个Unity 4.7.2的项目升级到Unity 5.5.3。打成安卓包，发现APK文件比之前大了200MB。然后分别对4.7.2打出来的APK包和5.5.3打出来的包分别进行解包，发现音频文件个数一样，但所占大小多了200MB左右，平均每个文件都大了几百KB。Unity 4.7.2的解包为Mp3格式，Unity 5.5.3的解包为Wav格式。 于是我在Unity 4.7.2和Unity 5.5.3下，分别新建一个空工程，将单独一个音频文件（ogg格式）放入Resources文件下，即两个Unity版本的空工程里只有一个Resources文件夹，文件夹里只有一个相同的Ogg格式音频文件，打成安卓包。使用解包工具解包，发现Unity 4.7.2的音频文件转成了mp3格式，大小几十kb；Unity 5.5.3的音频文件转成Wav格式，大小200多KB。 请问这种问题怎么解决？针对音频，Unity 4.x和Unity 5.x在打包过程中，作了那些修改？ 引用Unity 5.0的release note：https://unity3d.com/unity/whats-new/unity-5.0“Rewritten Audio asset pipeline and AudioClip backend.””Much improved audio formats in terms of memory and CPU usage.** The Format property no longer refers to a specific platform-specific file format, but to a encoding method** (Uncompressed, Compressed, ADPCM).” 可以看到，在Unity 5.x中，不同平台的音频不再与特定的文件格式关联，而是与文件编码关联。文件格式不等同于音频编码，虽然同是Wav格式的文件，但其有不同的编码方法（PCM，ADPCM，Vorbis，Wav也可以用mp3编码），编码方法会影响到Apk的大小。选定编码方式后降低quality和sample rate也会降低apk大小。 Font我们在iPhone5c上测试时发现Font.CacheFontForText会造成很严重的卡顿，看了UWA的Blog，了解到可能是因为创建FontTexture导致的开销。那是否可以认为如果我们一开始申请了足够大的Font Texture，后面即便有新的文字，开销也不会很大？ 如果可以这么做，一开始申请使用的字符串是根据自己项目生成一个字典，还是直接使用网上3、4千字的常用字库更好？ 是的，如果Font.CacheFontForText开销较大，那么在无法降低字体数量的情况下，一开始增大Font Texture是较为可行的方法。建议根据自己项目的字体来撑大Font Texture，避免不必要的浪费。 同时，也建议看一下这篇关于字体的精简优化方法。 GamePlay我想了解下如何获取物体的最小包围盒？Collider.bounds.size 获取的是与世界坐标系坐标轴平行的包围盒(AABB)，当物体旋转时包围盒大小会发生变化。那如何获取物体的OBB，使包围盒的大小不会随物体旋转而改变呢？ 获取 OBB 可以用 Mesh.bonuds(模型空间)。注意蒙皮Mesh这一类在Shader中修改顶点坐标的操作。 安卓客户端存在大量的模板数据需要配置，其中一些模板表甚至可能达到万级的数据条目，那么怎么对这些数据模板表进行打包和加载，可以兼顾加载速度和热更新表结构？一开始我们采用了ScriptableObject，把全部模板数据加载到内存并序列化为Asset的方式进行Assetbundle打包，该方案加载速度较为理想。但当我们通过Dll替换热更新安卓客户端时，发现这种方式不支持热更新，一旦Dll中修改了模板表结构，热更新替换后，ScriptableObject的AssetBundle就无法读取了，提示损坏的AssetBundle，目前的方案是采用Protobuf代替ScriptableObject进行序列化，可以实现热更新模板表结构，但是加载速度相对ScriptableObject有较大的差距，目前数据模板加载较慢便导致了玩家进入世界的时间比较久。因此想了解大家有什么好的建议呢？ 用ScriptableObject或者BinaryFormatter二进制存储然后反序列化成保存数据结构的对象，这两种方法应该是加载速度最快的。我们实际没有采取这个方案，也使用的是Protobuf，是出于以下考虑: 一份二进制数据，客户端和服务器可以通用。从服务器推数据很方便； 策划习惯使用Excel编辑，有脚本可以把表格内容导出成Protobuf的二进制数据，另外，还有.cs/.go表结构描述文件需要重点考虑。也就是说，策划修改表结构、增减表，服务器和客户端的结构描述文件可以自动生成好； 第一个问题：配置表存储格式现在主流的数据存储基本分为三大类，各有优劣，需要根据实际情况选择： ProtoBuf或类似序列化库，这种方式兼容性高，但是加载速度一般； 自己实现二进制数据存储，兼容性差，需要精心设计达到较高的数据表达能力； 采用Lua热更新方案的游戏，普遍直接把数据存储为Lua表。 第二个问题：配置表数据与代码兼容一般不建议大量修改数据结构，比如增删字段，如果实在无法避免，需要代码连同数据一起发布进行热更，做好版本管理即可。 第三个问题：配置读取速度优化 先从数据量上约减，减小数据冗余重复，数据存储设计优化，多次引用的字段多引用等等； 采用多线程加载，避免使用Unity提供的API，在游戏启动时，并行加载配置表，充分利用多核优势； 就我们自己项目而言，没有使用Lua的更新方案，但是我们依然采用Lua作为了数据存储，经过优化后加载速度也不错，可以参考 LuaTableOptimizer。 MainCamera 渲染完场景后，在 Screen Depth Buffer 上记录了整个场景的深度信息。Camera2 在 MainCamera 后，将模型绘制到一个 RenderTexture 上，我想利用 Screen Depth Buffer + Camera2.RenderTexture.ColorBuffer 对 Camera2 绘制的内容进行深度剔除，这时 Unity 会提示 Screen Depth Buffer 和 RenderTexture.ColorBuffer 不能混用。这样的需求该怎么做呢？ 这是一个很有意思的问题，参考https://blog.uwa4d.com/archives/1945.html 请问怎么在inspector中显示Dictionary呢？ 例如： Public Dictionary&lt;string,string&gt; dict; Unity 无法序列化Dictionary类型，无法将其显示在inspector中。一个Workaround是将Dictionary的Key和Value拆到两个list中，list可以在Inspector中显示。利用API：ISerializationCallbackReceiver （https://docs.unity3d.com/ScriptReference/ISerializationCallbackReceiver.html 有示例代码）可以在序列化/反序列化时将Dictoionary中的内容与list内容同步。 Unity需要对float进行相等判定 Mathf.Approximately 通常UGUI中的Button点击事件在代码中是通过onClick.addListener()来添加的。而且这种按钮的点击事件通常只会执行一次，如果添加了多次就会出现点击一次、按钮调用多次的事件函数。如果该Button只会添加一种事件，可以通过引用来判断是否添加了重复事件，从而不再重复添加相同事件。但是如果Button添加了多种点击事件，那么引用的方式就无效了。C#中的Delegate中有一个函数GetInvocationListD()可以获取此委托中的事件列表，从而剔除相同事件。然而让人头痛的是，我查看了Button的API似乎并没有暴露出此Button添加了的事件列表，所以没有办法剔除相同事件。不知道是否有什么办法可以解决这个问题? onClick是一个ButtonClickedEvent对象，而ButtonClickedEvent的基类是UnityEventBase。UnityEventBase里有一个InvokableCallList对象，里面应该就存了事件列表，但这个是private的，可能只能尝试通过反射，去取里面的值来对比了。看上去并没有比较简便的方法。 可以考虑扩展下Button组件，封装一个AddUniqueListener的接口，保留一下已经onClick.addListener的UnityEvent，然后每次Add前都先和这些UnityEvent做个对比，没有重复再进行onClick.addListener。 如果场景中有大量物体，请问如何利用相机拾取获取不同范围内的物体？ 采用Physics.SphereCastAll函数来获取，类似下面这个场景： 在SphereCastAll这个API的参数中，第二radius可以控制获取半径，我们分别设置5和10的效果是这样的：radius=5： radius=10： 如下图，蓝色部分为Unity视图，绿色为Android图片，我现在需要把Unity蓝色区域透视或者去除，iOS上已经透视成功，但Android一直失败，Unity版本为5.5.2，大家有什么建议呢？ 只记录下方案 https://blog.uwa4d.com/archives/TechSharing_79.html 改变GUILayout中ScrollView滑动条宽度123456789101112GUIStyle gs = GUI.skin.verticalScrollbar;GUIStyle gs1 = GUI.skin.verticalScrollbarThumb; gs.fixedWidth = 30;gs1.fixedWidth = 30;......pos = GUILayout.BeginScrollView(pos);......GUILayout.EndScrollView();......gs.fixedWidth = 0;gs1.fixedWidth = 0; 我这边做了个测试，把场景中的物件进行StaticBatch，用Lightmap烘焙，并且在烘焙完记录每个物件Renderer的lightmapindex and offset，然后在运行中，我删除了生成的LightingData.Asset，自己设置了Lightmapsetting，并且恢复了每个物体Renderer的Lightmapindex and offset, 结果我发现烘焙出来的场景Lightmap还是不对的。我怀疑是不是LightingData.Asset 还记录了别的东西，想问问看UWA有没有什么经验呢？ 这个问题还是出在Static Batching上。经过测试我们发现如果去掉场景中物件的“Static Batching”标记，换成手动Batching，即采用StaticBatchingUtility.Combine的方式结果就正确了。 同时，我们发现使用LightingData.Asset时，开启Static Batching与不开启都正确，因此我们认为LightingData.Asset可能记录了与CombinedMesh有关的数据，导致如果仅仅使用gameobject的LightMap参数无法正确读取CombinedMesh的LightMap UV。另外一种可能是Unity的一个Bug。最后，我们建议采用上述手动Batching的方式，即可解决此问题。 当使用Linear设置时，UI上图片透明度等也跟着变化，出来的效果与美术人员的需求不一样。请问有什么办法可以让UI不使用Linear或者让UI可以在Linear影响下也正常呢？ 值记录下做法：https://blog.uwa4d.com/archives/2066.html Texture请问在iOS上，图集如何设置成PVRTC的格式呢？ 下图中的设置是否正确？ 图集的设置需要考虑到该图集的用法，如果是作为普通的Texture给3D物体用的，那么TextureType选择Texture，然后Format选择Compressed就可以，因为在iOS上，Unity会自动处理NPOT（把纹理拉伸为边长为2的幂次的正方形），并默认采用PVRTC。 设置之后可以看一下下方的预览面板，会直接显示PVRTC的；如果是给UGUI用，那不同情况下，设置又不一样了；如果是给NGUI用，可以按照问题中截图里的设置即可，最终再确认下预览图上是不是PVRTC。 LoadSubsAsync和LoadSubs加载SpriteData，我想请问一下： 如果先LoadTexture加载纹理再加载LoadSubs，或者LoadSubsAsync函数调用加载SpriteData，纹理是否会加载两次，以及性能如何呢？ 按照我的理解，LoadSubsAsync或者LoadSubs，它自身有Texture属性，我断点调试可以看到SpriteData内的Texture会随着SpriteData加载而出来。 LoadSub和LoadSubAsync是会同时加载Texture的。 而先Load再LoadSub，并不会造成冗余问题，所以Load过Texture后，LoadSub的耗时就很小了。 但如果Texture里的Sprite是打了图集的，那么LoadSub的时候还是会有个图集加载的耗时。 UIQ1：众所周知，UGUI中有个Canvas.sendWillRender()函数在View打开的时候很耗时，所以通常的做法是把View移出屏幕外，或者Canvas.group，或者Scale等类似的处理机制。这样虽然能解决SendWillRender()消耗过高的问题，但也会有新的问题出现： EventSystem.Update()。由于各个View都是Active的状态，所以这个函数底下的Graphic.GetDepth()消耗很大，而且又由于不止一个GraphicRaycaster组件，所以这个函数下面的List.Sort()消耗巨大，更何况是每帧都在耗。 还有一个函数ScrollRect.LateUpdate()，它的开销也很高。而如果将Scale设置成0，其消耗更大，这种情况下，我还是倾向于用回Active/Deactive的处理机制，因为就界面打开的时候会卡一下，而不至于影响总体的帧率。 界面的快速隐藏和显示，比较推荐的做法是： 把界面单独作为一个Canvas，并绑定一个相机，同时在绑定相机的Culling Mask中设置一个不渲染的Layer； 隐藏时，把Canvas移出相机范围，同时把Canvas的Layer改为不被渲染的Layer，禁用对应的GraphicRaycaster组件，把Canvas中所有的动态UI元素停止。 显示时，移回Canvas，改回Layer，激活GraphicRaycaster组件。 针对题主的问题1，禁用GraphicRaycaster组件后就没问题了，被禁用的GraphicRaycaster不会进行Raycast操作； 针对题主的问题2，ScrollRect.LateUpdate中会通过EnsureLayoutHasRebuilt提前触发Canvas.SendWillRenderCanvases()，所以实际上还是Canvas.SendWillRenderCanvases()的开销。Canvas.SendWillRenderCanvases()开销高，是因为用Scale改为0的方式会清除顶点信息，在Scale改回1的时候还是需要重新创建顶点信息，开销肯定还是很高的，所以不推荐用Scale改为0来隐藏复杂的UI界面。 UI界面勾选Static是会节省一部分性能，但是如果我移动了某个设置为Static界面下的元素，这个界面还算是静态的么? 还是等运动的元素停下来后的界面才算静态的? 如果是这样，是不是我全部界面都设置静态就好了? 如果题主所指的“勾选static”是指GameObject右上角的Static框，这个Static和UI是无关的，不会对UI有影响；如果是NGUI的UIPanel上的Static选项，勾上之后，子节点中的UI元素是无法移动的（即使改了Transform，其图标位置也不会更新）。 工具Profiler里Assets和Scene Memory的区别是什么？比如Mesh这一项，在Scene Memory的Mesh中看到的只有2个合并的Mesh：CombinedMesh(root: scene)，在Assets的Mesh里看到的有100多个，包括场景里的非合并Mesh，动态加载出来的角色Mesh等。并且Assets的Mesh中的某些点击后选择右边的Referenced By，在Hierarchy里会自动选中场景中的物体，怎么看也不像是单纯的模板，而是实例化出来的东西。 Resources.Load/Assetbundle.Load出来的ParticleSystem都是放Assets下的，可以认为是模板资源，并不在场景里。Instantiate出来的放在Scene Memory下，是出现在场景里的。 所以两边都有是正常的。 在Unity里资源至少分为两类： 一类是可以被引用的，比如Mesh、Texture，如果要渲染多个相同的Mesh，并不需要对Mesh实例化，只需要在场景里多创建几份MeshRenderer/MeshFilter去引用它即可。所以Assets下的Mesh不应该被认为是实例化出来的东西，这些Mesh仅仅是通过AsssetBundle.Load/Resources.Load加载出来的，只是被场景里的东西引用了； 但SceneMemory下的Mesh通常是通过new Mesh或者Instantiate创建的，这部分可以说是实例化出来的了，另外像CombinedMesh是Unity自己创建的，也可以算是实例化的。 另一类是不可被引用的，通常是组件资源，比如ParticleSystem，如果要渲染多个相同的ParticleSystem，就需要实例化多份出来，ParticleSystem的模板在Assets下，而实例化出来的在SceneMemory下。 我在Editor下测试， 前一帧Mono还是67.2MB，下一帧突然自己掉到了51.5MB。然而并没有gc.collect()调用，这Mono是为什么减少？因为有不明原因的减少，所以担心也有不明原因的增多。 如果题主是在Editor测的，这个Mono的回落就正常了。Editor本身（渲染窗口，处理交互事件等）就会造成内存分配，同时也会触发GC。 但默认情况下，Editor本身的开销在Profiler里是看不到的，除非题主点击一下“Profile Editor”。 点击之后，就可以看到Editor本身函数的耗时和GC的触发了。 模型&amp;动画场景中放置一动画物体，原先正常进行动画，修改了物体Hierarchy某结点的名称，然后动画就异常了。打开Animation Window，发现动画曲线变为Missing。把物体名称改回后又恢复正常。我的疑问是动画Curve是与物体名称绑定的吗？如果是，如何修改动画物体的名称呢？ anim文件里有节点路径的：比如：curve: serializedVersion: 2 m_Curve: time: 0 value: {x: -0.187, y: -0.003, z: 0.062} inSlope: {x: 0, y: 0, z: 0} outSlope: {x: 0, y: 0, z: 0} tangentMode: 0 time: 0.93333334 value: {x: -0.187, y: -0.003, z: 0.062} inSlope: {x: 0, y: 0, z: 0} outSlope: {x: 0, y: 0, z: 0} tangentMode: 0 m_PreInfinity: 2 m_PostInfinity: 2 m_RotationOrder: 4 path: Bip001/Bip001 Pelvis/Bip001 Spine/Bip001 Spine1/Bip001 Neck/Bip001 R Clavicle/Bip001 R UpperArm/Bip001 R Forearm/Bip001 R Hand/Bip001 R Finger1 Animation Curve与动画物体是名称绑定的（名称包含其Hierarchy的Path，除去Root）； Animation Window中可以修改Curve的绑定名，可以将其更新为改名后物体的Path； 如李先生所说Animation文件包含结点路径，可以“ForceText”后用文本工具来修改，比较方便； 平时研究动画系统的时候有几个不太明白的问题： BlendTree（不论1D或者2D） 在采样的时候，如果BlendTree内的AnimationClip的长度不同，那么输出的动画长度是可变的。不同的BlendTree参数会导致不同的BlendTree输出的动画长度。问题是BlendTree最终输出的动画长度是如何计算出来的？采样AnimationClip的时候，对于动画的TimeScale做了什么调整？ 图例：run是一个BlendTree2D，当它的参数Speed=300时，和Speed=900时的长度是不一样的。 2.Unity的BlendTree2D是如何根据两个动画参数确定该在哪几个AnimationClip中采样？这些AnimationClip各自的权重是多少？ 图例：当Direction=-19，Speed=777的时候，黄箭头所指的动画实际上是由红箭头所指的4个动画混合而成的。那么混合权重分别是多少？ 对于不同的Clip动画数据进行Blend时，Unity会把所有Clip的时间都归一化（展开为相同长度）后，再根据各个Clip的权重进行加权平均。 Blend后的时间长度与各Clip的权重相关，时间更接近权重大的Clip的时间（近似时间长度的加权平均）。BlendTree参数值用来决定当前Blend各Clip的权重值，参数不同导致权重不同，因此时间也就不同。参数值如何决定哪些Clip进行Blend，其权重则跟不同Clip的参数threshhold相关。 2D时在参数空间中根据（x,y)的坐标位置对临近的Clips进行插值。不同2D Blend 类型使用的插值方法不同，而插值方法的实现也就决定了各Clip的权重。对于插值算法可以参考这里提供的pdf：http://answers.unity3d.com/questions/1206428/how-weights-of-2d-blending-are-calculated.html 性能综合如下图，不理解ScriptMapper具体是什么，为什么会引用StandardShader，有什么办法可以彻底把StandardShader从内存里移除呢？ 这说明是有代码在索引这个Shader。建议题主尝试以下方法来定位Standard Shader的具体引用： 在游戏运行时遍历所有的GameObject或者Material，然后获取其所使用的Shader信息，查找跟“Standard”名称相对应的Shader，然后就可以定位它是出自哪个Material或GameObject。 上述方法应该适用于大部分情况，但无法适用于以下情况： Shader被加载后直接被缓存在代码脚本中； Shader是通过AssetBundle.LoadAll加载的； Shader通过Preload Shader加载的。 Unity对GameObject.active()这个底层具体做了什么？因为在优化项目的时候看见有些界面active()这个函数造成的开销比较高，我采取的办法是移除摄像机的范围，这是参照UWA以前文章找到的办法，但是我还是想知道Unity对Active底层具体做了哪些操作，否则会有点困惑。 至少SetActive后，如果GameObject被激活，那么会调用该GameObject和所有子GameObject上的所有组件的OnEnable函数。而各种不同的UI组件的OnEnable中也有各种不同的操作。 如果题主希望深入研究下，可以看一下NGUI或者UGUI的源码，OnEnable具体做了什么都可以看到。同时，针对UI界面而言，还会在同一帧里触发其他的相关函数，出现后续的开销，如UGUI里的SendWillRenderCanvases和NGUI里的UIPanel.LateUpdate。","link":"/2017/12/22/每天一点UWA：第十九周/"},{"title":"How I build games with Entitas 摘要","text":"这篇文章并不会讲解entitas的功能，作者在文章中主要谈了谈他如何利用entitas开发清晰、稳定和灵活的代码结构。这篇文章可以说是对于ECS的一种实践的总结，同时也是对于Entitas的使用总结。 文章会介绍如下的话题： 定义：数据、逻辑和视图层 维护它们彼此的独立 通过接口进行抽象 IOC 视图层抽象（视图和视图控制器） 定义 数据 Data：游戏的 状态 ，比如生命、存量、经验等。在entitas中这些数据存在于 Component 中。 逻辑 Logic：数据变化的规则，在我们的代码中可能就是一些常见的函数，这些函数在改变着数据。在entitas中表现为 Systems. 视图 View：实际上就是游戏状态的表现，比如渲染、动画、音频、UI等。在作者的example中就是 GameObjects 上的 MonoBehaviours。 服务 Service：ECS之外的功能，常见的就是寻路、物理、社会化分享等，在entitas的视角里面游戏引擎也是一种服务（entitas本质是与引擎无关的，这个需要对源码进行一些扩展，比如Math库就不能使用unity引擎相关的数据定义）。 输入Input：ECS外部的输入，比如键盘、鼠标、网络等。个人认为input对于ECS的影响是通过修改component数据来实现的，也就要求了外部是输入是可以操作部分system的，因为我们修改component是通过system。 架构 任何游戏的核心只是CPU中的数值模拟。每一个游戏都只是数据集合（游戏状态）的周期性变化（游戏逻辑）。逻辑 规定了数据变化的规则。 纯粹的数据模拟与游戏的却别在于，游戏中有外部的玩家，能够使用逻辑来改变游戏的状态。 随之而来的需求是游戏数据与玩家的通信，或者说交互。而这个交互就是视图层，表现为渲染actor到屏幕、播放音频、更新UI等。 以上是作者对于游戏中数据、逻辑的理解，可谓之醍醐灌顶。而下面的图可以说是对于ECS（Entitas）使用的最佳实践。 Action中的抽象 首先抽象是一个移除What you want to do和How you want to do之间耦合的过程。如何理解what和how，简单来说what就是interface，how就是implementation。 文章中使用了一个常见的例子，就是在开发中的使用log。当然一般来说我们会避免把Debug.Log方法在代码的各处使用，弊端显而易见。作者提出这个例子和角色控制器是为了提出一个很重要的思想 关注点分离（Separate your concerns），这个也是ECS的一个重要的作用。 那么entitas是如何实现关注点分离的呢？一般会使用LogMessageComponent (string message)和一个 用于处理它的ReactiveSystem。代码如下，以后需要修改实现时只要修改这个system就行了。本质就是一个功能交给一个system，和之前定义一个专门负责log的函数或者类是一个概念。entitas中需要输出log只需要创建一个LogEntity就好了。 123456789101112131415161718192021222324using UnityEngine;using Entitias; using System.Collections.Generic;// debug message component[Debug] public sealed class DebugLogComponent : IComponent { public string message;}// reactive system to handle messagespublic class HandleDebugLogMessageSystem : ReactiveSystem&lt;DebugEntity&gt; { // collector: Debug.Matcher.DebugLog // filter: entity.hasDebugLog public void Execute (List&lt;DebugEntity&gt; entities) { foreach (var e in entities) { Debug.Log(e.debugLog.message); e.isDestroyed = true; } }} 最后上面代码的弊端是依赖了unity API debug，除此之外如果这里的log功能比较复杂比如json解析、网络发送等时，就会需要更多的依赖甚至关联。如果画出UML可能惨目忍睹。为了解决这个问题作者提出了使用接口。这块其实就没啥特别的了，面向接口编程本身也是OOP里面重要的概念，在上面的图里面，只要不是在虚线框内的代码多数情况是OOP的。而外部代码与ECS代码的交互是基于接口的。 Interfaces by example 在这部分中作者使用大量的例子来展示如何在entitas中使用接口来解耦。对于上面的log功能来说设计出来的接口可能只需要一个方法LogMessage(string message)。 代码如下： 可以看出UnityDebugLogService和JsonLogService对应了不同的log需要。 123456789101112131415161718192021222324252627// the interface public interface ILogService { void LogMessage(string message);}// a class that implements the interfaceusing UnityEngine;public class UnityDebugLogService : ILogService { public void LogMessage(string message) { Debug.Log(message); }}// another class that does things differently but still implements the interfaceusing SomeJsonLib;public class JsonLogService : ILogService { string filepath; string filename; bool prettyPrint; // etc... public void LogMessage(string message) { // open file // parse contents // write new contents // close file }} 下面的代码展示了如何通过system的构造函数来注入interface，最后实现了system与interface的关联，但是不与具体实现产生依赖或关联。 123456789101112131415161718192021// the previous reactive system becomes public class HandleDebugLogMessageSystem : ReactiveSystem&lt;DebugEntity&gt; { ILogService _logService; // contructor needs a new argument to get a reference to the log service public HandleDebugLogMessageSystem(Contexts contexts, ILogService logService) { // could be a UnityDebugLogService or a JsonLogService _logService = logService; } // collector: Debug.Matcher.DebugLog // filter: entity.hasDebugLog public void Execute (List&lt;DebugEntity&gt; entities) { foreach (var e in entities) { _logService.LogMessage(e.DebugLog.message); // using the interface to call the method e.isDestroyed = true; } }} 下面的例子是一个较为复杂的IInputService，可以看到是对unity api的一个封装。 12345678910111213141516171819// interfacepublic interface IInputService { Vector2D leftStick {get;} Vector2D rightStick {get;} bool action1WasPressed {get;} bool action1IsPressed {get;} bool action1WasReleased {get;} float action1PressedTime {get;} // ... and a bunch more}// (partial) unity implementationusing UnityEngine;public class UnityInputService : IInputService { // thank god we can hide this ugly unity api in here Vector2D leftStick {get {return new Vector2D(Input.GetAxis('horizontal'), Input.GetAxis('Vertical'));} } // you must implement ALL properties from the interface // ... } 12345678910111213141516171819202122232425262728public class EmitInputSystem : IInitalizeSystem, IExecuteSystem { Contexts _contexts; IInputService _inputService; InputEntity _inputEntity; // contructor needs a new argument to get a reference to the log service public EmitInputSystem (Contexts contexts, IInputService inputService) { _contexts = contexts; _inputService= inputService; } public void Initialize() { // use unique flag component to create an entity to store input components _contexts.input.isInputManger = true; _inputEntity = _contexts.input.inputEntity; } // clean simple api, // descriptive, // obvious what it does // resistant to change // no using statements public void Execute () { inputEntity.isButtonAInput = _inputService.button1Pressed; inputEntity.ReplaceLeftStickInput(_inputService.leftStick); // ... lots more queries }} Inversion of control 控制反转 这部分是对上面构造函数的进一步升级，无需在每个system的构造函数中注入服务实例，而是在entitas中使用一个helper类来引用每个服务实例。这个引入的时机最好是应用启动时。下面的例子是完整的过程。 可以看到下面是一个关联了很多service的类，通过构造函数注入实例。特别注意一下暴露出的全局变量都是只读的。 Services.cs 1234567891011121314151617181920212223public class Services{ public readonly IViewService View; public readonly IApplicationService Application; public readonly ITimeService Time; public readonly IInputService Input; public readonly IAiService Ai; public readonly IConfigurationService Config; public readonly ICameraService Camera; public readonly IPhysicsService Physics; public Services(IViewService view, IApplicationService application, ITimeService time, IInputService input, IAiService ai, IConfigurationService config, ICameraService camera, IPhysicsService physics) { View = view; Application = application; Time = time; Input = input; Ai = ai; Config = config; Camera = camera; Physics = physics; }} 实例化Services类 1234567891011var _services = new Services( new UnityViewService(), // responsible for creating gameobjects for views new UnityApplicationService(), // gives app functionality like .Quit() new UnityTimeService(), // gives .deltaTime, .fixedDeltaTime etc new InControlInputService(), // provides user input // next two are monobehaviours attached to gamecontroller GetComponent&lt;UnityAiService&gt;(), // async steering calculations on MB GetComponent&lt;UnityConfigurationService&gt;(), // editor accessable global config new UnityCameraService(), // camera bounds, zoom, fov, orthsize etc new UnityPhysicsService() // raycast, checkcircle, checksphere etc.); 下面的代码是一个不错的方法，使用一个特别的context（MetaContext）中的component中包含这些服务实例。注意这个component是单例的。 In my MetaContext I have a set of unique components that hold instances of these interfaces. For example: 1234[Meta, Unique]public sealed class TimeServiceComponent : IComponent { public ITimeService instance;} 下面的两段代码演示了如何将services中包含各个实例引入到ecs系统中。 首先上面一步已经创建了一些负责持有这些service实例的component，并且是singleton的。 使用 Feature来创建一些IInitializeSystem。Feature继承自system，但是从它包含了多个system。这个命名在我看来是极具深意的，因为只有多个system的协作才能形成一个特征（feature）。同时feature在执行顺序上非常靠前会先执行。 在各个IInitializeSystem类中注入service 在system会创建第一步中的component实例，并将service实例赋值进component的成员变量中。 ServiceRegistrationSystems.cs 123456789101112131415public class ServiceRegistrationSystems : Feature{ public ServiceRegistrationSystems(Contexts contexts, Services services) { Add(new RegisterViewServiceSystem(contexts, services.View)); Add(new RegisterTimeServiceSystem(contexts, services.Time)); Add(new RegisterApplicationServiceSystem(contexts, services.Application)); Add(new RegisterInputServiceSystem(contexts, services.Input)); Add(new RegisterAiServiceSystem(contexts, services.Ai)); Add(new RegisterConfigurationServiceSystem(contexts, services.Config)); Add(new RegisterCameraServiceSystem(contexts, services.Camera)); Add(new RegisterPhysicsServiceSystem(contexts, services.Physics)); Add(new ServiceRegistrationCompleteSystem(contexts)); }} Example of one of the registration systems 12345678910111213141516public class RegisterTimeServiceSystem : IInitializeSystem{ private readonly MetaContext _metaContext; private readonly ITimeService _timeService; public RegisterTimeServiceSystem(Contexts contexts, ITimeService timeService) { _metaContext = contexts.meta; _timeService = timeService; } public void Initialize() { _metaContext.ReplaceTimeService(_timeService); }} 下面的代码是entitas中ReplaceComponent的源码，可以看到如果没有某个component对象时会创建一个。 123456789101112131415161718/// Replaces an existing component at the specified index/// or adds it if it doesn't exist yet./// The prefered way is to use the/// generated methods from the code generator.public void ReplaceComponent(int index, IComponent component) { if (!_isEnabled) { throw new EntityIsNotEnabledException( \"Cannot replace component '\" + _contextInfo.componentNames[index] + \"' on \" + this + \"!\" ); } if (HasComponent(index)) { replaceComponent(index, component); } else if (component != null) { AddComponent(index, component); }} 经过上面的处理，在system中使用_contexts.meta.timeService.instance就能够获得一个service的实例了。这些实例都是在service的构造函数中创建的，便于管理和替换。 至于此处IOC的理解，可以回到上面的那个图。中间虚线框内可以认为是一个ECS framework，我们只向framework注入service实现，但是如何使用是framework内部的事情。这种把控制权交给一个framework的做法就是控制反转。 View Layer Abstraction 视图层抽象 这部分是上面图中的右边部分，描述了如何将entitas系统与表现层结合一起。 需要注意的是，GameObject的实例是被一个ViewComponent持有的。这个和service是一样的，也就是说ECS系统之外的对象都可以让一个特别的component持有引用。不过需要通过使用interface，将entitas与引擎API进行了解耦。 在这里的View layer用于游戏状态的展示，可以是动画、音频、mesh、渲染器等等。当然也可以是GameObject，或者GameObject上的一个MonoBehaviour对象。 下面是这部分功能的代码，看起来比较零散，做了个UML的图可以便于理解。 UML图中左边是一个用于创建GameObject的service，中间是entity、system等entitas内容，右边是view层的实现。完美符合开始的那张图。 1234567891011121314151617181920212223242526272829303132333435public interface IViewController { Vector2D Position {get; set;} Vector2D Scale {get; set;} bool Active {get; set;} void InitializeView(Contexts contexts, IEntity Entity); void DestroyView();}``` - IViewController的unity实现:```csharppublic class UnityGameView : MonoBehaviour, IViewController { protected Contexts _contexts; protected GameEntity _entity; public Vector2D Position { get {return transform.position.ToVector2D();} set {transform.position = value.ToVector2();} } public Vector2D Scale // as above but with tranform.localScale public bool Active {get {return gameObject.activeSelf;} set {gameObject.SetActive(value);} } public void InitializeView(Contexts contexts, IEntity Entity) { _contexts = contexts; _entity = (GameEntity)entity; } public void DestroyView() { Object.Destroy(this); }} 持有viewController的component 1234[Game]public sealed class ViewComponent : IComponent { public IViewController instance;} 使用IViewService来创建view，并且绑定到entitas 1234public interface IViewService { // create a view from a premade asset (e.g. a prefab) IViewController LoadAsset(Contexts contexts, IEntity entity, string assetName);} service的unity实现 123456789public class UnityViewService : IViewService { public IViewController LoadAsset(Contexts contexts, IEntity entity, string assetName) { var viewGo = GameObject.Instantiate(Resources.Load&lt;GameObject&gt;(\"Prefabs/\" + assetName)); if (viewGo == null) return null; var viewController = viewGo.GetComponent&lt;IViewController&gt;(); if (viewController != null) viewController.InitializeView(contexts, entity); return viewController; }} LoadAssetSystem用于加载资源（创建view）和绑定view到component 1234567891011121314151617181920public class LoadAssetSystem : ReactiveSystem&lt;GameEntity&gt;, IInitializeSystem { readonly Contexts _contexts; readonly IViewService _viewService; // collector: GameMatcher.Asset // filter: entity.hasAsset &amp;&amp; !entity.hasView public void Initialize() { // grab the view service instance from the meta context _viewService = _contexts.meta.viewService.instance; } public void Execute(List&lt;GameEntity&gt; entities) { foreach (var e in entities) { // call the view service to make a new view var view = _viewService.LoadAsset(_contexts, e, e.asset.name); if (view != null) e.ReplaceView(view); } }} 在其它的system中使用抽象的view实例。需要注意entitas中并不知道view对象到底是个什么，下面代码能够改变GameObject的position是因为IViewController中的定义。 123456789public class SetViewPositionSystem : ReactiveSystem&lt;GameEntity&gt; { // collector: GameMatcher.Position; // filter: entity.hasPosition &amp;&amp; entity.hasView public void Execute(List&lt;GameEntity&gt; entities) { foreach (var e in entities) { e.view.instance.Position = e.position.value; } }} 存在的问题 上面的最后一段代码中，当需要修改位置时是直接修改了view的position属性的，这与开始时描述的一个原则相违背。我们希望ECS中执行的就是数据与逻辑，不需要知道这些数据到底是如何表现出来的。但是现在我们在修改数据的同时也必须手动的修改view的position属性。下面的Event章节会来解决这个问题。 Events 事件 本质还是使用C#的事件功能 view MonoBehaviours作为事件监听器 下面是修改后的代码 首先需要给要监听的数据（component）添加Event标签，这个标签会在代码生成中生成监听器和事件系统。下面的代码会生成PositionListenerComponent 和 IPositionListener。文章作者写了个IEventListener，用来将监听器与entity绑定起来。 12345// [Game, Event(true)] (Event(true) DEPRECATED as of Entitas 1.6.0) [Game, Event(EventTarget.Self)] // generates events that are bound to the entities that raise thempublic sealed class PositionComponent : IComponent { public Vector2D value;} 123public interface IEventListener { void RegisterListeners(IEntity entity);} 不在需要viewcomponent，同时LoadAsset方法不需要在有返回值。然后需要在UnityViewService中添加一些代码来确定和初始化事件监听器。 12345678using Entitas;public interface IViewService { // create a view from a premade asset (e.g. a prefab) void LoadAsset( Contexts contexts, IEntity entity, string assetName);} 更新后的IViewService实现，前面还是生成GameObject，但是后面认为GameObject默认要有个实现了IEventListener的MonoBehaviour（这里单独写一个MonoBehaviour或者直接写在继承了IViewController的那个脚本中都可以），同时将监听器和entity绑定到一起。 1234567891011121314151617181920212223using UnityEngine;using Entitas;public class UnityViewService : IViewService { // now returns void instead of IViewController public void LoadAsset(Contexts contexts, IEntity entity, string assetName) { //Similar to before, but now we don't return anything. var viewGo = GameObject.Instantiate(Resources.Load&lt;GameObject&gt;(\"Prefabs/\" + assetName)); if (viewGo != null) { var viewController = viewGo.GetComponent&lt;IViewController&gt;(); if(viewController != null) { viewController.InitializeView(contexts, entity); } // except we add some lines to find and initialize any event listeners var eventListeners = viewGo.GetComponents&lt;IEventListener&gt;(); foreach(var listener in eventListeners) { listener.RegisterListeners(entity); } } }} 在PositionListener中实现接口。此处可以看出来一个viewGo上可以监听了多个数据变化的事件，每个事件都要绑定一次entity。 同时_entity.AddPositionListener(this);方法会把这个MonoBehaviour的引用交给_entity的PositionListenerComponent。当数据发送变化时，system会调用OnPosition方法，这些方法、接口都是添加了[Event]标签后自动生成的。 12345678910111213public class PositionListener : MonoBehaviour, IEventListener, IPositionListener { GameEntity _entity; public void RegisterEventListeners(IEntity entity) { _entity = (GameEntity)entity; _entity.AddPositionListener(this); } public void OnPosition(GameEntity e, Vector2D newPosition) { transform.position = newPosition.ToVector2(); }} 如此以来，GameObject的transform的改变就不需要system专门做什么处理了，view的position与ecs中的PositionComponent实现了解耦。 附加一些文中没有贴出来的代码，便于阅读 自动生成的PositionListener相关的代码 1234567public void AddPositionListener(IPositionListener value) { var listeners = hasPositionListener ? positionListener.value : new System.Collections.Generic.List&lt;IPositionListener&gt;(); listeners.Add(value); ReplacePositionListener(listeners);} AddPositionListener是在PositionListener中调用的，但是最后它会调用ReplacePositionListener，然后在ECS中创建一个PositionListenerComponent对象。 同时生成了一个PositionEventSystem 123456789101112131415161718192021222324252627282930public sealed class PositionEventSystem : Entitas.ReactiveSystem&lt;GameEntity&gt; { readonly System.Collections.Generic.List&lt;IPositionListener&gt; _listenerBuffer; public PositionEventSystem(Contexts contexts) : base(contexts.game) { _listenerBuffer = new System.Collections.Generic.List&lt;IPositionListener&gt;(); } protected override Entitas.ICollector&lt;GameEntity&gt; GetTrigger(Entitas.IContext&lt;GameEntity&gt; context) { return Entitas.CollectorContextExtension.CreateCollector( context, Entitas.TriggerOnEventMatcherExtension.Added(GameMatcher.Position) ); } protected override bool Filter(GameEntity entity) { return entity.hasPosition &amp;&amp; entity.hasPositionListener; } protected override void Execute(System.Collections.Generic.List&lt;GameEntity&gt; entities) { foreach (var e in entities) { var component = e.position; _listenerBuffer.Clear(); _listenerBuffer.AddRange(e.positionListener.value); foreach (var listener in _listenerBuffer) { listener.OnPosition(e, component.value); } } }} 附一个Event的时序图 总结 entitas配合面向接口编程&amp;Event，实现了数据+逻辑与表现层的解耦，同时解耦ECS与引擎。 需要注意的是，最开始的图是一个横向的，如果纵向的来看，Entitas是在底层，service和view是在上面的。也就是说后面两部分是可以直接持有entitas中的对象的，典型的就是Context、Entity等对象。而entitas则是通过interface、event等手段来操作service和view。 当然，较真来说，entitas其实也是持有了后两者的对象。这个目前看来是无法避免的。","link":"/2019/02/13/2019-2-13-How-I-build-games-with-Entitas-摘要/"},{"title":"JVM学习笔记1：概述","text":"JVM解决什么问题 JVM在我的理解与CLR是一回事，本身还是为了解决java代码无法直接编译为机器码。 对标C#，类型的动态推导等功能是在运行时做的，因此无法做到AOT。就需要虚拟机来做这个事情了。 如虚函数实现多态这样的情况，JVM中可以简单的获得当前应该调用哪个实现函数，从而优化代码的执行。 最后，使用虚拟机可以做到代码不考虑具体在哪个平台运行的问题，实现跨平台使用。 JVM的运行五个部分 Java 虚拟机将运行时内存区域划分为五个部分，分别为方法区、堆、PC 寄存器、Java 方法栈和本地方法栈。Java 程序编译而成的 class 文件，需要先加载至方法区中，方能在 Java 虚拟机中运行。 本质上所有的代码执行都是JVM构建栈帧，这个东西在C#、java、lua上都是一样的。 估计java的寄存器也是JVM自己的，而不是真正硬件的寄存器。 解释执行器和即时编译器（JIT） 前者对于字节码逐条编译为机器码，然后运行。 后者对于一个函数整体编译为机器码，然后运行。 HotSpot的执行 HotSpot 采用了多种技术来提升启动性能以及峰值性能，刚刚提到的即时编译便是其中最重要的技术之一。 即时编译建立在程序符合二八定律的假设上，也就是百分之二十的代码占据了百分之八十的计算资源。 对于占据大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。 JIT Hotspot中有C1、C2、Graal三个JIT编译器。 之所以引入多个即时编译器，是为了在编译时间和生成代码的执行效率之间进行取舍。C1 又叫做 Client 编译器，面向的是对启动性能有要求的客户端 GUI程序，采用的优化手段相对简单，因此编译时间较短。 C2 又叫做 Server 编译器，面向的是对峰值性能有要求的服务器端程序，采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的执行效率较高。 从 Java 7 开始，HotSpot 默认采用分层编译的方式：热点方法首先会被 C1 编译，而后热点方法中的热点会进一步被 C2 编译。","link":"/2019/03/13/2019-3-13-JVM学习笔记1：概述/"},{"title":"JVM学习笔记2：类型","text":"Boolean Java中的Boolean类型在JVM中映射为int类型。“true”被映射为整数 1，而“false”被映射为整数 0。因此，将原本声明为 boolean 类型的局部变量，赋值为除了 0、1 之外的整数值，在 Java 虚拟机看来是“合法”的。 对于存储 boolean 数组的字节码，Java 虚拟机需保证实际存入的值是整数 1 或者 0。 对于下面的代码来说，第一个if是true，第二个是false。因为第一个是在true是1的情况下，等于问的是“吃过几碗饭”，而第二个if是问“吃了一碗饭吗”。 1234567public class Foo { public static void main(String[] args) { boolean 吃过饭没 = 2; // 直接编译的话 javac 会报错 if (吃过饭没) System.out.println(\" 吃了 \"); if (true == 吃过饭没) System.out.println(\" 真吃了 \"); }} 其它类型 浮点 Java 的浮点类型采用 IEEE 754 浮点数格式。以 float 为例，浮点类型通常有两个 0，+0.0F 以及 -0.0F。前者在 Java 里是 0，后者是符号位为 1、其他位均为 0 的浮点数，在内存中等同于十六进制整数 0x8000000（即 -0.0F 可通过 Float.intBitsToFloat(0x8000000) 求得）。尽管它们的内存数值不同，但是在 Java 中 +0.0F == -0.0F 会返回真。 在有了 +0.0F 和 -0.0F 这两个定义后，我们便可以定义浮点数中的正无穷及负无穷。正无穷就是任意正浮点数（不包括 +0.0F）除以 +0.0F 得到的值，而负无穷是任意正浮点数除以 -0.0F 得到的值。在 Java 中，正无穷和负无穷是有确切的值，在内存中分别等同于十六进制整数 0x7F800000 和 0xFF800000。 [0x7F800001, 0x7FFFFFFF] 和 [0xFF800001, 0xFFFFFFFF] 对应的都是 NaN。 NaN 有一个有趣的特性：除了“!=”始终返回 true 之外，所有其他比较结果都会返回 false。举例来说，“NaN&lt;1.0F”返回 false，而“NaN&gt;=1.0F”同样返回 false。对于任意浮点数 f，不管它是 0 还是 NaN，“f!=NaN”始终会返回 true，而“f==NaN”始终会返回 false。 类型的大小 在 Java 虚拟机规范中，局部变量区等价于一个数组，并且可以用正整数来索引。除了 long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。 boolean、byte、char、short 这四种类型，在栈上占用的空间和 int 是一样的，和引用类型也是一样的。因此，在 32 位的 HotSpot 中，这些类型在栈上将占用 4 个字节；而在 64 位的 HotSpot 中，他们将占 8 个字节。 当然，这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。对于 byte、char 以及 short 这三种类型的字段或者数组单元，它们在堆上占用的空间分别为一字节、两字节，以及两字节，也就是说，跟这些类型的值域相吻合。 栈上应该是为了方便的取得数据，因为都是int的话通过下标就可以得到变量的值了。 类型的存储于加载 当我们将一个 int 类型的值，存储到这些类型的字段或数组时，相当于做了一次隐式的掩码操作。举例来说，当我们把 0xFFFFFFFF（-1）存储到一个声明为 char 类型的字段里时，由于该字段仅占两字节，所以高两位的字节便会被截取掉，最终存入“\\uFFFF”。 Java 虚拟机的算数运算几乎全部依赖于操作数栈。也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。 对于 boolean、char 这两个无符号类型来说，加载伴随着零扩展。举个例子，char 的大小为两个字节。在加载时 char 的值会被复制到 int 类型的低二字节，而高二字节则会用 0 来填充。 对于 byte、short 这两个类型来说，加载伴随着符号扩展。举个例子，short 的大小为两个字节。在加载时 short 的值同样会被复制到 int 类型的低二字节。如果该 short 值为非负数，即最高位为 0，那么该 int 类型的值的高二字节会用 0 来填充，否则用 1 来填充。","link":"/2019/03/15/2019-3-15-JVM学习笔记2：类型/"},{"title":"JVM学习笔记3：类加载","text":"知识点 基本步骤：经过加载、链接以及初始化三大步骤。其中，链接过程中同样需要验证；而内存中的类没有经过初始化，同样不能使用。 引用类型与CLR基本一致，泛型会被编译为特定类型的代码。类和接口是字节码。数组类是由 Java 虚拟机直接生成的，这个似乎没有CLR中对标的东西。 加载用的字节流可以来自java编译后的class，也可以是网络比如网页中内嵌的小程序 Java applet。字节流我理解就是IL，而且从结果看也确实就是这个东西。 结论 加载器通加载字节流创建类 链接过程是把类合并到JVM，验证和准备是必须的，解析不是必须的。解析是一个符号引用到对象引用的转换过程。 初始化只执行一次，干两件事： 常来字段赋值 调用clinit函数 加载 通过类加载器来查找字节流 启动类加载器（boot class loader）：启动类加载器是由 C++ 实现的，没有对应的 Java 对象，因此在 Java 中只能用 null 来指代。 除了启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。 双亲委派模型：每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。 C++启动一个java的加载器，然后java内部开始自加载，没毛病。 在 Java 9 之前，启动类加载器负责加载最为基础、最为重要的类，比如存放在 JRE 的 lib 目录下 jar 包中的类（以及由虚拟机参数 -Xbootclasspath 指定的类）。除了启动类加载器之外，另外两个重要的类加载器是扩展类加载器（extension class loader）和应用类加载器（application class loader），均由 Java 核心类库提供。 扩展类加载器的父类加载器是启动类加载器。它负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）。 应用类加载器的父类加载器则是扩展类加载器。它负责加载应用程序路径下的类。（这里的应用程序路径，便是指虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径。）默认情况下，应用程序中包含的类便是由应用类加载器加载的。 Java 9 引入了模块系统，并且略微更改了上述的类加载器1。扩展类加载器被改名为平台类加载器（platform class loader）。Java SE 中除了少数几个关键模块，比如说 java.base 是由启动类加载器加载之外，其他的模块均由平台类加载器所加载。 支持自定义的类加载器 在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。即便是同一串字节流，经由不同的类加载器加载，也会得到两个不同的类。在大型应用中，我们往往借助这一特性，来运行同一个类的不同版本。 opps! 链接 是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。它可分为验证、准备以及解析三个阶段。 验证阶段的目的，在于确保被加载类能够满足 Java 虚拟机的约束条件。 准备阶段的目的，则是为被加载类的静态字段分配内存。Java 代码中对静态字段的具体初始化，则会在稍后的初始化阶段中进行。 除了分配内存外，部分 Java 虚拟机还会在此阶段构造其他跟类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表。 当一个class文件没有被加载到JVM之前，使用它其中内容的字节码实际使用的是一个符号引用，这个是有编译器生成的，包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。 解析阶段正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。） Java 虚拟机规范并没有要求在链接过程中完成解析。它仅规定了：如果某些字节码使用了符号引用，那么在执行这些字节码之前，需要完成对这些符号引用的解析。 初始化 在 Java 代码中，如果要初始化一个静态字段，我们可以在声明时直接赋值，也可以在静态代码块中对其赋值。 如果直接赋值的静态字段被 final所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），是虚拟机来初始化。其它的静态变量是一个名为clinit的函数来初始化。 类加载的最后一步是初始化，便是为标记为常量值的字段赋值，以及执行 &lt; clinit &gt; 方法的过程。Java 虚拟机会通过加锁来确保类的 &lt; clinit &gt; 方法仅被执行一次。 类的初始化何时会被触发呢？JVM 规范枚举了下述多种触发情况： 当虚拟机启动时，初始化用户指定的主类； 当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类； 当遇到调用静态方法的指令时，初始化该静态方法所在的类； 当遇到访问静态字段的指令时，初始化该静态字段所在的类； 子类的初始化会触发父类的初始化； 如果一个接口定义了 default方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化； 使用反射 API 对某个类进行反射调用时，初始化这个类； 当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。","link":"/2019/04/16/2019-4-16-JVM学习笔记3：类加载/"},{"title":"JVM学习笔记4：方法调用","text":"重载与重写 重载的方法在编译阶段完成识别，调用是根据参数声明类型选择重载方法。选择分三个阶段： 在不考虑对基本类型自动装拆箱（auto-boxing，auto-unboxing），以及可变长参数的情况下选取重载方法； 如果在第 1 个阶段中没有找到适配的方法，那么在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法； 如果在第 2 个阶段中没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法。 如果 Java 编译器在同一个阶段中找到了多个适配的方法，那么它会在其中选择一个最为贴切的，而决定贴切程度的一个关键就是形式参数类型的继承关系。 下面代码中第一次调用会是函数2，因为null可以匹配object和string，但是因为string是Object的子类，所以编译器认为string合适。 1234567void invoke(Object obj, Object... args) { ... }void invoke(String s, Object obj, Object... args) { ... } invoke(null, 1); // 调用第二个 invoke 方法invoke(null, 1, 2); // 调用第二个 invoke 方法invoke(null, new Object[]{1}); // 只有手动绕开可变长参数的语法糖， // 才能调用第一个 invoke 方法 子类中的方法如果满足重载的情况， 是可以与父类方法形成重载的。 子类中方法的定义与父类完全一样则是重写。 JVM 的静态绑定和动态绑定 Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符（method descriptor）。方法描述符，它是由方法的参数类型以及返回类型所构成。在同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在类的验证阶段报错。 Java 虚拟机中关于方法重写的判定同样基于方法描述符。也就是说，如果子类定义了与父类中非私有、非静态方法同名的方法，那么只有当这两个方法的参数类型以及返回类型一致，Java 虚拟机才会判定为重写。 由于对重载方法的区分在编译阶段已经完成，我们可以认为 Java 虚拟机不存在重载这一概念。因此，在某些文章中，重载也被称为静态绑定（static binding），或者编译时多态（compile-time polymorphism）；而重写则被称为动态绑定（dynamic binding）。 确切地说，Java 虚拟机中的静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。 具体来说，Java 字节码中与调用相关的指令共有五种。 invokestatic：用于调用静态方法。 invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。 invokevirtual：用于调用非私有实例方法。 invokeinterface：用于调用接口方法。 invokedynamic：用于调用动态方法。 对于 invokestatic 以及 invokespecial 而言，Java 虚拟机能够直接识别具体的目标方法。 而对于 invokevirtual 以及 invokeinterface 而言，在绝大部分情况下，虚拟机需要在执行过程中，根据调用者的动态类型，来确定具体的目标方法。 唯一的例外在于，如果虚拟机能够确定目标方法有且仅有一个，比如说目标方法被标记为final，那么它可以不通过动态类型，直接确定目标方法。 符号引用存储在 class 调用指令的符号引用 文件的常量池之中。根据目标方法是否为接口方法，这些引用可分为接口符号引用和非接口符号引用。 对于可以静态绑定的方法调用而言，实际引用是一个指向方法的指针。对于需要动态绑定的方法调用而言，实际引用则是一个方法表的索引。 虚方法调用 Java 里所有非私有实例方法调用都会被编译成 invokevirtual 指令 Java 虚拟机需要根据调用者的动态类型，来确定虚方法调用的目标方法。 如果虚方法调用指向一个标记为 final 的方法，那么 Java 虚拟机也可以静态绑定该虚方法调用的目标方法。 方发表 和C++的差不多 方法表满足两个特质：其一，子类方法表中包含父类方法表中的所有方法；其二，子类方法在方法表中的索引值，与它所重写的父类方法的索引值相同。 使用了方法表的动态绑定与静态绑定相比，仅仅多出几个内存解引用操作：访问栈上的调用者，读取调用者的动态类型，读取该类型的方法表，读取方法表中某个索引值所对应的目标方法。相对于创建并初始化 Java 栈帧来说，这几个内存解引用操作的开销简直可以忽略不计。 内联缓存 内联缓存是一种加快动态绑定的优化技术。 它能够缓存虚方法调用中调用者的动态类型，以及该类型所对应的目标方法。在之后的执行过程中，如果碰到已缓存的类型，内联缓存便会直接调用该类型所对应的目标方法。如果没有碰到已缓存的类型，内联缓存则会退化至使用基于方法表的动态绑定。 Java 虚拟机中的即时编译器会使用内联缓存来加速动态绑定。开始先采用的单态内联缓存，当碰到新的调用者时，如果其动态类型与缓存中的类型匹配，则直接调用缓存的目标方法。否则，Java 虚拟机将该内联缓存劣化为超多态内联缓存，在今后的执行过程中直接使用方法表进行动态绑定。 单态（monomorphic）指的是仅有一种状态的情况。 多态（polymorphic）指的是有限数量种状态的情况。二态（bimorphic）是多态的其中一种。 超多态（megamorphic）指的是更多种状态的情况。通常我们用一个具体数值来区分多态和超多态。在这个数值之下，我们称之为多态。否则，我们称之为超多态。","link":"/2019/04/27/2019-4-27-JVM学习笔记4：方法调用/"},{"title":"JVM学习笔记6：反射","text":"反射的实现 横向比对C#，几乎是是一样的 核心是invoke函数1234567891011public final class Method extends Executable { ... public Object invoke(Object obj, Object... args) throws ... { ... // 权限检查 MethodAccessor ma = methodAccessor; if (ma == null) { ma = acquireMethodAccessor(); } return ma.invoke(obj, args); }} 调用过程 如果打印stack trace可以看到西面的代码，从中可以看到java的反射本质是依次调用DelegatingMethodAccessorImpl、NativeMethodAccessorImpl，最后调用对象方法。 这个思路说白了就是在C++层面（native开头的API）查询到对象函数的地址，然后调用。 1234567891011121314151617181920212223import java.lang.reflect.Method; public class Test { public static void target(int i) { new Exception(&quot;#&quot; + i).printStackTrace(); } public static void main(String[] args) throws Exception { Class&lt;?&gt; klass = Class.forName(&quot;Test&quot;); Method method = klass.getMethod(&quot;target&quot;, int.class); method.invoke(null, 0); }}-------------------------------------------java.lang.Exception: #0 at Test.target(Test.java:5) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl .invoke0(Native Method) a t java.base/jdk.internal.reflect.NativeMethodAccessorImpl. .invoke(NativeMethodAccessorImpl.java:62) t java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.i .invoke(DelegatingMethodAccessorImpl.java:43) java.base/java.lang.reflect.Method.invoke(Method.java:564) t Test.main(Test.java:131 当多次调用（这个次数由Dsun.reflect.inflationThreshold决定）后，JVM会动态构建一个函数的字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Inflation。 123456java.lang.Exception: #16 at Test.target(Test.java:5) at jdk.internal.reflect.GeneratedMethodAccessor1 .invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl .invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:564) at Test.main(Test.java:12) 反射的开销外部消耗 从上面的实现可以看出，反射需要调用forName、getMethod等方法，这些方法调用本身就会产生消耗。Class.forName 会调用本地方法，Class.getMethod 则会遍历该类的公有方法。如果没有匹配到，它还将遍历父类的公有方法。 以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝。因此，我们应当避免在热点代码中使用返回 Method 数组的 getMethods 或者 getDeclaredMethods 方法，以减少不必要的堆空间消耗。 内部消耗 在invoke函数中需要传递一个object数组，这个是会产生内存消耗的。 同时，基础类型转object有装箱消耗。不过java会对[-128,127]之间的数字对应的Integer对象有cache。 还有java会做逃逸分析，也就是说下面代码中invoke函数中的object会被认为是不逃逸的，那么即时编译器可以选择栈分配甚至是虚拟分配，也就是不占用堆空间。 最后是内联函数的实现，由于 Java 虚拟机调用点的类型 profile（注：对于 invokevirtual 或者 invokeinterface，Java 虚拟机会记录下调用者的具体类型，我们称之为类型 profile）无法同时记录这么多个类，因此可能造成所测试的反射调用没有被内联的情况。可以提高 Java 虚拟机关于每个调用能够记录的类型数目（对应虚拟机参数 -XX:TypeProfileWidth，默认值为 2，这里设置为 3）。 1234567891011121314151617181920212223Import java.lang.reflect.Method; public class Test { public static void target(int i) { // 空方法 } public static void main(String[] args) throws Exception { Class&lt;?&gt; klass = Class.forName(&quot;Test&quot;); Method method = klass.getMethod(&quot;target&quot;, int.class); long current = System.currentTimeMillis(); for (int i = 1; i &lt;= 2_000_000_000; i++) { if (i % 100_000_000 == 0) { long temp = System.currentTimeMillis(); System.out.println(temp - current); current = temp; } method.invoke(null, 128); } }}","link":"/2019/06/06/2019-6-6-JVM学习笔记6：反射/"},{"title":"JVM学习笔记5：异常处理","text":"异常的分类 显式：主体是应用程序，它指的是在程序中使用“throw”关键字，手动将异常实例抛出。 隐式：主体则是 Java 虚拟机，它指的是 Java 虚拟机在执行过程中，碰到无法继续执行的异常状态，自动抛出异常。举例来说，Java 虚拟机在执行读取数组操作时，发现输入的索引值是负数，故而抛出数组索引越界异常（ArrayIndexOutOfBoundsException）。 异常的使用 和C#一样使用try-catch-finally语法 try中出异常执行catch，然后执行finally catch中出异常依旧走finally，但是最后还是会throw catch中的异常。 finally 代码块也触发了异常，那么只好中断当前 finally 代码块的执行，并往外抛异常。 catch用法与C#完全一样，可以定义多个catch块来监听不同的异常类型。同样，前面的 catch 代码块所捕获的异常类型不能覆盖后边的，否则编译器会报错。 catch也是会逐层去找的，也就是说一个函数如果没有catch到，那么会去到调用这个函数的代码块去找。理论上main加个catch应该可以hold住所有。 异常的JVM实现 从字节码角度看每个函数后面有一个异常处理表。 from 指针和 to 指针分别为 0 和 3，代表它的监控范围从索引为 0 的字节码开始，到索引为 3 的字节码结束（不包括 3）。该条目的 target 指针是 6，代表这个异常处理器从索引为 6 的字节码开始。条目的最后一列，代表该异常处理器所捕获的异常类型正是 Exception。 12345678910111213141516171819public static void main(String[] args) { try { mayThrowException(); } catch (Exception e) { e.printStackTrace(); }}// 对应的 Java 字节码public static void main(java.lang.String[]); Code: 0: invokestatic mayThrowException:()V 3: goto 11 6: astore_1 7: aload_1 8: invokevirtual java.lang.Exception.printStackTrace 11: return Exception table: from to target type 0 3 6 Class java/lang/Exception // 异常表条目 try-catch-finally的字节码。从这个代码中可以看到为何finally块会执行呢？就是因为finally块被嵌入到了try\\catch里面。 最后如果 下面这个图很形象的反应了代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Foo { private int tryBlock; private int catchBlock; private int finallyBlock; private int methodExit; public void test() { try { tryBlock = 0; } catch (Exception e) { catchBlock = 1; } finally { finallyBlock = 2; } methodExit = 3; }} $ javap -c Foo... public void test(); Code: 0: aload_0 1: iconst_0 2: putfield #20 // Field tryBlock:I 5: goto 30 8: astore_1 9: aload_0 10: iconst_1 11: putfield #22 // Field catchBlock:I 14: aload_0 15: iconst_2 16: putfield #24 // Field finallyBlock:I 19: goto 35 22: astore_2 23: aload_0 24: iconst_2 25: putfield #24 // Field finallyBlock:I 28: aload_2 29: athrow // catch块如果也异常了 30: aload_0 31: iconst_2 32: putfield #24 // Field finallyBlock:I 35: aload_0 36: iconst_3 37: putfield #26 // Field methodExit:I 40: return Exception table: from to target type 0 5 8 Class java/lang/Exception 0 14 22 any ... 需要注意的是如果catch块异常了，最后的finally捕获的是新异常。 语法糖1234567891011121314151617public class Foo implements AutoCloseable { private final String name; public Foo(String name) { this.name = name; } @Override public void close() { throw new RuntimeException(name); } public static void main(String[] args) { try (Foo foo0 = new Foo(\"Foo0\"); // try-with-resources Foo foo1 = new Foo(\"Foo1\"); Foo foo2 = new Foo(\"Foo2\")) { throw new RuntimeException(\"Initial\"); } }} 这个就是java版的using","link":"/2019/05/06/2019-5-6-JVM学习笔记5：异常处理/"},{"title":"JVM学习笔记8：Java对象的内存布局","text":"对象创建方式 6种方法创建对象，但是不同的方法对于实例字段的初始化是不同的: 直接复制已有的数据到实例化字段：Object.clone 方法和反序列化 没有初始化实例字段：Unsafe.allocateInstance 通过调用构造器来初始化实例字段： new 语句和反射机制 创建过程，以new为例：下面的代码本质还是mallco+init 12345// Foo foo = new Foo(); 编译而成的字节码 0 new Foo 3 dup 4 invokespecial Foo() 7 astore_1 如果一个类没有定义任何构造器的话， Java 编译器会自动添加一个无参数的构造器。 12345// Foo 类构造器会调用其父类 Object 的构造器public Foo(); 0 aload_0 [this] 1 invokespecial java.lang.Object() [8] 4 return 子类的构造器需要调用父类的构造器。如果父类存在无参数构造器的话，该调用可以是隐式的，也就是说 Java 编译器会自动添加对父类构造器的调用。但是，如果父类没有无参数构造器，那么子类的构造器则需要显式地调用父类带参数的构造器。 显式调用又可分为两种，一是直接使用“super”关键字调用父类构造器，二是使用“this”关键字调用同一个类中的其他构造器。无论是直接的显式调用，还是间接的显式调用，都需要作为构造器的第一条语句，以便优先初始化继承而来的父类字段。（不过这可以通过调用其他生成参数的方法，或者字节码注入来绕开。） 总而言之，当我们调用一个构造器时，它将优先调用父类的构造器，直至 Object 类。这些构造器的调用者皆为同一对象，也就是通过 new 指令新建而来的对象。 总结：通过 new 指令新建出来的对象，它的内存其实涵盖了所有父类中的实例字段。也就是说，虽然子类无法访问父类的私有实例字段，或者子类的实例字段隐藏了父类的同名实例字段，但是子类的实例还是会为这些父类实例字段分配内存的。 PS：似乎刷新了C# new中获得的知识，一直以为父类私有字段不会占有内存。 压缩指针 在 Java 虚拟机中，每个 Java 对象都有一个对象头（object header），这个由标记字段和类型指针所构成。其中，标记字段用以存储 Java 虚拟机有关该对象的运行数据，如哈希码、GC 信息以及锁信息，而类型指针则指向该对象的类。 PS：锁信息就是C#中的同步块索引，类型指针就是CLR的类类型（类型指针）。 在 64 位的 Java 虚拟机中，对象头的标记字段占 64 位，而类型指针又占了 64 位。也就是说，每一个 Java 对象在内存中的额外开销就是 16 个字节。以 Integer 类为例，它仅有一个 int 类型的私有字段，占 4 个字节。 为了尽量较少对象的内存使用量，64 位 Java 虚拟机引入了压缩指针的概念（对应虚拟机选项 -XX:+UseCompressedOops，默认开启），将堆中原本 64 位的 Java 对象指针压缩成 32 位的。这样一来，对象头中的类型指针也会被压缩成 32 位，使得对象头的大小从 16 字节降至 12 字节。标记阻断 PS:对象头中只有类型指针被压缩，但是标记头没有被压缩，所以是8+4。 被压缩的指针的寻址是以当前指针x2的方式来实现的，因此每个对象的地址都是偶数，进而引发了内存对齐 。对应虚拟机选项 -XX:ObjectAlignmentInBytes，默认值为 8。 默认情况下，Java 虚拟机堆中对象的起始地址需要对齐至 8 的倍数。如果一个对象用不到 8N 个字节，那么空白的那部分空间就浪费掉了。这些浪费掉的空间我们称之为对象间的填充（padding），padding的概念在多数语言中都有。 字段重排列 这是JVM为实现内存对齐而做出的策略 对应 Java 虚拟机选项 -XX:FieldsAllocationStyle，默认值为 1。 如果一个字段占据 C 个字节，那么该字段的偏移量需要对齐至 NC。这里偏移量指的是字段地址与对象的起始地址差值。 以 long 类为例，它仅有一个 long 类型的实例字段。在使用了压缩指针的 64 位虚拟机中，尽管对象头的大小为 12 个字节，该 long 类型字段的偏移量也只能是 16(2*8)，而中间空着的 4 个字节便会被浪费掉。 子类所继承字段的偏移量，需要与父类对应字段的偏移量保持一致。 对于使用了压缩指针的 64 位虚拟机，子类第一个字段需要对齐至 4N；而对于关闭了压缩指针的 64 位虚拟机，子类第一个字段则需要对齐至 8N。 实际上就是对应的32位和64位。 1234567891011121314151617181920212223242526272829303132333435363738class A { long l; int i；} class B extends A { long l; int i;}=========================# 启用压缩指针时，B 类的字段分布B object internals: OFFSET SIZE TYPE DESCRIPTION 0 4 (object header) 4 4 (object header) 8 4 (object header) 12 4 int A.i 0 16 8 long A.l 0 24 8 long B.l 0 32 4 int B.i 0 36 4 (loss due to the next object alignment) # 关闭压缩指针时，B 类的字段分布B object internals: OFFSET SIZE TYPE DESCRIPTION 0 4 (object header) 4 4 (object header) 8 4 (object header) 12 4 (object header) 16 8 long A.l 24 4 int A.i 28 4 (alignment/padding gap) 32 8 long B.l 40 4 int B.i 44 4 (loss due to the next object alignment) 伪共享、缓存行填充和CPU缓存 推荐看一下这篇文章《JAVA 拾遗 — CPU Cache 与缓存行》 伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的 CPU 缓存失效，造成的结果是访问效率降低。 Java 8 引入了一个新的注释 @Contended，用来解决对象字段之间的虚共享（false sharing）问题。它本质上还是对内存进行填充，从而避免数据出现在同一cache line中，需要开启-XX:-RestrictContended=false。","link":"/2019/07/09/2019-7-9-JVM学习笔记8：Java对象的内存布局/"},{"title":"JVM学习笔记7：invokedynamic","text":"问题的产生 在java中实现动态语言的能力 Java 7 引入了一条新的指令 invokedynamic。该指令的调用机制抽象出调用点这一个概念，并允许应用程序将调用点链接至任意符合条件的方法上作为 invokedynamic 的准备工作，Java 7 引入了更加底层、更加灵活的方法抽象 ：方法句柄（MethodHandle）。 方法句柄概念 方法句柄是一个强类型的，能够被直接执行的引用 。该引用可以指向常规的静态方法或者实例方法，也可以指向构造器或者字段。当指向字段时，方法句柄实则指向包含字段访问字节码的虚构方法，语义上等价于目标字段的 getter 或者 setter 方法。 方法句柄的类型（MethodType）是由所指向方法的参数类型以及返回类型组成的。它是用来确认方法句柄是否适配的唯一关键。当使用方法句柄时，我们其实并不关心方法句柄所指向方法的类名或者方法名。 上面这段话给我的总体感觉是方法句柄有点像函数指针。 方法句柄的使用 方法句柄的创建是通过 MethodHandles.Lookup 类来完成的。它提供了多个 API，既可以使用反射 API 中的 Method 来查找，也可以根据类、方法名以及方法句柄类型来查找。 调用方法句柄，和原本对应的调用指令是一致的。也就是说，对于原本用 invokevirtual 调用的方法句柄，它也会采用动态绑定；而对于原本用 invkespecial 调用的方法句柄，它会采用静态绑定。 下面这段代码中第二种方式就是完全按照方法签名来找出。 12345678910111213141516class Foo { private static void bar(Object o) { .. } public static Lookup lookup() { return MethodHandles.lookup(); }} // 获取方法句柄的不同方式MethodHandles.Lookup l = Foo.lookup(); // 具备 Foo 类的访问权限Method m = Foo.class.getDeclaredMethod(&quot;bar&quot;, Object.class);MethodHandle mh0 = l.unreflect(m); MethodType t = MethodType.methodType(void.class, Object.class);MethodHandle mh1 = l.findStatic(Foo.class, &quot;bar&quot;, t); 方法句柄同样也有权限问题。但它与反射 API 不同，其权限检查是在句柄的创建阶段完成的。在实际调用过程中，Java 虚拟机并不会检查方法句柄的权限。如果该句柄被多次调用的话，那么与反射调用相比，它将省下重复权限检查的开销。 方法句柄的操作invokeExact 需要严格匹配参数类型的 invokeExact。假设一个方法句柄将接收一个 Object 类型的参数，如果你直接传入 String 作为实际参数，那么方法句柄的调用会在运行时抛出方法类型不匹配的异常。正确的调用方式是将该 String 显式转化为 Object 类型。 方法句柄 API 有一个特殊的注解类 @PolymorphicSignature。在碰到被它注解的方法调用时，Java 编译器会根据所传入参数的声明类型来生成方法描述符，而不是采用目标方法所声明的描述符。 从下面的代码可以看到会生成两个不同的调用，string会出现异常。 123456789101112131415public void test(MethodHandle mh, String s) throws Throwable { mh.invokeExact(s); mh.invokeExact((Object) s); } // 对应的 Java 字节码 public void test(MethodHandle, String) throws java.lang.Throwable; Code: 0: aload_1 1: aload_2 2: invokevirtual MethodHandle.invokeExact:(Ljava/lang/String;)V 5: aload_1 6: aload_2 7: invokevirtual MethodHandle.invokeExact:(Ljava/lang/Object;)V 10: return 参数修改 需要自动适配参数类型，那么可以选取方法句柄的第二种调用方式 invoke。它同样是一个签名多态性的方法。invoke 会调用 MethodHandle.asType 方法。 方法句柄还支持增删改参数的操作，通过生成另一个方法句柄来实现的。其中，改操作就是 MethodHandle.asType 方法。删操作指的是将传入的部分参数就地抛弃，再调用另一个方法句柄。它对应的 API 是 MethodHandles.dropArguments 方法。 增加参数的操作会往传入的参数中插入额外的参数，再调用另一个方法句柄，它对应的 API 是 MethodHandle.bindTo 方法。Java 8 中捕获类型的 Lambda 表达式便是用这种操作来实现的。 句柄的实现1234567891011121314151617181920212223import java.lang.invoke.*; public class Foo { public static void bar(Object o) { new Exception().printStackTrace(); } public static void main(String[] args) throws Throwable { MethodHandles.Lookup l = MethodHandles.lookup(); MethodType t = MethodType.methodType(void.class, Object.class); MethodHandle mh = l.findStatic(Foo.class, &quot;bar&quot;, t); mh.invokeExact(new Object()); }}-------------------$ java -XX:+UnlockDiagnosticVMOptions -XX:+ShowHiddenFrames Foojava.lang.Exception at Foo.bar(Foo.java:5) at java.base/java.lang.invoke.DirectMethodHandle$Holder. invokeStatic(DirectMethodHandle$Holder:1000010) at java.base/java.lang.invoke.LambdaForm$MH000/766572210. invokeExact_MT000_LLL_V(LambdaForm$MH000:1000019) at Foo.main(Foo.java:12) Java 虚拟机会对 invokeExact 调用做特殊处理，调用至一个共享的、与方法句柄类型相关的特殊适配器中。这个适配器是一个 LambdaForm，我们可以通过添加虚拟机参数将之导出成 class 文件（-Djava.lang.invoke.MethodHandle.DUMP_CLASS_FILES=true）。 1234567891011121314final class java.lang.invoke.LambdaForm$MH000 { static void invokeExact_MT000_LLLLV(jeava.lang.bject, jjava.lang.bject, jjava.lang.bject); Code: : aload_0 1 : checkcast #14 //Mclass java/lang/invoke/ethodHandle : dup 5 : astore_0 : aload_32 : checkcast #16 //Mclass java/lang/invoke/ethodType 10: invokestatic I#22 // Method java/lang/invoke/nvokers.checkExactType:(MLjava/lang/invoke/ethodHandle,;Ljava/lang/invoke/ethodType);V 13: aload_0 14: invokestatic #26 I // Method java/lang/invoke/nvokers.checkCustomized:(MLjava/lang/invoke/ethodHandle);V 17: aload_0 18: aload_1 19: ainvakevirtudl #30 2 // Methodijava/lang/nvokev/ethodHandle.invokeBasic:(LLeava/lang/bject;;V 23 return PS：这段看着与C#的lambda表达式产生的结果极为类似，都是用一个class来包装一个函数的调用。OC也是类似的实现。 在这个适配器中，它会调用 Invokers.checkExactType 方法来检查参数类型，然后调用 Invokers.checkCustomized 方法。后者会在方法句柄的执行次数超过一个阈值时进行优化（对应参数 -Djava.lang.invoke.MethodHandle.CUSTOMIZE_THRESHOLD，默认值为 127）。最后，它会调用方法句柄的 invokeBasic 方法。 Java 虚拟机同样会对 invokeBasic 调用做特殊处理，这会将调用至方法句柄本身所持有的适配器中。这个适配器同样是一个 LambdaForm，你可以通过反射机制将其打印出来。 1234// 该方法句柄持有的 LambdaForm 实例的 toString() 结果DMH.invokeStatic_L_V=Lambda(a0:L,a1:L)=&gt;{ t2:L=DirectMethodHandle.internalMemberName(a0:L); t3:V=MethodHandle.linkToStatic(a1:L,t2:L);void} 这个适配器将获取方法句柄中的 MemberName 类型的字段，并且以它为参数调用 linkToStatic 方法。Java 虚拟机也会对 linkToStatic 调用做特殊处理，它将根据传入的 MemberName 参数所存储的方法地址或者方法表索引，直接跳转至目标方法。 1234final class MemberName implements Member, Cloneable {... //@Injected JVM_Method* vmtarget; //@Injected int vmindex; Invokers.checkCustomized：方法句柄一开始持有的适配器是共享的。当它被多次调用之后，Invokers.checkCustomized 方法会为该方法句柄生成一个特有的适配器。这个特有的适配器会将方法句柄作为常量，直接获取其 MemberName 类型的字段，并继续后面的 linkToStatic 调用。生成的字节码如下，可以看到最后的MemberName和linkToStatic。 1234567891011121314final class java.lang.invoke.LambdaForm$DMH000 { static void invokeStatic000_LL_V(java.lang.Object, java.lang.Object); Code: 0: ldc #14 // String CONSTANT_PLACEHOLDER_1 &lt;&lt;Foo.bar(Object)void/invokeStatic&gt;&gt; 2: checkcast #16 // class java/lang/invoke/MethodHandle 5: astore_0 // 上面的优化代码覆盖了传入的方法句柄 6: aload_0 // 从这里开始跟初始版本一致 7: invokestatic #22 // Method java/lang/invoke/DirectMethodHandle.internalMemberName:(Ljava/lang/Object;)Ljava/lang/Object; 10: astore_2 11: aload_1 12: aload_2 13: checkcast #24 // class java/lang/invoke/MemberName 16: invokestatic #28 // Method java/lang/invoke/MethodHandle.linkToStatic:(Ljava/lang/Object;Ljava/lang/invoke/MemberName;)V 19: return 总结 总体感觉是一个与反射类似的功能，用来通过非正常途径调用函数。。 invokedynamic invokedynamic 是 Java 7 引入的一条新指令，用以支持动态语言的方法调用。具体来说，它（指令）将调用点（CallSite）抽象成一个 Java 类，并且将原本由 Java 虚拟机控制的方法调用以及方法链接暴露给了应用程序。在运行过程中，每一条 invokedynamic 指令将捆绑一个调用点，并且会调用该调用点所链接的方法句柄。 生成调用点是在第一次调用 invokedynamic 指令时，Java 虚拟机会调用该指令所对应的启动方法（BootStrap Method）。 PS：方法句柄产生一个CallSite（调用点），然后被程序调用，实现方法的改变。 Lambda 表达式 java中的lambda是编译器将符合条件的接口辨认为函数式接口，利用 invokedynamic 指令来生成实现了函数式接口的适配器。 更加lambda是否捕获外部变量，产生的函数会不一样。 1234567891011121314151617181920int x = ..IntStream.of(1, 2, 3).map(i -&gt; i * 2).map(i -&gt; i * x);---------------------------// i -&gt; i * 2 private static int lambda$0(int); Code: 0: iload_0 1: iconst_2 2: imul 3: ireturn // i -&gt; i * x private static int lambda$1(int, int); Code: 0: iload_1 1: iload_0 2: imul 3: ireturn 如果 Lambda 表达式没有捕获其他变量，那么可以认为它是上下文无关的。因此，启动方法将新建一个适配器类的实例，并且生成一个特殊的方法句柄，始终返回该实例。 如果该 Lambda 表达式捕获了其他变量，那么每次执行该 invokedynamic 指令，我们都要更新这些捕获了的变量，以防止它们发生了变化。为了保证 Lambda 表达式的线程安全，我们无法共享同一个适配器类的实例。因此，在每次执行 invokedynamic 指令时，所调用的方法句柄都需要新建一个适配器类实例。 PS：如果与外部数据无关，那么就是线程安全的，因此只要有一份实例就够了。如果用了外部数据，为了保证每次调用数据都是新的，就需要不断的构建新的实例。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// i-&gt;i*2 对应的适配器类final class LambdaTest$$Lambda$1 implements IntUnaryOperator { private LambdaTest$$Lambda$1(); Code: 0: aload_0 1: invokespecial java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public int applyAsInt(int); Code: 0: iload_1 1: invokestatic LambdaTest.lambda$0:(I)I 4: ireturn} // i-&gt;i*x 对应的适配器类final class LambdaTest$$Lambda$2 implements IntUnaryOperator { private final int arg$1; private LambdaTest$$Lambda$2(int); Code: 0: aload_0 1: invokespecial java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iload_1 6: putfield arg$1:I 9: return private static java.util.function.IntUnaryOperator get$Lambda(int); Code: 0: new LambdaTest$$Lambda$2 3: dup 4: iload_0 5: invokespecial &quot;&lt;init&gt;&quot;:(I)V 8: areturn public int applyAsInt(int); Code: 0: aload_0 1: getfield arg$1:I 4: iload_1 5: invokestatic LambdaTest.lambda$1:(II)I 8: ireturn} 总结 lambda会被编译为类，类中包含了真正执行的方法，与C#一致。","link":"/2019/06/19/2019-6-19-JVM学习笔记7：invokedynamic/"},{"title":"JVM学习笔记9：垃圾回收","text":"引用计数法与可达性分析 引用计数没啥可说的，就是对堆中的对象记录有多少对象来持有它。在我的理解中最多的应该还是变量来引用，还有如果是与native的代码交互，可能还有指针来持有。 可达性是用来解决互相引用问题的，这个算法的实质在于将一系列 GC Roots 作为初始的存活对象合集（live set），然后从该合集出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中，这个过程我们也称之为标记（mark）。最终，未被探索到的对象便是死亡的，是可以回收的。 那么什么是 GC Roots 呢？我们可以暂时理解为由堆外指向堆内的引用，一般而言，GC Roots 包括（但不限于）如下几种： Java 方法栈桢中的局部变量； 已加载类的静态变量； JNI handles； 已启动且未停止的 Java 线程。 PS：本质上对当前运行环境中所有可能持有对象的情况进行扫描，当发现没有堆中有对象不可达，那么就任务可以free。比如C持有A，AB形成了互引用。当C不在持有A了，AB虽然引用计数不为0，但是实际上已经不可达了。 弊端： 在多线程环境下，其他线程可能会更新已经访问过的对象中的引用，从而造成误报（将引用设置为 null）或者漏报（将引用设置为未被访问过的对象）。 误报并没有什么伤害，Java 虚拟机至多损失了部分垃圾回收的机会，相当于野指针。 漏报则比较麻烦，因为未被访问过的对象会被认为是未达，垃圾回收器就可能回收这个实际上仍被引用的对象内存，这就是空指针错误了。 Stop-the-world和安全点 CLR与传统JVM会在GC时停止其他非垃圾回收线程的工作，直到完成垃圾回收。 当 Java 虚拟机收到 Stop-the-world 请求，它便会等待所有的线程都到达安全点，才允许请求 Stop-the-world 的线程进行独占的工作。 安全点的初始目的并不是让其他线程停下，而是找到一个稳定的执行状态。在这个执行状态下，Java 虚拟机的堆栈不会发生变化。这么一来，垃圾回收器便能够“安全”地执行可达性分析。 比较常见的安全点: 当 Java 程序通过 JNI 执行本地代码时，如果这段代码不访问 Java 对象、调用 Java 方法或者返回至原 Java 方法，那么 Java 虚拟机的堆栈不会发生改变，也就代表着这段本地代码可以作为同一个安全点。 解释执行字节码、执行即时编译器生成的机器码和线程阻塞。 阻塞的线程由于处于 Java 虚拟机线程调度器的掌控之下，因此属于安全点。 其他几种状态则是运行状态，需要虚拟机保证在可预见的时间内进入安全点。否则，垃圾回收线程可能长期处于等待所有线程进入安全点的状态，从而变相地提高了垃圾回收的暂停时间。 对于解释执行来说，字节码与字节码之间皆可作为安全点。Java 虚拟机采取的做法是，当有安全点请求时，执行一条字节码便进行一次安全点检测。 执行即时编译器生成的机器码则比较复杂。由于这些代码直接运行在底层硬件之上，不受 Java 虚拟机掌控，因此在生成机器码时，即时编译器需要插入安全点检测，以避免机器码长时间没有安全点检测的情况。HotSpot 虚拟机的做法便是在生成代码的方法出口以及非计数循环的循环回边（back-edge）处插入安全点检测。 垃圾回收的三种方式清除（sweep） 把死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表（free list）之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。 优点：够简单 缺点：产生大量的内存碎片 压缩（compact） 把存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销。 优点：解决内存碎片 缺点：压缩算法性能开销 复制（copy） 把内存区域分为两等分，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针指向的内存区域中，并且交换 from 指针和 to 指针的内容。 优点：解决内存碎片 缺点：只有一半内存被使用，浪费。 JVM分代 Java 虚拟机将堆划分为新生代和老年代。其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区。 默认情况下，Java 虚拟机采取的是一种动态分配的策略（对应 Java 虚拟机参数 -XX:+UsePSAdaptiveSurvivorSizePolicy），根据生成对象的速率，以及 Survivor 区的使用情况动态调整 Eden 区和 Survivor 区的比例。 也可以通过参数 -XX:SurvivorRatio 来固定这个比例。但是需要注意的是，其中一个 Survivor 区会一直为空，因此比例越低浪费的堆空间将越高。 new的过程 每个线程可以向 Java 虚拟机申请一段连续的内存，比如 2048 字节，作为线程私有的 TLAB（Thread Local Allocation Buffer，对应虚拟机参数 -XX:+UseTLAB，默认开启）。线程创建的对象被存储在这个buffer中，如果buffer不够用了就申请新的内存。 线程申请内存的这个操作需要加锁，线程需要维护两个指针（实际上可能更多，但重要也就两个），一个指向 TLAB 中空余内存的起始位置，一个则指向 TLAB 末尾。 接下来的 new 指令，便可以直接通过指针加法（bump the pointer）来实现，即把指向空余内存位置的指针加上所请求的字节数。如果加法后空余内存指针的值仍小于或等于指向末尾的指针，则代表分配成功。否则，TLAB 已经没有足够的空间来满足本次新建操作。这个时候，便需要当前线程重新申请新的 TLAB。 Minor GC 当 Eden 区的空间耗尽Java 虚拟机便会触发一次 Minor GC，来收集新生代的垃圾。存活下来的对象，则会被送到 Survivor 区。 当发生 Minor GC 时，Eden 区和 from 指向的 Survivor 区中的存活对象会被复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，以保证下一次 Minor GC 时，to 指向的 Survivor 区还是空的。 Java 虚拟机会记录 Survivor 区中的对象一共被来回复制了几次。如果一个对象被复制的次数为 15（对应虚拟机参数 -XX:+MaxTenuringThreshold），那么该对象将被晋升（promote）至老年代。另外，如果单个 Survivor 区已经被占用了 50%（对应虚拟机参数 -XX:TargetSurvivorRatio），那么较高复制次数的对象也会被晋升至老年代。 PS：注意要么次数到了，要么达到一个阈值。 总而言之，当发生 Minor GC 时，应用了标记 - 复制算法，将 Survivor 区中的老存活对象晋升到老年代，然后将剩下的存活对象和 Eden 区的存活对象复制到另一个 Survivor 区中。理想情况下，Eden 区中的对象基本都死亡了，那么需要复制的数据将非常少，因此采用这种标记 - 复制算法的效果极好。 Minor GC 的另外一个好处是不用对整个堆进行垃圾回收。但是，它却有一个问题，那就是老年代的对象可能引用新生代的对象。也就是说，在标记存活对象的时候，我们需要扫描老年代中的对象。如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。 卡表 HotSpot 给出一项叫做卡表（Card Table）的技术，解决老年代引用新生代时，需要进行全堆扫描的问题。 该技术将整个堆划分为一个个大小为 512 字节的卡，并且维护一个卡表，用来存储每张卡的一个标识位。这个标识位代表对应的卡是否可能存有指向新生代对象的引用。如果可能存在，那么我们就认为这张卡是脏的。 在进行 Minor GC 的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的对象加入到 Minor GC 的 GC Roots 里。当完成所有脏卡的扫描之后，Java 虚拟机便会将所有脏卡的标识位清零。 由于 Minor GC 伴随着存活对象的复制，而复制需要更新指向该对象的引用。因此，在更新引用的同时，我们又会设置引用所在的卡的标识位。这个时候，我们可以确保脏卡中必定包含指向新生代对象的引用。 要保证每个可能有指向新生代对象引用的卡都被标记为脏卡，Java 虚拟机需要截获每个引用型实例变量的写操作，并作出对应的写标识位操作。在JIT生成的机器码中，则需要插入额外的逻辑。这也就是所谓的写屏障（write barrier，注意不要和 volatile 字段的写屏障混淆）。 总结 可以看到垃圾回收的一个演变的过程 一开始采用引用计数，产生互引用问题。 加入可达性的检查，有了GC ROOT的概念，产生多线程问题。 线程挂起，有了安全点的概念。 三种回收方式各有优缺点 对于堆对象采用分代的机制，结合回收方式有了Minor GC。 为了解决老年代引用新生代时GC效率的问题，加入了卡表。","link":"/2019/07/16/2019-7-16-JVM学习笔记9：垃圾回收/"},{"title":"JVM学习笔记10：内存模型","text":"概念 个人感觉这个内存模型的名称很让人迷惑，开始理解的模型是一个数据结构，但是明显这里的内存模型是一个套解决内存可见性和代码乱序执行的技术方案。 PS：《深入理解java虚拟机：jvm高级特性与最佳实践》中提到的：Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 解决什么问题 在多线程环境下，假设这两个方法分别跑在两个不同的线程之上，如果 Java 虚拟机在执行了任一方法的第一条赋值语句之后便切换线程，那么最终结果将可能出现（0，0）的情况。 造成这一情况的原因有三个，分别为即时编译器的重排序，处理器的乱序执行，以及内存系统的重排序。 后两种原因涉及具体的体系架构。 1234567891011int a=0, b=0; public void method1() { int r2 = a; b = 1;} public void method2() { int r1 = b; a = 2;} 即时编译器（和处理器）需要保证程序能够遵守 as-if-serial 属性。通俗地说，就是在单线程情况下，要给程序一个顺序执行的假象。即经过重排序的执行结果要与顺序执行的结果保持一致。 另外，如果两个操作之间存在数据依赖，那么即时编译器（和处理器）不能调整它们的顺序，否则将会造成程序语义的改变。 Java 内存模型与 happens-before 关系 happens-before 关系是用来描述两个操作的内存可见性的。如果操作 X happens-before 操作 Y，那么 X 的结果对于 Y 可见。 在同一个线程中，字节码的先后顺序（program order）也暗含了 happens-before 关系：在程序控制流路径中靠前的字节码 happens-before 靠后的字节码。然而，这并不意味着前者一定在后者之前执行。实际上，如果后者没有观测前者的运行结果，即后者没有数据依赖于前者，那么它们可能会被重排序。 PS：万恶的编译器优化 happens-before规则 （非常关键） 解锁操作 happens-before 之后（这里指时钟顺序先后）对同一把锁的加锁操作。 volatile 字段的写操作 happens-before 之后（这里指时钟顺序先后）对同一字段的读操作。前提是同一个线程中，不同线程不一定。 线程的启动操作（即 Thread.starts()） happens-before 该线程的第一个操作。 线程的最后一个操作 happens-before 它的终止事件（即其他线程通过 Thread.isAlive() 或 Thread.join() 判断该线程是否中止）。 线程对其他线程的中断操作 happens-before 被中断线程所收到的中断事件（即被中断线程的 InterruptedException 异常，或者第三个线程针对被中断线程的 Thread.interrupted 或者 Thread.isInterrupted 调用）。 构造器中的最后一个操作 happens-before 析构器的第一个操作。 happens-before 关系还具备传递性。如果操作 X happens-before 操作 Y，而操作 Y happens-before 操作 Z，那么操作 X happens-before 操作 Z。 解决可见性和编译器乱序问题的方法 volatile 字段 以上面的代码为例，比如说将 b 设置为 volatile 字段。假设 r1 能够观测到 b 的赋值结果 1。显然，这需要 b 的赋值操作在时钟顺序上先于 r1 的赋值操作。根据 volatile 字段的 happens-before 关系，我们知道 b 的赋值操作 happens-before r1 的赋值操作。 PS：上面这段话中的粗体部分很关键，还是要看执行顺序的。也就是说如果两个线程同时跑修改后的代码，先执行了method2，其实r1还是0。 12345678910111213int a=0;volatile int b=0; public void method1() { int r2 = a; b = 1;} public void method2() { int r1 = b; a = 2;} 下图是.NET中的处理方式，其实都是一样的。 Java 内存模型的底层实现 Java 内存模型是通过内存屏障（memory barrier）来禁止重排序的。 对于即时编译器来说，它会针对前面提到的每一个 happens-before 关系，向正在编译的目标方法中插入相应的读读、读写、写读以及写写内存屏障。 PS：在.NET中相当于在合适的位置调用MemoryBarrier方法。 这些内存屏障会限制即时编译器的重排序操作。以 volatile 字段访问为例，所插入的内存屏障将不允许 volatile 字段写操作之前的内存访问被重排序至其之后；也将不允许 volatile 字段读操作之后的内存访问被重排序至其之前。 即时编译器将根据具体的底层体系架构，将这些内存屏障替换成具体的 CPU 指令。以我们日常接触的 X86_64 架构来说，读读、读写以及写写内存屏障是空操作（no-op），只有写读内存屏障会被替换成具体指令。 volatile的实际效果 在 X86_64 架构上，只有 volatile 字段写操作之后的写读内存屏障需要用具体指令来替代。（HotSpot 所选取的具体指令是 lock add DWORD PTR [rsp],0x0，而非 mfence。） 该具体指令的效果，可以简单理解为强制刷新处理器的写缓存。写缓存是处理器用来加速内存存储效率的一项技术。 在碰到内存写操作时，处理器并不会等待该指令结束，而是直接开始下一指令，并且依赖于写缓存将更改的数据同步至主内存（main memory）之中。 强制刷新写缓存，将使得当前线程写入 volatile 字段的值（以及写缓存中已有的其他内存修改），同步至主内存之中。 由于内存写操作同时会无效化其他处理器所持有的、指向同一内存地址的缓存行，因此可以认为其他处理器能够立即见到该 volatile 字段的最新值。 锁，volatile 字段，final 字段与安全发布锁 在解锁时，Java 虚拟机同样需要强制刷新缓存，使得当前线程所修改的内存对其他线程可见。 锁操作的 happens-before 规则的关键字是同一把锁。也就意味着，如果编译器能够（通过逃逸分析）证明某把锁仅被同一线程持有，那么它可以移除相应的加锁解锁操作。 PS：即时编译后的 synchronized (new Object()) {}，可能等同于空操作，而不会强制刷新缓存。 PS2：例子就是多线程对资源进行抢占，用lock或者synchronized来做锁。synchronized的本质是成对出现的lock和unlock。第一个抢到的线程unlock后，下一个线程对同一个资源对象进行lock，此时前一个锁中的内存变化对后一个可见。 volatile volatile 字段可以看成一种轻量级的、不保证原子性的同步，其性能往往优于（至少不亚于）锁操作。然而，频繁地访问 volatile 字段也会因为不断地强制刷新缓存而严重影响程序的性能。 在 X86_64 平台上，只有 volatile 字段的写操作会强制刷新缓存。因此，理想情况下对 volatile 字段的使用应当多读少写，并且应当只有一个线程进行写操作。 volatile 字段的另一个特性是即时编译器无法将其分配到寄存器里。换句话说，volatile 字段的每次访问均需要直接从内存中读写。 PS：volatile变量不能被分配到寄存器中，但是计算还是加载到寄存器中来计算的。所谓的分配到寄存器中，可以理解为编译器将内存中的值缓存在寄存器中，之后一直用访问寄存器来代表对这个内存的访问的。假设我们要遍历一个数组，数组的长度是内存中的值。由于我们每次循环都要比较一次，因此编译器决定把它放在寄存器中，免得每次比较都要读一次内存。对于会更改的内存值，编译器也可以先缓存至寄存器，最后更新回内存即可。Volatile会禁止上述优化。 最后，volatile禁止了编译器的顺序优化。 final final 实例字段则涉及新建对象的发布问题。当一个对象包含 final 实例字段时，希望其他线程只能看到已初始化的 final 实例字段。因此，即时编译器会在 final 字段的写操作后插入一个写写屏障，以防某些优化将新建对象的发布（即将实例对象写入一个共享引用中）重排序至 final 字段的写操作之前。在 X86_64 平台上，写写屏障是空操作。 新建对象的安全发布（safe publication）问题不仅仅包括 final 实例字段的可见性，还包括其他实例字段的可见性。 发布问题 首先原子性指的是CPU指令的原子执行，一句高级代码后面是多个CPU指令，并不能保证原子性。 看似安全的双检锁由于编译器的优化，会先申请内存，然后把内存地址付给instance变量，在初始化对象。 在多线程的情况下，后面到来的线程可能会读到一个非空但是没有初始化的instance对象，导致运行出错。 对instance加了volatile关键字后，可以解决编译器优化导致的乱序问题，这样在发布的时候保证的是一个初始化后的对象。 PS：对标.NET里面的Interlock.Exchange()方法。 123456789101112public class Singleton { static Singleton instance; static Singleton getInstance(){ if (instance == null) { synchronized(Singleton.class) { if (instance == null) instance = new Singleton(); } } return instance; }} 总结一下： 总结来说：刷新内存、禁止编译优化就是volatile的作用，这解决了可见性与有序性两个问题。 也就是说第二段代码里面可以保证的是int r2 = a;在b = 1;之前执行。为啥会不在之前呢？因为这两句话完全没有依赖性，所以正常来说编译后谁先谁后都可以的。 PS：CLR via C#里这一段真的很有趣。","link":"/2019/08/23/2019-8-24-JVM学习笔记10：内存模型/"},{"title":"JVM学习笔记11：synchronized的实现","text":"synchronized作用于代码块与函数 当声明 synchronized 代码块时，编译而成的字节码将包含 monitorenter 和 monitorexit 指令。这两种指令均会消耗操作数栈上的一个引用类型的元素（也就是 synchronized 关键字括号里的引用），作为所要加锁解锁的锁对象。 12345678910111213141516171819202122232425262728public void foo(Object lock) { synchronized (lock) { lock.hashCode(); } } // 上面的 Java 代码将编译为下面的字节码 public void foo(java.lang.Object); Code: 0: aload_1 1: dup 2: astore_2 3: monitorenter 4: aload_1 5: invokevirtual java/lang/Object.hashCode:()I 8: pop 9: aload_2 10: monitorexit 11: goto 19 14: astore_3 15: aload_2 16: monitorexit 17: aload_3 18: athrow 19: return Exception table: from to target type 4 11 14 any 14 17 14 any 当用 synchronized 标记方法时，会看到字节码中方法的访问标记包括 ACC_SYNCHRONIZED。该标记表示在进入该方法时，Java 虚拟机需要进行 monitorenter 操作。而在退出该方法时，不管是正常返回，还是向调用者抛异常，Java 虚拟机均需要进行 monitorexit 操作。 12345678910111213public synchronized void foo(Object lock) { lock.hashCode(); } // 上面的 Java 代码将编译为下面的字节码 public synchronized void foo(java.lang.Object); descriptor: (Ljava/lang/Object;)V flags: (0x0021) ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=1, locals=2, args_size=2 0: aload_1 1: invokevirtual java/lang/Object.hashCode:()I 4: pop 5: return monitorenter 和 monitorexit 这里 monitorenter 和 monitorexit 操作所对应的锁对象是隐式的。对于实例方法来说，这两个操作对应的锁对象是 this；对于静态方法来说，这两个操作对应的锁对象则是所在类的 Class 实例。 关于 monitorenter 和 monitorexit 的作用，我们可以抽象地理解为每个锁对象拥有一个锁计数器和一个指向持有该锁的线程的指针。 关于 monitorenter 和 monitorexit 的作用，我们可以抽象地理解为每个锁对象拥有一个锁计数器和一个指向持有该锁的线程的指针。 当执行 monitorenter 时，如果目标锁对象的计数器为 0，那么说明它没有被其他线程所持有。在这个情况下，Java 虚拟机会将该锁对象的持有线程设置为当前线程，并且将其计数器加 1。 在目标锁对象的计数器不为 0 的情况下，如果锁对象的持有线程是当前线程，那么 Java 虚拟机可以将其计数器加 1，否则需要等待，直至持有线程释放该锁。 当执行 monitorexit 时，Java 虚拟机则需将锁对象的计数器减 1。当计数器减为 0 时，那便代表该锁已经被释放掉了。 之所以采用这种计数器的方式，是为了允许同一个线程重复获取同一把锁。举个例子，如果一个 Java 类中拥有多个 synchronized 方法，那么这些方法之间的相互调用，不管是直接的还是间接的，都会涉及对同一把锁的重复加锁操作。因此，我们需要设计这么一个可重入的特性，来避免编程里的隐式约束。 HotSpot 虚拟机中具体的锁实现重量级锁 重量级锁是 Java 虚拟机中最为基础的锁实现。在这种状态下，Java 虚拟机会阻塞加锁失败的线程，并且在目标锁被释放的时候，唤醒这些线程。 Java 线程的阻塞以及唤醒，都是依靠操作系统来完成的。 为了尽量避免昂贵的线程阻塞、唤醒操作，Java 虚拟机会在线程进入阻塞状态之前，以及被唤醒后竞争不到锁的情况下，进入自旋状态，在处理器上空跑并且轮询锁是否被释放。如果此时锁恰好被释放了，那么当前线程便无须进入阻塞状态，而是直接获得这把锁。 与线程阻塞相比，自旋状态可能会浪费大量的处理器资源。这是因为当前线程仍处于运行状况，只不过跑的是无用指令。它期望在运行无用指令的过程中，锁能够被释放出来。 自旋状态还带来另外一个副作用，那便是不公平的锁机制。处于阻塞状态的线程，并没有办法立刻竞争被释放的锁。然而，处于自旋状态的线程，则很有可能优先获得这把锁。 轻量级锁 多个线程在不同的时间段请求同一把锁，也就是说没有锁竞争。针对这种情形，Java 虚拟机采用了轻量级锁，来避免重量级锁的阻塞以及唤醒。 下图是openjdk wiki中的图，右边是不支持偏向锁的对象的加锁过程，左边是偏向锁的加锁过程。 轻量锁的执行过程 第一行： 对象头中的标记字段（mark word），它的最后两位便被用来表示该对象的锁状态。其中，00 代表轻量级锁，01 代表无锁（或偏向锁），10 代表重量级锁，11 则跟垃圾回收算法的标记有关。 第二行： 进行加锁操作时，Java 虚拟机会判断是否已经是重量级锁。如果不是，它会在当前线程的当前栈桢中划出一块空间，作为该锁的锁记录，并且将锁对象的标记字段（和锁对象的指针）复制到该锁记录中。PS：图中的record就是这个锁对象 然后，Java 虚拟机会尝试用 CAS（compare-and-swap）操作替换锁对象的标记字段。这里解释一下，CAS 是一个原子操作，它会比较目标地址的值是否和期望值相等，如果相等，则替换为一个新的值。 假设当前锁对象的标记字段为 X…XYZ（X…X其实就是前面的那些位数，这里只关注最后两位），Java 虚拟机会比较该字段是否为 X…X01。如果是，则替换为刚才分配的锁记录的地址。由于内存对齐的缘故，它的最后两位为 00。此时，该线程已成功获得这把锁，可以继续执行了。 至此完成了轻量锁的占用。 如果不是 X…X01，那么有两种可能。第一，该线程重复获取同一把锁。此时，Java 虚拟机会将锁记录清零（也就是用0替代原来存的标记字段和指针），以代表该锁被重复获取。PS：图中的recursive lock PS:重复获取同一把锁的话，不是简单地清零，而应该是把0作为一条新的锁记录压入锁记录的栈顶。 第三行： 第二，其他线程持有该锁。此时，Java 虚拟机会将这把锁膨胀为重量级锁，并且阻塞当前线程。 解锁： 当进行解锁操作时，如果当前锁记录（你可以将一个线程的所有锁记录想象成一个栈结构，每次加锁压入一条锁记录，解锁弹出一条锁记录，当前锁记录指的便是栈顶的锁记录）的值为 0，则代表重复进入同一把锁，直接返回即可。PS：对应recursive lock 否则，Java 虚拟机会尝试用 CAS 操作，比较锁对象的标记字段的值是否为当前锁记录的地址。如果是，则替换为锁记录中的值，也就是锁对象原本的标记字段。此时，该线程已经成功释放这把锁。PS：对应正常的轻量锁 如果不是，则意味着这把锁已经被膨胀为重量级锁。此时，Java 虚拟机会进入重量级锁的释放过程，唤醒因竞争该锁而被阻塞了的线程。 偏向锁 如果说轻量级锁针对的情况很乐观，那么接下来的偏向锁针对的情况则更加乐观：从始至终只有一个线程请求某一把锁。 epoch值 JVM的每个类（类类型）中维护一个 epoch 值，可以理解为第几代偏向锁。当设置偏向锁时，Java 虚拟机需要将该 epoch 值复制到锁对象的标记字段中。 加锁过程 在线程进行加锁时，如果该锁对象支持偏向锁，那么 Java 虚拟机会通过 CAS 操作，将当前线程的地址记录在锁对象的标记字段之中，并且将标记字段的最后三位设置为 101。也就是图中右边的操作。 在接下来的运行过程中，每当有线程请求这把锁，Java 虚拟机只需判断锁对象标记字段中：最后三位是否为 101，是否包含当前线程的地址，以及锁对象类类型中的epoch 值是否和锁对象的类的 epoch 值相同。如果都满足，那么当前线程持有该偏向锁，可以直接返回。 当请求加锁的线程和锁对象标记字段保持的线程地址不匹配时（而且 epoch 值相等，如若不等，那么当前线程可以将该锁重偏向至自己），Java 虚拟机需要撤销该偏向锁。这个撤销过程非常麻烦，它要求持有偏向锁的线程到达安全点，再将偏向锁替换成轻量级锁。也就是图中revoke bias的过程。 如果某一类锁对象的总撤销数超过了一个阈值（对应 Java 虚拟机参数 -XX:BiasedLockingBulkRebiasThreshold，默认为 20），那么 Java 虚拟机会宣布这个类的偏向锁失效。 在宣布某个类的偏向锁失效时，Java 虚拟机实则将该类的 epoch 值加 1，表示之前那一代的偏向锁已经失效。而新设置的偏向锁则需要复制新的 epoch 值。 为了保证当前持有偏向锁并且已加锁的线程不至于因此丢锁，Java 虚拟机需要遍历所有线程的 Java 栈，找出该类已加锁的实例，并且将它们标记字段中的 epoch 值加 1。该操作需要所有线程处于安全点状态。 如果总撤销数超过另一个阈值（对应 Java 虚拟机参数 -XX:BiasedLockingBulkRevokeThreshold，默认值为 40），那么 Java 虚拟机会认为这个类已经不再适合偏向锁。此时，Java 虚拟机会撤销该类实例的偏向锁，并且在之后的加锁过程中直接为该类实例设置轻量级锁。 总结来说就是偏向锁遇到需要撤销的情况，就先从偏向锁转成轻量级锁。撤销20次后当前的类的偏向锁失效，epoch+1。撤销40次后，被取消作为偏向锁的资格，在用这个对象作为锁对象时直接使用轻量级锁。 补充 jvm处理synchronized的时候是先将它当轻量级锁处理，然后在一段时间（延缓毫秒数-XX:BiasedLockingStartupDelay）后变成偏向锁，再慢慢膨胀为重量级锁的。但是在Java 9还是10默认值改为0了，也就是说后面是先按照偏向锁处理，在轻量级、重量级。 对于轻量级锁，markword本质是一个32位的bit，无锁情况下，末尾是01加锁过程只是通过CAS把这32位的bit替换为lockrecord的地址，由于lockrecord地址只有30位，所以末尾补齐32后，末尾是00。 轻量级锁通过cas替换锁的标记字段，和标记字段复制到栈中对应的锁记录中这两个操作的先后顺序无所谓。应该是有保护的机制。","link":"/2019/09/07/2019-9-7-JVM学习笔记11：synchronized的实现/"},{"title":"Maven笔记","text":"基础安装 需要java sdk、Maven 如果使用idea安装则没有对path进行写入，需要手动写入。 M2_HOME:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.1.3\\plugins\\maven\\lib\\maven3 MAVEN_HOME:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.1.3\\plugins\\maven\\lib\\maven3 Path:%M2_HOME%/bin 配置文件 类型 定义位置 Per Project 在项目中定义的POM文件, pom.xml Per User 定义在Maven中的设置XML文件(%USER_HOME%/.m2/settings.xml) Global 定义在Maven中的全局设置xml文件 (%M2_HOME%/conf/settings.xml) src/main/resources有三个特定的文件： 文件名称 描述 env.properties 如果没有配置文件关联则使用默认配置 env.test.properties 当测试配置文件用于测试配置 env.prod.properties 生产配置时，prod信息被使用 代理设置 找到文件 {M2_HOME}/conf/settings.xml, 并把你的代理服务器信息配置写入，下面是一个例子。 1234567891011121314151617&lt;!-- proxies | This is a list of proxies which can be used on this machine to connect to the network. | Unless otherwise specified (by system property or command-line switch), the first proxy | specification in this list marked as active will be used. |--&gt; &lt;proxies&gt; &lt;proxy&gt; &lt;id&gt;optional&lt;/id&gt; &lt;active&gt;true&lt;/active&gt; &lt;protocol&gt;http&lt;/protocol&gt; &lt;username&gt;yiibai&lt;/username&gt; &lt;password&gt;password&lt;/password&gt; &lt;host&gt;proxy.yiibai.com&lt;/host&gt; &lt;port&gt;8888&lt;/port&gt; &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt; &lt;/proxy&gt; &lt;/proxies&gt; 本地仓库 默认情况下，Maven的本地资源库默认为 .m2 目录文件夹： Unix/Mac OS X: ~/.m2 Windows：${user.home}/.m2/repository PS：我本机的是在C:\\Users\\admin\\.m2 在setting.xml中可以修改这个位置 1234567&lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; --&gt; &lt;localRepository&gt;D:\\software\\apache-maven\\repository&lt;/localRepository&gt; 中央存储库 官方的库：https://search.maven.org/ 从Maven远程存储库下载 在Maven中，当你声明的库不存在于本地存储库中，也不存在于Maven中心储存库，该过程将停止并将错误消息输出到 Maven 控制台。 例如在pox.xml中定义下面的库将依赖找不到失败并输出错误消息，需要在repositories中定义url。 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.jvnet.localizer&lt;/groupId&gt; &lt;artifactId&gt;localizer&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt;&lt;/dependency&gt;&lt;!--添加远程库--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;java.net&lt;/id&gt; &lt;url&gt;https://maven.java.net/content/repositories/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 经过上面的修改，Maven的依赖库查询顺序更改为： 在 Maven 本地资源库中搜索，如果没有找到，进入第 2 步，否则退出。 在 Maven 中央存储库搜索，如果没有找到，进入第 3 步，否则退出。 在 java.net Maven的远程存储库搜索，如果没有找到，提示错误信息，否则退出。 使用依赖机制 传统使用jar需要自己下载、放入项目设置依赖，用maven可以通过设置dependency标签来实现依赖库的下载与更新。 比如在pom.xml中定义依赖log4j，你们在maven编译或构建时就会从中心库下载包到本地库。 如果“version”标签被忽略，它会自动升级库时当有新的版本时。 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.14&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在这个期间发生的过程就是上面说的，先在本地找，然后去中央库，最后去自定义的远程库中。 依赖传递 问题是：A依赖B，C依赖A，变相的C依赖B。 只需要在每个项目POM定义直接依赖关系。 Maven自动处理其余部分。 下图主要的依赖关系可以通过父POM来管理Libs的依赖，当建立App-UI-WAR项目，Maven会发现所有的依赖通过遍历依赖图和构建应用程序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192===================App-UI-WAR===================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;App-UI-WAR&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;App-Core-lib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;App-Data-lib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt;===================App-Core-lib===================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;Root&lt;/artifactId&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;App-Core-lib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt;&lt;/project&gt;===================App-Data-lib===================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;Root&lt;/artifactId&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;App-Data-lib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt;&lt;/project&gt;===================Root===================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.groupname&lt;/groupId&gt; &lt;artifactId&gt;Root&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.companyname.groupname1&lt;/groupId&gt; &lt;artifactId&gt;Lib1&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.companyname.groupname2&lt;/groupId&gt; &lt;artifactId&gt;Lib2&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.companyname.groupname3&lt;/groupId&gt; &lt;artifactId&gt;Lib3&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 自定义jar包到本地maven 使用mvn install命令，然后在pom中使用即可。 123456789101112131415161718D:\\&gt;mvn install:install-file -Dfile=c:\\kaptcha-2.3.jar -DgroupId=com.google.code -DartifactId=kaptcha -Dversion=2.3 -Dpackaging=jar[INFO] Scanning for projects...[INFO] Searching repository for plugin with prefix: &apos;install&apos;.[INFO] ------------------------------------------------------------------------[INFO] Building Maven Default Project[INFO] task-segment: [install:install-file] (aggregator-style)[INFO] ------------------------------------------------------------------------[INFO] [install:install-file][INFO] Installing c:\\kaptcha-2.3.jar to D:\\maven_repo\\com\\google\\code\\kaptcha\\2.3\\kaptcha-2.3.jar[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ------------------------------------------------------------------------[INFO] Total time: &lt; 1 second[INFO] Finished at: Tue May 12 13:41:42 SGT 2014[INFO] Final Memory: 3M/6M[INFO] ------------------------------------------------------------------------ 构建生命周期命令 mvn clean: 情况build的结果，直接看就是删掉了target文件夹。清理生命周期 mvn compile：编译项目代码，不编译test代码 mvn test: 编译项目和test代码 mvn package: 编译项目代码和test代码，生成war或jar包 mvn install：编译项目代码和test代码，生成war或jar包，并把它们copy到了repository中。感觉可以上传到远程仓库啊！！ mvn deploy: 发布 注意：从compile到deploy是一个完整的默认生命周期，后一个命令会包含前一个命令的操作。比如test即编译了src/main，也编译了test本身。 对于jar包冲突的解决 开发的时候因为要导入jar来帮助编码，但是有时候在部署和运行的时候用的jar包版本冲突，此时对于编码时的jar在设置dependency的时候只要标记scope为provided即可，意味着只在编译和测试的时候用，真正发布后不用。 插件 一个插件通常提供了一组目标，可使用以下语法来执行：mvn [plugin-name]:[goal-name] 快照 在开发阶段的一个特殊的版本，maven可以在快照有更新时自动获得最新的快照版本。 如果使用版本号则每次更新还需要手动的修改pom文件中的version，在开发阶段是比较麻烦的事情。 在release时需要将快照名称改为正式名称，比如：2.1:-SNAPSHOT 改为2.1 构建自动化 pomInclude可以在bus-core-api编译后继续编译别的工程。下面的例子中web和desktop依赖core，最后的编译中先编译core，然后开始编译web和desktop。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697======================app_web_ui===========================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;app_web_ui&lt;/groupId&gt; &lt;artifactId&gt;app_web_ui&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;app_web_ui&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;bus_core_api&lt;/groupId&gt; &lt;artifactId&gt;bus_core_api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;C:\\MVN\\bus_core_api\\target\\bus_core_api-1.0-SNAPSHOT.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;======================app-desktop-ui=========================== &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;app-desktop-ui&lt;/groupId&gt; &lt;artifactId&gt;app-desktop-ui&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;bus-core-api&lt;/groupId&gt; &lt;artifactId&gt;bus-core-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt;======================bus-core-api=========================== &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;bus-core-api&lt;/groupId&gt; &lt;artifactId&gt;bus-core-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt;&lt;/project&gt;======================总线POM===========================&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;bus-core-api&lt;/groupId&gt; &lt;artifactId&gt;bus-core-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-invoker-plugin&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;configuration&gt; &lt;debug&gt;true&lt;/debug&gt; &lt;pomIncludes&gt; &lt;pomInclude&gt;app-web-ui/pom.xml&lt;/pomInclude&gt; &lt;pomInclude&gt;app-desktop-ui/pom.xml&lt;/pomInclude&gt; &lt;/pomIncludes&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;build&gt;&lt;/project&gt;","link":"/2019/11/25/Maven笔记/"},{"title":"maven私服的搭建与使用","text":"安装 centOS下使用的nexus3，安装过程没啥可说的，主要是记一下遇到的问题。 vm配置 错误提示内容： Error occurred during initialization of VMCould not reserve enough space for objectheap 解决方法是改小vm需要的内存 在3里面配置vm的文件是/usr/local/nexus/nexus-3.19.1-01/bin/nexus.vmoptions，修改前三行内容为 123-Xms128m-Xmx128m-XX:MaxDirectMemorySize=256m 初始化密码问题 这个问题有点坑，nexus2时默认的账号密码是 admin.admin123，但是到了3在安装完成后会有一个随机的密码，在第一次登陆时进入引导流程，修改密码。 可以通过vim直接打开文件：vim /usr/local/nexus/sonatype-work/nexus3/admin.password。 一个现象是修改密码后找不到这个文件了，不排除是删掉了。 外部访问问题 默认情况下8082（我改了端口号）端口是没有暴露出来的， vim /etc/sysconfig/iptables中添加-A INPUT -m state --state NEW -m tcp -p tcp --dport 8082 -j ACCEPT 配置文件的位置 xxx/nexus-3.19.1-01/etc/nexus-default.properties,里面可以改端口号等信息。 启动方式 进入/usr/local/nexus/nexus-3.19.1-01/bin 执行 ./nexus run。start指令似乎不是我想象的效果。 使用 标准使用流程也没啥可说的，记录部分特别的需求。 同时使用多个私服账密信息获取 servers标签内记录的主要是账号密码这样的信息，但是因为两个私服都有类似thirdparty这样的仓库，在上传第三方jar到仓库的时候就遇到了如何取账号密码信息的问题。 mvn deploy:deploy-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37 -Dpackaging=jar -Dfile=fastjson-1.1.37.jar -Durl=http://192.168.2.130:8082/repository/thirdparty/ -DrepositoryId=mini-thirdparty 上面是命令行，核心的是-DrepositoryId，它代表要用settings中servers标签下哪个server的配置。显然取的是账户为admin的这个来用。 12345678910&lt;server&gt; &lt;id&gt;thirdparty&lt;/id&gt; &lt;username&gt;develop&lt;/username&gt; &lt;password&gt;develop&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;mini-thirdparty&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt;&lt;/server&gt; 提交jar12345678910&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;mini-releases&lt;/id&gt; &lt;url&gt;http://192.168.2.130:8082/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;mini-snapshots&lt;/id&gt; &lt;url&gt;http://192.168.2.130:8082/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 这是一段标准的提交配置，可见这个ID就是server里面配置的，真正决定提交到什么仓库的是URL，id只是用来取账密信息。 mirror的设置 mirrorOf标签用来标注这个镜像是谁的，下面的例子中值是central，所以它就是中央仓库的镜像。国内用阿里的比较多。 123456&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt; 对于私服来说，它可以代理任何的外部仓库，包括中央仓库。因此可以配置成这样，*是个通配符。 需要注意的是，如果私服要验证信息，那么同样需要在servers中设置同id的验证信息。 123456&lt;mirror&gt; &lt;id&gt;nexus-mini&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus mini&lt;/name&gt; &lt;url&gt;http://192.168.2.130:8082/repository/maven-public/&lt;/url&gt;&lt;/mirror&gt; 其实在nexus中maven-public这个仓库是个group，它包含了release、snapshot和maven-central，而maven-central可以设置代理，就可以设置成上面的aliyun的url。 但是需要注意的是，其它几个仓库的验证信息并不会因为配置了maven-public的而忽略。","link":"/2019/12/20/maven私服的搭建与使用/"},{"title":"cmake学习笔记","text":"看了B站一个cmake教程，部分笔记内容来自别人 CMake中的变量 变量和含义 常用变量 含义 PROJECT_NAME 工程名变量 PROJECT_SOURCE_DIR 顶层的项目目录 PROJECT_BINARY_DIR 使用cmake的路径 CMAKE_ROOT CMAKE安装的根目录 CMAKE_BUILD_TYPE 编译类型：empty，Debug，Release… CMAKE_SOURCE_DIR 顶层的CMakeLists.txt所在路径 CMAKE_BINARY_DIR 顶层的CMakeLists.txt的build所在目录 CMAKE_&lt;LANG&gt;_COMPILER 设定某个语言LANG的编译器，比如g-- CMAKE_INSTALL_PREFIX 指令install的路径 CMAKE_CURRENT_SOURCE_DIR 当前CMakeLists.txt所在路径 CMAKE_CURRENT_BINARY_DIR 当前CMakeLists.txt的build所在目录 EXECUTABLE_OUTPUT_PATH 可执行文件输出路径 LIBRARY_OUTPUT_PATH 库输出路径 个别变量解释源码目录结构 123456789101112131415jmudou ├── build.sh├── CMakeLists.txt└── muduo └── base ├── Atomic.h ├── CMakeLists.txt ├── copyable.h ├── tests │ ├── Atomic_unittest.cc │ ├── CMakeLists.txt │ └── Timestamp_unittest.cc ├── Timestamp.cc ├── Timestamp.h └── Types.h 三个CMakeLists.txt输出 123456789101112131415161718192021222324jmuduo/CMakeLists.txt: PROJECT_SOURCE_DIR= 11/jmuduo PROJECT_BINARY_DIR= 11/build/debug CMAKE_SOURCE_DIR= 11/jmuduo # 指定顶层的CMakeLists.txt的，因此所有的都相同 CMAKE_BINARY_DIR= 11/build/debug # 上面四项都是与整个项目相关，因此都是一致的。 CMAKE_CURRENT_SOURCE_DIR= 11/jmuduo # 指定当前层的CMakeLists.txt的，因此与层相关 CMAKE_CURRENT_BINARY_DIR= 11/build/debugmuduo/base/test/CMakeLists.txt: PROJECT_SOURCE_DIR= 11/jmuduo PROJECT_BINARY_DIR= 11/build/debug CMAKE_SOURCE_DIR= 11/jmuduo CMAKE_BINARY_DIR= 11/build/debug CMAKE_CURRENT_SOURCE_DIR= 11/jmuduo/muduo/base/tests CMAKE_CURRENT_BINARY_DIR= 11/build/debug/muduo/base/testsmuduo/base/CMakeLists.txt: PROJECT_SOURCE_DIR= 11/jmuduo PROJECT_BINARY_DIR= 11/build/debug CMAKE_SOURCE_DIR= 11/jmuduo CMAKE_BINARY_DIR= 11/build/debug CMAKE_CURRENT_SOURCE_DIR= 11/jmuduo/muduo/base CMAKE_CURRENT_BINARY_DIR= 11/build/debug/muduo/base 函数所有的函数列表中，&lt;&gt;表示的参数必须要有，[]表示的参数为可选。 set 可以设置三个类型的变量值：正常变量，cache variable、环境变量。 Normal Variable:set(&lt;variable&gt; &lt;value&gt;... [PARENT_SCOPE]) cache：set(&lt;variable&gt; &lt;value&gt;... CACHE &lt;type&gt; &lt;docstring&gt; [FORCE]) env：set(ENV{&lt;variable&gt;} [&lt;value&gt;]) OPTION：提供用户可以选择的选项 格式：option(&lt;variable&gt; &quot;description&quot; [initial value]) 比如： 12345option( USE_MYPATH \"user path\" ON) aux_source_directory 语法：aux_source_directory(&lt;dir&gt; &lt;variable&gt;) 查找目录dir下的所有源文件(即.c, .cpp, .cc等文件)，并将名称保存到 variable 变量 add_compile_options add_compile_options(&lt;option&gt; ...) 向COMPILE_OPTIONS目录属性中添加选项，这些选项在编译当前目录及子目录的对象时被使用。 e.g: add_compile_options(-std=c++11) add_subdirectory add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 添加一个将被编译的子目录。指明CMakeLists.txt所在目录下包含了一个子目录source_dir。这样source_dir下的源文件和CMakeLists.txt等也会被处理。 target_link_libraries target_link_libraries(exec libs) 表示可执行程序exec需要链接到一个名为libs的链接库。 add_library `add_library( [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] [source1] [source2 ...])` 添加一个名为的库文件，该库文件将会根据调用的命令里列出的源文件来创建。对应于逻辑目标名称，而且在一个工程的全局域内必须是唯一的。待构建的库文件的实际文件名根据对应平台的命名约定来构造（比如lib.a或者.lib）。 指定STATIC，SHARED，或者MODULE参数用来指定要创建的库的类型。STATIC库是目标文件的归档文件，在链接其它目标的时候使用。SHARED库会被动态链接，在运行时被加载。MODULE库是不会被链接到其它目标中的插件，但是可能会在运行时使用dlopen-系列的函数动态链接。如果没有类型被显式指定，这个选项将会根据变量BUILD_SHARED_LIBS的当前值是否为真决定是STATIC还是SHARED。 configure_file 加入一个配置头文件，用于处理 CMake 对源码的设置 1234configure_file ( \"${PROJECT_SOURCE_DIR}/config.h.in\" # config.h.in文件目录 \"${PROJECT_BINARY_DIR}/config.h\" # config.h 生成的头文件目录) 在配置文件config.h中，配置相关项，比如options中的USE_MYPATH： 1#cmakedefine USE_MYMATH include include(file [optional])：读取CMake的相关文件。 include(moudle [optional]) the file with name .cmake is searched in the CMAKE_MODULE_PATH。 include_directories 1include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) 将给定的路径添加到编译器搜索包含文件（.h文件）的路径列表中。缺省情况下，该路径会被附加在当前路径列表的后面。这种缺省行为可以通过设置CMAKE_include_directories_BEFORE变量为ON被改变。通过将该变量改变为BEFORE或AFTER，你可以在追加和附加在前端这两种方式中选择，而不用理会缺省设置。如果指定了SYSTEM选项，编译器将会认为该路径是某种平台上的系统包含路径。 install 使用：cmake之后，sudo make install就可以执行相应的库和头文件的安装。 TARGET格式 12345678install(TARGETS targets... [[ARCHIVE|LIBRARY|RUNTIME] [DESTINATION &lt;dir&gt;] [PERMISSIONS permissions...] [CONFIGURATIONS [Debug|Release|...]] [COMPONENT &lt;component&gt;] [OPTIONAL] ] [...]) targets的类型 可以安装的库有[ARCHIVE|LIBRARY|RUNTIME]三种： 1) 可执行程序视为runtime 2) 静态库视为archieve 3) Module Library视为library 4) 共享库和平台有关 另一种说法：有5中可以被安装的目标文件：ARCHIVE，LIBRARY，RUNTIME，FRAMEWORK，和BUNDLE。 除了被标记为MACOSX_BUNDLE属性的可执行文件被当做OS X上的BUNDLE目标外，其他的可执行文件都被当做RUNTIME目标。 静态链接的库文件总是被当做ARCHIVE目标。 模块库总是被当做LIBRARY目标。 对于动态库不是DLL格式的平台来说，动态库会被当做LIBRARY目标来对待， 被标记为FRAMEWORK的动态库是例外，它们被当做OS X上的FRAMEWORK目标。 对于DLL平台而言，动态库的DLL部分被当做一个RUNTIME目标而对应的导出库被当做是一个ARCHIVE目标。 所有基于Windows的系统，包括Cygwin，都是DLL平台。ARCHIVE，LIBRARYRUNTIME和FRAMEWORK参数改变了后续属性会加诸之上的目标的类型。如果只出了一种类型，那么只有那种类型的目标会被安装（这样通常只会安装一个LL或者一个导出库。） - 参数 - `DESTINATION`： 指定一个文件将要被安装的目录。如果给的是一个全路径，那么就直接使用；如果是相对路径，默认是相对`CMAKE_INSTALL_PREFIX`,其值默认是`/usr/local/`。 1) 头文件:`inclide` 2) 可执行文件:`bin` 3) 库:`lib` - `PERMISSIONS`： 指定安装文件的权限： &amp;emsp;&amp;emsp;1) user&amp;emsp;: ` OWNER_READ, OWNER_WRITE, OWNER_EXECUTE` &amp;emsp;&amp;emsp;2) group：`GROUP_READ, GROUP_WRITE, GROUP_EXECUTE` &amp;emsp;&amp;emsp;3) other：`WORLD_READ, WORLD_WRITE, WORLD_EXECUTE` &amp;emsp;&amp;emsp;4) uid&amp;emsp;：` SETUID, and SETGID`。 - `CONFIGURATIONS`：为安装规则建立一个配置文件列表。 install FILES格式 123456INSTALL(FILES files... DESTINATION &lt;dir&gt; [PERMISSIONS permissions...] [CONFIGURATIONS [Debug|Release|...]] [COMPONENT &lt;component&gt;] [RENAME &lt;name&gt;] [OPTIONAL]) files：即文件名 测试 enanle_testing()：启动测试 add_test(testname Exename arg1 arg2 ...)： 需要先运行测试程序enanle_testing()，这个指令才有效。 Exename是可执行程序名，参数arg1, arg2。 set_tests_properties(...) 括号内格式：(Exename [Exename2...] PROPERTIES prop1 value1 prop2 value2)，其中PROPERTIES是固定的单词不能改 为Exename设置属性，如果没有这个属性，就报错，有如下属性： &emsp;&emsp;1) WILL_FAIL：如果设置为true，那么会反转测试结果的pass/fail标志。 &emsp;&emsp;2) PASS_REGULAR_EXPRESSION： 匹配正则表达式，只少有一个匹配，则pass &emsp;&emsp;2) FAIL_REGULAR_EXPRESSION： 匹配正则表达式，则fail 宏测试 12345macro(&lt;name&gt; [arg1 [arg2 [arg3 ...]]]) COMMAND1(ARGS ...) COMMAND2(ARGS ...) ...endmacro(&lt;name&gt;) 就类似于写一个函数，用宏实现，调用：name(arg1,arg2,...)。 设置项目的版本号 在顶层的CMakeLists.txt中： 123# 加入版本号是 1.0set (Project_VERSION_MAJOR 1) # 主版本号set (Project_VERSION_MINOR 0) # 副版本号 在配置文件config.h.in中设置： 12#define Project_VERSION_MAJOR @Project_VERSION_MAJOR@#define Project_VERSION_MINOR @Project_VERSION_MINOR@ main函数中就可以直接使用这两个宏，代表版本号： 123printf(\"Version %d.%d\\n\", Project_VERSION_MAJOR, Project_VERSION_MINOR); target_compile_definitions 格式 123target_compile_definitions(&lt;target&gt; &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...] [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...]) 作用：编译时定义的宏 string REPLACE 123string(REPLACE &lt;match_string&gt; &lt;replace_string&gt; &lt;output_variable&gt; &lt;input&gt; [&lt;input&gt;...]) 将所有input中出现的match_String替换为replace_string，并且将结果存在output_variable。 message 1message([&lt;mode&gt;] \"message to display\" ...) 显示信息给用户 mode取决于信息的类型： STATUS：以简洁的方式显示用户感兴趣的信息。 123456message(STATUS \"CXX_FLAGS = \" ${CMAKE_CXX_FLAGS} \" \" ${CMAKE_CXX_FLAGS_${BUILD_TYPE}} ) 可以理解为printf，把后面的几个信息以空格相间，然后打印出来。显示结果为(和上面对应分成三段): 123456789CXX_FLAGS = -g -D_FILE_OFFSET_BITS=64 -Wall -Wextra -Werror -Wconversion -Wno-unused-parameter -Wold-style-cast -Woverloaded-virtual -Wpointer-arith -Wshadow -Wwrite-strings -march=native -rdynamic -O0 123456(无) = 重要消息；STATUS = 非重要消息；WARNING = CMake 警告, 会继续执行；AUTHOR_WARNING = CMake 警告 (dev), 会继续执行；SEND_ERROR = CMake 错误, 继续执行，但是会跳过生成的步骤；FATAL_ERROR = CMake 错误, 终止所有处理过程； find_package 12345find_package(&lt;PackageName&gt; [version] [EXACT] [QUIET] [MODULE] [REQUIRED] [[COMPONENTS] [components...]] [OPTIONAL_COMPONENTS components...] [NO_POLICY_SCOPE]) 主要是寻找和加载外部项目。如果PackageName找到了，PackageName-found会显出，当没有找到时，默认显示 PackageName-not found。通过模式的选择，可以处理在没有找到包时的解决方案。 QUIET：不显示有用信息， REQUIRED：报错 find_path 1234567891011121314151617find_path ( &lt;VAR&gt; name | NAMES name1 [name2 ...] [HINTS path1 [path2 ... ENV var]] [PATHS path1 [path2 ... ENV var]] [PATH_SUFFIXES suffix1 [suffix2 ...]] [DOC \"cache documentation string\"] [NO_DEFAULT_PATH] [NO_PACKAGE_ROOT_PATH] [NO_CMAKE_PATH] [NO_CMAKE_ENVIRONMENT_PATH] [NO_SYSTEM_ENVIRONMENT_PATH] [NO_CMAKE_SYSTEM_PATH] [CMAKE_FIND_ROOT_PATH_BOTH | ONLY_CMAKE_FIND_ROOT_PATH | NO_CMAKE_FIND_ROOT_PATH] ) 用以寻找包含着name1等文件的目录，如果找到了结果存储在VAR，没有找到结果结果是VAR-not found。成功时，变量被清除find_path再次搜索，没有成功,fin_path再次以相同的变量被调用时搜索。 find_library 同上find_path 1find_library (&lt;VAR&gt; name0|NAMES name1 [path1 path2 ...]) OPTIONS NAMES 为library指定一个或多个可能的名字。 生成库 用add_library命令 静态库与动态库的区别 静态库： 是在链接阶段，库中目标文件所含的所有将被程序使用的函数的机器码被拷贝到最终的可执行文件中。 这个链接的过程是在编译期完成的，好处是程序运行时与函数库无关了，移植方便。运行效率快，以为所有的代码都变成机器码了。 当然，编译结果对象体积会变大。而且如果多个程序公用一个库代码，其实每个程序运行起来都会在内存中包含一份库的代码，造成内存浪费。 动态库： 相反的，目标文件需要的库代码在编译时不会被连接到目标代码中，而是在运行时才被载入。 可执行文件只包含了它需要的函数的引用表，而不是代码。 只有执行时需要的函数代码才被拷贝到内存中。 可以增量更新。 缺点也明显，如果缺失了一些动态库程序会报错。 生成库的使用 cmake中链接内部库的依赖 12345678910111213141516cmake_minimum_required(2.8)project(demo)add_compile_options(-std=c++11)set(LIBRARY_OUTPUT_DIRECTORY ${PROJECT_SOURCE_DIR}/lib)set(LIBRARY_OUTPUT_NAME ${PROJECT_NAME})# 创建一个动态库，名字是libAadd_library(libA SHARED src/classa.cpp)add_executable(${PROJECT_NAME} src/main.cpp)# 链接上面创建的动态库# 也可以在add_executable中加入classa.cpp，但是如果后面还有用到这个库话抽象成一个lib可以复用。target_link_libraries(${PROJECT_NAME} libA ) 导入外部库文件 绝对路径引用方式 install方式 find_package 定义FindlibB.cmake：这个文件本质是为了find_package服务器的，因为这个函数并没有查询自定义目录的能力。 12345678910111213141516171819202122find_path(libB_INCLUDE_DIR NAMES libB.h PATHS \"C:/Users/admin/Desktop/CMAKE/src\" )find_library(libB_LIBRARY NAMES libB PATHS \"C:/Users/admin/Desktop/CMAKE/src\")if(libB_INCLUDE_DIR AND libB_LIBRARY) set(libB_FOUND TRUE)endif(libB_INCLUDE_DIR AND libB_LIBRARY)if(libB_FOUND) if(NOT libB_QUIETLY) message(STATUS \"找到了libB ${libB_LIBRARY}\") endif(NOT libB_QUIETLY)else(libB_FOUND) if(NOT libB_REQUIRED) message(FATAL_ERROR \"没找到了libB \") endif(NOT libB_REQUIRED)endif(libB_FOUND) 使用find_package的完整版 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566cmake_minimum_required(VERSION 3.0.0)project(demo)add_compile_options(-std=c++11)# 设置源码路径set(src_path ${PROJECT_SOURCE_DIR}/src)set(modules_path ${PROJECT_SOURCE_DIR}/modules/)set(LIBRARY_OUTPUT_DIRECTORY ${PROJECT_SOURCE_DIR}/lib)set(LIBRARY_OUTPUT_NAME ${PROJECT_NAME})# 创建一个动态库，名字是libBadd_library(libB STATIC ${src_path}/libB.cpp)# add_executable(${PROJECT_NAME} src/main.cpp)# # 链接上面创建的动态库# # 也可以在add_executable中加入classa.cpp，但是如果后面还有用到这个库话抽象成一个lib可以复用。# target_link_libraries(${PROJECT_NAME} libA )# # 使用第三方库# # 使用绝对路径# set(libB xxx/yyy/libB)# 使用install# 设置FindXXX.cmake文件路径路径，目前测试的结果是无法识别，路径全对。当把文件放到C:\\Program Files\\CMake\\share\\cmake-3.15\\Modules后可以识别。# set(CMAKE_MODULE_PATH \"C:/Users/admin/Desktop/CMAKE/modules/\")set(CMAKE_MODULE_PATH ${modules_path})message(STATUS \"CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH}\")# 需要指定头文件和库文件的安装路径# 先指定安装的前缀CMAKE_INSTALL_PREFIX为 工程src目录下的install文件夹message(STATUS \"源码目录：${PROJECT_SOURCE_DIR}\")set(CMAKE_INSTALL_PREFIX ${PROJECT_SOURCE_DIR}/libB/install)# 安装camke文件到 ${PROJECT_SOURCE_DIR}/libB/install/cmakeinstall(FILES FindlibB.cmake DESTINATION cmake)# 安装文件到install(FILES ${src_path}/libB.h # 将文件安装到${PROJECTOURCE_DIR}/libB/install/include 下 DESTINATION include )# 规定了安装工程中的目标（targets）的规则install(TARGETS libB # 安装的对象是libB ARCHIVE # 将静态库安装到${PROJECT_SOURCE_DIR}/libB/install/lib下 DESTINATION lib ) # find_package查找set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/libB/cmake/)# 查找libB相关的内容：头文件、库文件。将结果放到libB_FOUND这个变量中，这个变量的名称是xxx_FOUND这样的固定格式find_package(libB REQUIRED) # libB_FOUND找到后if(libB_FOUND) # 把libB/install/include路径设置到头文件的搜索路径中 include_directories(${libB_INCLUDE_DIR}) # 编译目标 add_executable(${PROJECT_NAME} src/main.cpp) # 把libB/install/lib中的库文件链接到目标，PS:不确定libB_LIBRARY是个路径还是文件 target_link_libraries(${PROJECT_NAME} ${libB_LIBRARY})else(libB_FOUND) message(ERROR)endif(libB_FOUND) cmake中有大量的约定性的变量，比如FindlibB.cmake这个文件，Find就是标准写法。比如libB_INCLUDE_DIR、libB_LIBRARY、libB_FOUND这些都是固定下发，可以看下 Find Modules 这部分。 cmake语言本身很接近编程语言，因此也有一些类型判断的内容，可以参考 if 的用法这块。 参考 CMake API搜索 CMake tutorial","link":"/2020/03/31/2020-3-31-cmake学习笔记/"},{"title":"MacOS部署Jenkins，打包unity","text":"准备Jenkins 终端输入brew install jenkins，用这个方式安装本质还是个war包，但是不用再安装Tomcat 安装好后直接在终端输入jenkins启动应用，浏览器输入localhost:8080可以打开。 网上有8080端口被占用的处理办法 brew安装失败大概率是因为githubusercontent被墙了，要么梯子，要么修改Mac上的hosts，方法如下： sudo vi /etc/hosts 在https://www.ipaddress.com/查询raw.githubusercontent.com的当前地址 然后在hosts里面加入，当前的IP是199.232.28.133 raw.githubusercontent.com 网页打开后第一次要注册，然后会提示安装插件，最后就可以进入Jenkins。基本上准备工作没啥难度，除了网速。 准备自动打包Jenkins中配置 创建一个任务后，点击任务的配置 构建部分，这些暴露的参数就是给下面脚本用的，而脚本中调用unity命令时的参数又是在C#中通过GetCommandArgValue函数获得。 1234567export Project_Path=$WORKSPACEexport PRODUCT_NAME=&quot;Test&quot;export PROJ_OUTPUT=&quot;$Project_Path/build/android&quot;export UNITY_PATH=&quot;/Applications/Unity/Unity.app/Contents/MacOS/Unity&quot;export PROJ_PATH=&quot;$Project_Path/HelloUnity/&quot;export UNITY3D_BUILD_METHOD=&quot;PerformBuild.CommandLineBuildAndroid&quot;sh /Users/m/work/JenkinsTest/MacBuildAndroid.sh 准备sh脚本 脚本主体就是调用unity的命令，其中大量的参数都来自jenkins的设置。 123456789#！/bin/bashecho &quot;Delete build/android&quot;rm -rf $Project_Path/build/androidecho &quot;Delete Success&quot;echo &quot;Build Android&quot;${UNITY_PATH} -quit -batchmode -nographics -projectPath $PROJ_PATH -executeMethod ${UNITY3D_BUILD_METHOD} -logFile &quot;log.txt&quot; -PROJ_OUTPUT $PROJ_OUTPUT -PRODUCT_NAME $PRODUCT_NAMEecho &quot;Build Success!&quot; 准备C#脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869static readonly string OUTPUT_PATH_NAME = &quot;-PROJ_OUTPUT&quot;;static readonly string PRODUCTT_NAME = &quot;-PRODUCT_NAME&quot;; //包名称...static string GetCommandArgValue(string key){ string defaultValue = string.Empty; // 获取参数的值 string[] args = System.Environment.GetCommandLineArgs(); for (int i = 0; i &lt; args.Length - 1; i++) { if (args[i].Equals(key)) { defaultValue = args[i + 1]; break; } } return defaultValue;}static string[] GetBuildScenes(){ List&lt;string&gt; names = new List&lt;string&gt;(); foreach (EditorBuildSettingsScene e in EditorBuildSettings.scenes) { if (e == null) continue; if (e.enabled) names.Add(e.path); } return names.ToArray();}static string GetBuildPathAndroid(){ string dirPath = GetCommandArgValue(OUTPUT_PATH_NAME) + &quot;/&quot; + GetCommandArgValue(PRODUCTT_NAME) + &quot;.apk&quot;; if (!System.IO.Directory.Exists(dirPath)) { System.IO.Directory.CreateDirectory(dirPath); } return dirPath;} static void CommandLineBuildAndroid(){ Debug.Log(&quot;Command line build android version\\n------------------\\n------------------&quot;); string[] scenes = GetBuildScenes(); string path = GetBuildPathAndroid(); if (scenes == null || scenes.Length == 0 || path == null) { Debug.LogError(&quot;Please add scene to buildsetting...&quot;); return; } Debug.Log(string.Format(&quot;Path: \\&quot;{0}\\&quot;&quot;, path)); for (int i = 0; i &lt; scenes.Length; ++i) { Debug.Log(string.Format(&quot;Scene[{0}]: \\&quot;{1}\\&quot;&quot;, i, scenes[i])); } Debug.Log(&quot;Starting Android Build!&quot;); SetUnityBuildArgs(BuildTargetGroup.Android); BuildPipeline.BuildPlayer(scenes, path, BuildTarget.Android, BuildOptions.None);} 各种删除构建历史记录 jenkins–系统管理—-脚本命令行 12345678910111213141516// NOTE: uncomment parameters below if not using Scriptler &gt;= 2.0, or if you&apos;re just pasting// the script in manually.// The name of the job.def jobName = &quot;Test&quot;// The range of build numbers to delete.def buildRange = &quot;1-30&quot;import jenkins.model.*;import hudson.model.Fingerprint.RangeSet;def j = jenkins.model.Jenkins.instance.getItem(jobName);def r = RangeSet.fromString(buildRange, true);j.getBuilds(r).each { it.delete() } 修改时区 jenkins–系统管理—-脚本命令行 1System.setProperty(&apos;org.apache.commons.jelly.tags.fmt.timeZone&apos;, &apos;Asia/Shanghai&apos;)","link":"/2020/02/27/2020-2-27-MacOS部署Jenkins，打包unity/"}],"tags":[{"name":"iOS学习笔记","slug":"iOS学习笔记","link":"/tags/iOS学习笔记/"},{"name":"Unity3D","slug":"Unity3D","link":"/tags/Unity3D/"},{"name":"杂记","slug":"杂记","link":"/tags/杂记/"},{"name":"VR/AR","slug":"VR-AR","link":"/tags/VR-AR/"},{"name":"3D数学","slug":"3D数学","link":"/tags/3D数学/"},{"name":"游戏设计模式","slug":"游戏设计模式","link":"/tags/游戏设计模式/"},{"name":"Lua","slug":"Lua","link":"/tags/Lua/"},{"name":"UWA","slug":"UWA","link":"/tags/UWA/"},{"name":"PHP","slug":"PHP","link":"/tags/PHP/"},{"name":"Unity預計算即時GI","slug":"Unity預計算即時GI","link":"/tags/Unity預計算即時GI/"},{"name":"CPP","slug":"CPP","link":"/tags/CPP/"},{"name":"并发模型","slug":"并发模型","link":"/tags/并发模型/"},{"name":"组成原理","slug":"组成原理","link":"/tags/组成原理/"},{"name":"Java","slug":"Java","link":"/tags/Java/"}],"categories":[{"name":"移动开发","slug":"移动开发","link":"/categories/移动开发/"},{"name":"游戏开发","slug":"游戏开发","link":"/categories/游戏开发/"},{"name":"杂记","slug":"杂记","link":"/categories/杂记/"},{"name":"编程语言","slug":"编程语言","link":"/categories/编程语言/"},{"name":"软件设计","slug":"软件设计","link":"/categories/软件设计/"},{"name":"计算机基础","slug":"计算机基础","link":"/categories/计算机基础/"}]}